{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn import ensemble as em\n",
    "train = pd.read_csv('year1-data.csv')\n",
    "train2  = pd.read_csv('year2-data.csv')\n",
    "X_test = pd.read_csv('testing_data.csv')\n",
    "#train.shape #6588(366*18)*26\n",
    "#train2.shape #6570(365*18)*26\n",
    "#X_test.shape #9000*11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train.replace(\"#\",\"\")\n",
    "#train = train.replace(\"\\*\",\"\")\n",
    "#train = train.replace(\"x\",\"\")\n",
    "def preprocess(train):\n",
    "    train.replace(\"#\",'',inplace=True,regex=True)\n",
    "    train.replace(\"x\",'',inplace=True,regex=True)\n",
    "    train.replace(\"\\*\",'',inplace=True,regex=True)\n",
    "    train.replace(\"NR\",0,inplace=True) #將NR變成0\n",
    "    train.fillna(0, inplace=True) #把NAN變成0\n",
    "    train = train.iloc[:,2:]\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =  preprocess(train) #6588*24\n",
    "train2 = preprocess(train2) #6570*24\n",
    "X_test = preprocess(X_test) #9000*9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(train,test=False):\n",
    "    train = np.array(train,dtype=float)# to array 6588*24\n",
    "    tmp=[]\n",
    "    feature = []\n",
    "    for i  in range(train.shape[0]): #0~6587\n",
    "        if not test:\n",
    "            if i/18>180 and i/18<240:\n",
    "                continue\n",
    "        index = i%18\n",
    "        if index==2 or index==4 or index==5 or index==7 or index==8 or index==9 or index==12:#只取CO,NO,NO2,PM2.5,PM10,O3,SO2\n",
    "                        \n",
    "    \n",
    "            tmp.append(train[i])\n",
    "        if index==17:\n",
    "            tmp = np.array(tmp,dtype=float)#shape7*24\n",
    "            feature.append(tmp)\n",
    "            tmp = []\n",
    "    feature = np.array(feature,dtype=float)#366*168\n",
    "    print(feature.shape)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_feature(train)#shape 366*168\n",
    "train2 = get_feature(train2)#shape 365*168\n",
    "X_test = get_feature(X_test,test=True)#500*7*9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.concatenate((train, train2), axis=0)#shape 731*7*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train[0]\n",
    "tmp.shape\n",
    "for i in range(1,train.shape[0]):\n",
    "    tmp =  np.concatenate((tmp, train[i]), axis=1)\n",
    "train = tmp #7*17544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(x, y):\n",
    "    if y <= 2 or y > 100:\n",
    "        return False\n",
    "    for i in range(9):\n",
    "        if x[5,i] <= 2 or x[5,i] > 100:\n",
    "            return False\n",
    "    for i in range(9):\n",
    "        for j in range(7):\n",
    "            if x[j,i] < 0:\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 63)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = []\n",
    "X_test.shape\n",
    "for i in range(X_test.shape[0]):\n",
    "    tmp.append(X_test[i].flatten())\n",
    "X_test = tmp \n",
    "X_test = np.array(X_test,dtype=float)#shape 500*63\n",
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "for i in range(0, train.shape[1]-9):\n",
    "    x =  train[:, i:i+9]\n",
    "    y = train[5, i+9]\n",
    "    if valid(x,y):\n",
    "        X.append(x.flatten())\n",
    "        Y.append(y)\n",
    "\n",
    "X = np.array(X)#shape 5845*63\n",
    "Y = np.array(Y)#shape 5845*1\n",
    "#X_1=X[0:2327,:]\n",
    "#X_2=X[2327:4654,:]\n",
    "#X_3=X[4654:6981,:]\n",
    "#X_4=X[6981:9308,:]\n",
    "#X_5=X[9308:,:]\n",
    "#Y_1 = Y[0:2327,:]\n",
    "#Y_2 = Y[2327:4654,:]\n",
    "#Y_3 = Y[4654:6981,:]\n",
    "#Y_4 = Y[6981:9308,:]\n",
    "#Y_5 = Y[9308:,:]\n",
    "#X.shape\n",
    "#Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1         120.4668            2.33m\n",
      "         2          99.6130            2.35m\n",
      "         3          82.5982            2.36m\n",
      "         4          68.6980            2.40m\n",
      "         5          57.3609            2.40m\n",
      "         6          48.0522            2.45m\n",
      "         7          40.4255            2.49m\n",
      "         8          34.1791            2.49m\n",
      "         9          29.0526            2.50m\n",
      "        10          24.7811            2.50m\n",
      "        20           7.0565            2.46m\n",
      "        30           3.5549            2.35m\n",
      "        40           2.2571            2.25m\n",
      "        50           1.5726            2.15m\n",
      "        60           1.1707            2.01m\n",
      "        70           0.9414            1.86m\n",
      "        80           0.8051            1.72m\n",
      "        90           0.6985            1.59m\n",
      "       100           0.5554            1.52m\n",
      "       200           0.0523           56.76s\n",
      "       300           0.0055           27.36s\n",
      "       400           0.0006            0.00s\n",
      "[20.57559712 16.69409583 37.78314352 14.57276084 20.20552636 14.36051784\n",
      "  4.85397764  7.99567504 15.87396078  5.66612839 24.20698116  7.6544459\n",
      " 15.70076156 16.71906542 10.05553872  8.0771301  12.05114828 12.35446481\n",
      "  9.81531224 27.9641259  12.77178902 10.48593474 15.16040987  7.72689336\n",
      " 24.2817025  14.526222   19.1588308  10.64954642 17.9541733   8.55800124\n",
      " 15.66121192 16.20037928 11.25330666 17.16983396 15.07673074 30.27773283\n",
      "  4.93659502 12.66835402 14.88801939 18.5424211  27.91951617 18.3698564\n",
      " 20.92136493  3.42452104 30.96475685 14.43634451 11.13451667 37.38648929\n",
      " 12.28044254 20.07731093  5.05866335 12.0770956  25.08562991 20.90221864\n",
      " 20.1369717  18.65995081  5.21848646 16.66172357 12.41530204  4.97124173\n",
      " 25.8273898  19.96998446  5.84551532 11.29028293 10.88106488  9.6682936\n",
      " 33.58097666 23.82449362 13.32950974 32.85341182 15.61589177  5.71787504\n",
      " 11.59993617 20.82750128 10.43483659  7.71146393 10.97100349 14.37121756\n",
      " 18.55763385  5.48405973 14.39081835  6.27375671 18.95524491  7.11462776\n",
      " 24.26545147  7.85684039  9.17230963  7.76358737  9.42378041 24.50167522\n",
      " 22.52231436 21.80360474 13.47786916  4.67935827 12.90630965 17.95068792\n",
      " 11.15309292 11.80255003  7.03224506 26.19701785  7.43519782 22.82556586\n",
      " 12.15471206  5.84839212 16.66172357 14.31245475  8.06918569  8.63933427\n",
      " 18.32383133 18.35604626 21.73762454  9.33075011  9.7912558  15.24533943\n",
      "  9.97060704  6.19327911 23.69081352 14.10196648 23.51338355 23.82877962\n",
      "  5.57328155 14.29619148 25.70575245 10.78120718 14.26293129  7.66017089\n",
      " 13.87725556 13.77096458 11.63134897 22.79486221 12.44793613 11.1340226\n",
      " 10.61421586 13.42911077 11.86730518 14.82274066  6.51405651 13.08410159\n",
      "  7.4068176   8.819391   18.31937144 16.12778789 23.49014901 17.72164286\n",
      " 25.19941344 10.09240808 16.61105232 34.68355069  8.3945982  11.12141425\n",
      " 45.50354369  5.29716418 12.28289904 12.01998595 22.81580928  4.80512884\n",
      "  9.61732028 23.10734614 11.47783035 18.52849429 20.95600377 21.47274284\n",
      " 11.88821679 12.9885053   6.13770798 16.00155684  7.29124002 10.26800212\n",
      "  8.98769708 44.37346968 20.36280568 16.09988908 20.52457612 13.11736146\n",
      " 15.13547822 37.61779126  6.6547786  15.98701704 10.88166881 17.24467018\n",
      " 14.53461055 11.34327108 11.39714499  8.99238652 24.95784132 14.44096499\n",
      " 14.03180482 30.17300529 10.15225084  7.72823527  5.62591377 29.25683725\n",
      " 24.32000654 18.45227326  8.56698474 18.07486005  9.24478449 12.48677455\n",
      "  9.74714929 10.70701989 12.58712132  9.04656074  7.32778256  8.52941602\n",
      " 12.96487877 18.2390395  15.26324192  5.00270093 17.83383348  4.8734683\n",
      " 14.92833429  7.65572248 14.26247229 14.71537849 13.84814083 10.61801398\n",
      " 19.16079753 20.97281129 16.11775895 18.01009078  9.20299486  9.37212855\n",
      "  7.49660002  9.62153093  8.77929261  6.47872582  7.14385886 13.92762438\n",
      "  6.69955913  6.24428119 12.86678759 12.96812869 12.28814536 15.44408513\n",
      " 11.39974318  5.43233514  5.19085861 18.58195879 10.14659475 14.93936143\n",
      " 30.68981187 12.83811808 13.26975505  5.55347029  6.31945727 14.68964687\n",
      " 14.05291206 19.01003113 14.09707108 32.43666338 17.57129336 12.68782134\n",
      "  7.62281266 21.05787375 11.01569373 18.15732978 16.80247801 18.16204319\n",
      "  7.05391834 15.59320881 12.82096027  8.8694763  16.12101744  8.71416409\n",
      " 14.04561527 20.37235799 13.45872033 13.56337258 20.14995526 11.13774658\n",
      "  7.21386297 15.77917747 22.94760809 17.91380609  9.3003578  10.75712877\n",
      "  6.19327911 13.22274687 10.55400106 16.12837542  5.17317312 31.92170651\n",
      " 12.48677455 28.44416885  8.6704596  33.07285518 24.2817025  14.16605387\n",
      " 14.22659138 16.13841448 26.99493923 16.85824229 14.16224702 21.16136855\n",
      " 22.21311575 22.56648753 13.02431923 15.53892109 11.74591174 17.22678074\n",
      " 18.16342002 10.02904568 18.69647283  5.05866335 19.11466506 26.53130908\n",
      " 21.94711179  5.9090544  18.45705936  5.1399004  10.49626547  6.80259217\n",
      " 26.66807296 18.566969    9.99403203  9.26051192  9.88200831 10.74942516\n",
      "  7.7014561  11.12141425 12.37920694 10.48833929 15.55563469 14.14212057\n",
      " 23.36544969 12.63638407 28.55158248  5.776645   14.6253489  25.07480742\n",
      "  7.42835422  5.1864404  17.79794377  5.42234367  8.60662681 12.54368346\n",
      " 15.19638898 11.72297995 27.7237561  20.11348613 10.08601519  7.80416794\n",
      " 19.47944503 19.6574268   8.86201557  8.04346678 14.10196648 26.69908122\n",
      " 13.92324233 14.93086733 26.01100445  5.74502624 31.29887674  5.89119451\n",
      " 25.22994177 17.9541733  32.396733   11.00114199 12.106859   12.45149472\n",
      " 11.61200712  6.66699519  9.97501072 27.23878196 13.5750517  23.40376689\n",
      "  8.71022786 10.55429159 31.95734784 12.96745403 16.01305069  7.97224205\n",
      " 14.30795029 24.18674373 20.86289108 12.95432723 11.00402088 12.19141409\n",
      " 13.04735693 21.47522844 13.05319885  7.9734649  32.82416504  8.88769792\n",
      "  7.29070545  6.12746863 11.99487586 11.834304    9.05023739 10.87084118\n",
      "  9.636803   12.30163119  7.59042718  7.86897066 31.49477044  5.27037324\n",
      "  7.37175041 30.17300529 13.86805968 22.98240148  8.97443368  5.34655163\n",
      " 11.51279916 19.90522822 13.54621419 12.30683585 10.78120718  8.70005484\n",
      " 24.67387136  4.67810386  8.55009663 10.60348513 17.39858854  4.30121322\n",
      " 12.69380481  7.36848214  6.52058142 15.54115726  6.81253652 37.61779126\n",
      " 25.70404524 10.06179801  6.30669054 23.89621269 11.13392694  8.79727344\n",
      "  6.06456678 17.47778878 20.7854024  14.78425842 15.02018128 20.53606766\n",
      "  8.06182531 20.77363122 14.61887031  7.42448397  9.75142228  5.86667861\n",
      "  9.88177503 17.62190411  8.58107141 18.48181393 16.72754586 14.05053663\n",
      " 28.47056743 11.15309292 20.1369717  37.00973614 22.34445761  7.45261902\n",
      " 17.98380947  9.11705994 26.97244594 12.6991023   8.85198911 10.10580519\n",
      " 17.80659008 10.89018144  7.76498187  7.76140834 12.15306917 24.99473327\n",
      " 10.04590806  8.26721596 10.15938784 17.5648385  36.94850813 12.00743442\n",
      " 17.76842239 15.86267458 17.53808698  9.90470046  9.7048166  39.14931303\n",
      " 14.06328157 13.75118726 12.97468174 55.52140077  9.81278893  8.12654827\n",
      "  6.42357611 14.39081835 18.82221367 25.74991013 12.45954018  7.04973411\n",
      " 12.10627212 20.82750128 21.32149065  7.9181473  33.79723238 20.30648204\n",
      " 20.41166236 12.84980117  6.25721955  6.39896309 11.8390758  14.38603947\n",
      "  5.80038329 18.51996386]\n"
     ]
    }
   ],
   "source": [
    "gbmodel = em.GradientBoostingRegressor(verbose = True,n_estimators=400, learning_rate=0.1,max_depth=10, random_state=0, loss='ls').fit(X,Y)\n",
    "ans = gbmodel.predict(X_test)\n",
    "\n",
    "print(ans)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_Regression():\n",
    "    def __init__(self,B = np.double(0),W = np.ones((63, 1))):\n",
    "        self.B = B\n",
    "        self.W = W\n",
    "        pass\n",
    "    def error(self, X, Y):\n",
    "        return Y - self.predict(X)\n",
    "\n",
    "    def MSE(self, X, Y):#MSE(X) = E[(X-Y)^2]\n",
    "        return np.sqrt(np.mean(self.error(X, Y) ** 2))\n",
    "    \n",
    "    def predict(self, X):#   y = wx+b\n",
    "        _X = np.reshape(X, (-1, self.feature_dim))\n",
    "        return np.dot(_X, self.W) + self.B\n",
    "\n",
    "    def fit(self, _X, Y, valid, max_epoch=500000, lr=0.000001, C=0.0):\n",
    "        assert _X.shape[0] == Y.shape[0]\n",
    "        N = _X.shape[0]\n",
    "        self.feature_dim = feature_dim = _X.shape[1]\n",
    "        self.C = C\n",
    "        print(_X.shape)\n",
    "        X = _X\n",
    "        \n",
    "     \n",
    "        #self.B = 0.0\n",
    "        #self.W = np.ones((self.feature_dim, 1))\n",
    "        for epoch in range(1, max_epoch+1):\n",
    "            \n",
    "            error = Y - self.predict(X)          \n",
    "            B_grad = -np.sum(error)  / N\n",
    "            W_grad = -np.dot(X.T, error) / N\n",
    "            self.B = self.B - lr  * B_grad\n",
    "            self.W = self.W - lr  * W_grad\n",
    "            \n",
    "            if epoch % 1000 == 0:\n",
    "                print('[Epoch {}]: loss: {}'.format(epoch, self.MSE(X, Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Linear_Regression()\n",
    "model.fit(X, Y, valid=None, max_epoch=100000, lr=0.000003, C=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict = model.predict(X_test)\n",
    "for i in range(len(ans)):\n",
    "    if ans[i]<0:\n",
    "        ans[i] = 19.445"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " with open('result.csv', 'w') as f:\n",
    "        print('id,value', file=f)\n",
    "        for (i, p) in enumerate(ans) :\n",
    "            print('id_{},{}'.format(i, p), file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO #\n",
    "\n",
    "* ~~去掉七八月~~\n",
    "* ~~shift 3 小時~~\n",
    "* ~~只做PM2.5 PM10 NO2影響大......~~\n",
    "* ~~負的資料砍掉~~\n",
    "* n-fold\n",
    "* normalize\n",
    "* gradient bootsing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
