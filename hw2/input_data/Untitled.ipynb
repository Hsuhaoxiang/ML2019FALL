{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_shape: (32560, 107) \n",
      "Y_shape: (32560, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "X = pd.read_csv(\"X_train\",low_memory=False)\n",
    "X.fillna(0, inplace=True) #把NAN變成0\n",
    "X=np.array(X,dtype = float)\n",
    "\n",
    "X = X[1:,:]\n",
    "Y = pd.read_csv(\"Y_train\",low_memory=False)\n",
    "Y = np.array(Y,dtype = float)\n",
    "bias = np.ones((32560,1))\n",
    "X = np.concatenate((X,bias),axis = 1)\n",
    "print(\"X_shape:\",X.shape,\"\\nY_shape:\",Y.shape)\n",
    "\n",
    "def sigmoid(X):\n",
    "    return 1 / (1 + np.exp(-X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic_Regression():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def _init_para(self):\n",
    "        self.W = np.zeros((self.feature_dim + 1, 1))\n",
    "        self._W_lr = 0.0\n",
    "\n",
    "    def fit(self, X, Y, valid=None, max_epochs=2000, lr=0.05, C=0.0):\n",
    "        assert X.shape[0] == Y.shape[0]\n",
    "        self.feature_dim = X.shape[1]\n",
    "        self._init_lr = self._lr = lr\n",
    "        self.C = C\n",
    "\n",
    "        self._init_para()\n",
    "        \n",
    "        self._mean, self._std = self._get_attr(X)\n",
    "        X = self._scale(X)\n",
    "        X = self._add_bias(X)\n",
    "        \n",
    "        for epoch in range(1, max_epochs+1):\n",
    "            self._step(X, Y)\n",
    "            \n",
    "            \n",
    "            loss = self._loss(X, Y)\n",
    "            acc = self.evaluate(X, Y)\n",
    "            print('[Epoch {:5d}] - training loss: {:.5f}, accuracy: {:.5f}'.format(epoch, loss, acc))\n",
    "            if valid is not None:\n",
    "                print('\\tvalid loss: {:.5f}, accuracy: {:.5f}'.format(self._loss(X_valid, Y_valid), self.evaluate(X_valid, Y_valid)))\n",
    "\n",
    "    def predict(self, X, test=False):\n",
    "        # sigmoid(X * W)\n",
    "        if test:\n",
    "            X = self._scale(X)\n",
    "            X = self._add_bias(X)\n",
    "        return sigmoid(np.dot(X, self.W))\n",
    "\n",
    "    def _get_attr(self, X):\n",
    "        return np.mean(X, axis=0), np.std(X, axis=0) \n",
    "\n",
    "    def _scale(self, X):\n",
    "        return (X - self._mean) / (self._std + 1e-20)\n",
    "\n",
    "    def _step(self, X, Y):\n",
    "        pred = self.predict(X)\n",
    "        self._update(X, Y, pred)\n",
    "\n",
    "    def _update(self, X, Y, pred):\n",
    "        grad = self._gradient(X, Y, pred)\n",
    "\n",
    "        self._W_lr = self._W_lr + grad ** 2\n",
    "        self._lr = self._init_lr / np.sqrt(self._W_lr)\n",
    "\n",
    "        self.W = self.W - self._lr * (grad + self.C * np.sum(self.W))\n",
    "\n",
    "    def _gradient(self, X, Y, pred):\n",
    "        return -np.dot(X.T, (Y - pred))\n",
    "\n",
    "    def _loss(self, X, Y, pred=None):\n",
    "        # y_hat: prediction of model\n",
    "        # -mean(y * log(y_hat) + ((1 - y) * log((1-y_hat))))\n",
    "        if pred is None:\n",
    "            pred = self.predict(X)\n",
    "        return -np.mean(Y * np.log(pred + 1e-20) + (1 - Y) * np.log((1 - pred + 1e-20)))\n",
    "\n",
    "    def evaluate(self, X, Y, test=False):\n",
    "        if test:\n",
    "            X = self._scale(X)\n",
    "            X = self._add_bias(X)\n",
    "        pred = self.predict(X)\n",
    "        p = pred\n",
    "        p[pred < 0.5] = 0.0\n",
    "        p[pred >= 0.5] = 1.0\n",
    "        return np.mean(1 - np.abs(Y - p))\n",
    "\n",
    "    def _add_bias(self, X):\n",
    "        return np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch     1] - training loss: nan, accuracy: nan\n",
      "[Epoch     2] - training loss: nan, accuracy: nan\n",
      "[Epoch     3] - training loss: nan, accuracy: nan\n",
      "[Epoch     4] - training loss: nan, accuracy: nan\n",
      "[Epoch     5] - training loss: nan, accuracy: nan\n",
      "[Epoch     6] - training loss: nan, accuracy: nan\n",
      "[Epoch     7] - training loss: nan, accuracy: nan\n",
      "[Epoch     8] - training loss: nan, accuracy: nan\n",
      "[Epoch     9] - training loss: nan, accuracy: nan\n",
      "[Epoch    10] - training loss: nan, accuracy: nan\n",
      "[Epoch    11] - training loss: nan, accuracy: nan\n",
      "[Epoch    12] - training loss: nan, accuracy: nan\n",
      "[Epoch    13] - training loss: nan, accuracy: nan\n",
      "[Epoch    14] - training loss: nan, accuracy: nan\n",
      "[Epoch    15] - training loss: nan, accuracy: nan\n",
      "[Epoch    16] - training loss: nan, accuracy: nan\n",
      "[Epoch    17] - training loss: nan, accuracy: nan\n",
      "[Epoch    18] - training loss: nan, accuracy: nan\n",
      "[Epoch    19] - training loss: nan, accuracy: nan\n",
      "[Epoch    20] - training loss: nan, accuracy: nan\n",
      "[Epoch    21] - training loss: nan, accuracy: nan\n",
      "[Epoch    22] - training loss: nan, accuracy: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:52: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:54: RuntimeWarning: invalid value encountered in multiply\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:72: RuntimeWarning: invalid value encountered in less\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:73: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch    23] - training loss: nan, accuracy: nan\n",
      "[Epoch    24] - training loss: nan, accuracy: nan\n",
      "[Epoch    25] - training loss: nan, accuracy: nan\n",
      "[Epoch    26] - training loss: nan, accuracy: nan\n",
      "[Epoch    27] - training loss: nan, accuracy: nan\n",
      "[Epoch    28] - training loss: nan, accuracy: nan\n",
      "[Epoch    29] - training loss: nan, accuracy: nan\n",
      "[Epoch    30] - training loss: nan, accuracy: nan\n",
      "[Epoch    31] - training loss: nan, accuracy: nan\n",
      "[Epoch    32] - training loss: nan, accuracy: nan\n",
      "[Epoch    33] - training loss: nan, accuracy: nan\n",
      "[Epoch    34] - training loss: nan, accuracy: nan\n",
      "[Epoch    35] - training loss: nan, accuracy: nan\n",
      "[Epoch    36] - training loss: nan, accuracy: nan\n",
      "[Epoch    37] - training loss: nan, accuracy: nan\n",
      "[Epoch    38] - training loss: nan, accuracy: nan\n",
      "[Epoch    39] - training loss: nan, accuracy: nan\n",
      "[Epoch    40] - training loss: nan, accuracy: nan\n",
      "[Epoch    41] - training loss: nan, accuracy: nan\n",
      "[Epoch    42] - training loss: nan, accuracy: nan\n",
      "[Epoch    43] - training loss: nan, accuracy: nan\n",
      "[Epoch    44] - training loss: nan, accuracy: nan\n",
      "[Epoch    45] - training loss: nan, accuracy: nan\n",
      "[Epoch    46] - training loss: nan, accuracy: nan\n",
      "[Epoch    47] - training loss: nan, accuracy: nan\n",
      "[Epoch    48] - training loss: nan, accuracy: nan\n",
      "[Epoch    49] - training loss: nan, accuracy: nan\n",
      "[Epoch    50] - training loss: nan, accuracy: nan\n",
      "[Epoch    51] - training loss: nan, accuracy: nan\n",
      "[Epoch    52] - training loss: nan, accuracy: nan\n",
      "[Epoch    53] - training loss: nan, accuracy: nan\n",
      "[Epoch    54] - training loss: nan, accuracy: nan\n",
      "[Epoch    55] - training loss: nan, accuracy: nan\n",
      "[Epoch    56] - training loss: nan, accuracy: nan\n",
      "[Epoch    57] - training loss: nan, accuracy: nan\n",
      "[Epoch    58] - training loss: nan, accuracy: nan\n",
      "[Epoch    59] - training loss: nan, accuracy: nan\n",
      "[Epoch    60] - training loss: nan, accuracy: nan\n",
      "[Epoch    61] - training loss: nan, accuracy: nan\n",
      "[Epoch    62] - training loss: nan, accuracy: nan\n",
      "[Epoch    63] - training loss: nan, accuracy: nan\n",
      "[Epoch    64] - training loss: nan, accuracy: nan\n",
      "[Epoch    65] - training loss: nan, accuracy: nan\n",
      "[Epoch    66] - training loss: nan, accuracy: nan\n",
      "[Epoch    67] - training loss: nan, accuracy: nan\n",
      "[Epoch    68] - training loss: nan, accuracy: nan\n",
      "[Epoch    69] - training loss: nan, accuracy: nan\n",
      "[Epoch    70] - training loss: nan, accuracy: nan\n",
      "[Epoch    71] - training loss: nan, accuracy: nan\n",
      "[Epoch    72] - training loss: nan, accuracy: nan\n",
      "[Epoch    73] - training loss: nan, accuracy: nan\n",
      "[Epoch    74] - training loss: nan, accuracy: nan\n",
      "[Epoch    75] - training loss: nan, accuracy: nan\n",
      "[Epoch    76] - training loss: nan, accuracy: nan\n",
      "[Epoch    77] - training loss: nan, accuracy: nan\n",
      "[Epoch    78] - training loss: nan, accuracy: nan\n",
      "[Epoch    79] - training loss: nan, accuracy: nan\n",
      "[Epoch    80] - training loss: nan, accuracy: nan\n",
      "[Epoch    81] - training loss: nan, accuracy: nan\n",
      "[Epoch    82] - training loss: nan, accuracy: nan\n",
      "[Epoch    83] - training loss: nan, accuracy: nan\n",
      "[Epoch    84] - training loss: nan, accuracy: nan\n",
      "[Epoch    85] - training loss: nan, accuracy: nan\n",
      "[Epoch    86] - training loss: nan, accuracy: nan\n",
      "[Epoch    87] - training loss: nan, accuracy: nan\n",
      "[Epoch    88] - training loss: nan, accuracy: nan\n",
      "[Epoch    89] - training loss: nan, accuracy: nan\n",
      "[Epoch    90] - training loss: nan, accuracy: nan\n",
      "[Epoch    91] - training loss: nan, accuracy: nan\n",
      "[Epoch    92] - training loss: nan, accuracy: nan\n",
      "[Epoch    93] - training loss: nan, accuracy: nan\n",
      "[Epoch    94] - training loss: nan, accuracy: nan\n",
      "[Epoch    95] - training loss: nan, accuracy: nan\n",
      "[Epoch    96] - training loss: nan, accuracy: nan\n",
      "[Epoch    97] - training loss: nan, accuracy: nan\n",
      "[Epoch    98] - training loss: nan, accuracy: nan\n",
      "[Epoch    99] - training loss: nan, accuracy: nan\n",
      "[Epoch   100] - training loss: nan, accuracy: nan\n",
      "[Epoch   101] - training loss: nan, accuracy: nan\n",
      "[Epoch   102] - training loss: nan, accuracy: nan\n",
      "[Epoch   103] - training loss: nan, accuracy: nan\n",
      "[Epoch   104] - training loss: nan, accuracy: nan\n",
      "[Epoch   105] - training loss: nan, accuracy: nan\n",
      "[Epoch   106] - training loss: nan, accuracy: nan\n",
      "[Epoch   107] - training loss: nan, accuracy: nan\n",
      "[Epoch   108] - training loss: nan, accuracy: nan\n",
      "[Epoch   109] - training loss: nan, accuracy: nan\n",
      "[Epoch   110] - training loss: nan, accuracy: nan\n",
      "[Epoch   111] - training loss: nan, accuracy: nan\n",
      "[Epoch   112] - training loss: nan, accuracy: nan\n",
      "[Epoch   113] - training loss: nan, accuracy: nan\n",
      "[Epoch   114] - training loss: nan, accuracy: nan\n",
      "[Epoch   115] - training loss: nan, accuracy: nan\n",
      "[Epoch   116] - training loss: nan, accuracy: nan\n",
      "[Epoch   117] - training loss: nan, accuracy: nan\n",
      "[Epoch   118] - training loss: nan, accuracy: nan\n",
      "[Epoch   119] - training loss: nan, accuracy: nan\n",
      "[Epoch   120] - training loss: nan, accuracy: nan\n",
      "[Epoch   121] - training loss: nan, accuracy: nan\n",
      "[Epoch   122] - training loss: nan, accuracy: nan\n",
      "[Epoch   123] - training loss: nan, accuracy: nan\n",
      "[Epoch   124] - training loss: nan, accuracy: nan\n",
      "[Epoch   125] - training loss: nan, accuracy: nan\n",
      "[Epoch   126] - training loss: nan, accuracy: nan\n",
      "[Epoch   127] - training loss: nan, accuracy: nan\n",
      "[Epoch   128] - training loss: nan, accuracy: nan\n",
      "[Epoch   129] - training loss: nan, accuracy: nan\n",
      "[Epoch   130] - training loss: nan, accuracy: nan\n",
      "[Epoch   131] - training loss: nan, accuracy: nan\n",
      "[Epoch   132] - training loss: nan, accuracy: nan\n",
      "[Epoch   133] - training loss: nan, accuracy: nan\n",
      "[Epoch   134] - training loss: nan, accuracy: nan\n",
      "[Epoch   135] - training loss: nan, accuracy: nan\n",
      "[Epoch   136] - training loss: nan, accuracy: nan\n",
      "[Epoch   137] - training loss: nan, accuracy: nan\n",
      "[Epoch   138] - training loss: nan, accuracy: nan\n",
      "[Epoch   139] - training loss: nan, accuracy: nan\n",
      "[Epoch   140] - training loss: nan, accuracy: nan\n",
      "[Epoch   141] - training loss: nan, accuracy: nan\n",
      "[Epoch   142] - training loss: nan, accuracy: nan\n",
      "[Epoch   143] - training loss: nan, accuracy: nan\n",
      "[Epoch   144] - training loss: nan, accuracy: nan\n",
      "[Epoch   145] - training loss: nan, accuracy: nan\n",
      "[Epoch   146] - training loss: nan, accuracy: nan\n",
      "[Epoch   147] - training loss: nan, accuracy: nan\n",
      "[Epoch   148] - training loss: nan, accuracy: nan\n",
      "[Epoch   149] - training loss: nan, accuracy: nan\n",
      "[Epoch   150] - training loss: nan, accuracy: nan\n",
      "[Epoch   151] - training loss: nan, accuracy: nan\n",
      "[Epoch   152] - training loss: nan, accuracy: nan\n",
      "[Epoch   153] - training loss: nan, accuracy: nan\n",
      "[Epoch   154] - training loss: nan, accuracy: nan\n",
      "[Epoch   155] - training loss: nan, accuracy: nan\n",
      "[Epoch   156] - training loss: nan, accuracy: nan\n",
      "[Epoch   157] - training loss: nan, accuracy: nan\n",
      "[Epoch   158] - training loss: nan, accuracy: nan\n",
      "[Epoch   159] - training loss: nan, accuracy: nan\n",
      "[Epoch   160] - training loss: nan, accuracy: nan\n",
      "[Epoch   161] - training loss: nan, accuracy: nan\n",
      "[Epoch   162] - training loss: nan, accuracy: nan\n",
      "[Epoch   163] - training loss: nan, accuracy: nan\n",
      "[Epoch   164] - training loss: nan, accuracy: nan\n",
      "[Epoch   165] - training loss: nan, accuracy: nan\n",
      "[Epoch   166] - training loss: nan, accuracy: nan\n",
      "[Epoch   167] - training loss: nan, accuracy: nan\n",
      "[Epoch   168] - training loss: nan, accuracy: nan\n",
      "[Epoch   169] - training loss: nan, accuracy: nan\n",
      "[Epoch   170] - training loss: nan, accuracy: nan\n",
      "[Epoch   171] - training loss: nan, accuracy: nan\n",
      "[Epoch   172] - training loss: nan, accuracy: nan\n",
      "[Epoch   173] - training loss: nan, accuracy: nan\n",
      "[Epoch   174] - training loss: nan, accuracy: nan\n",
      "[Epoch   175] - training loss: nan, accuracy: nan\n",
      "[Epoch   176] - training loss: nan, accuracy: nan\n",
      "[Epoch   177] - training loss: nan, accuracy: nan\n",
      "[Epoch   178] - training loss: nan, accuracy: nan\n",
      "[Epoch   179] - training loss: nan, accuracy: nan\n",
      "[Epoch   180] - training loss: nan, accuracy: nan\n",
      "[Epoch   181] - training loss: nan, accuracy: nan\n",
      "[Epoch   182] - training loss: nan, accuracy: nan\n",
      "[Epoch   183] - training loss: nan, accuracy: nan\n",
      "[Epoch   184] - training loss: nan, accuracy: nan\n",
      "[Epoch   185] - training loss: nan, accuracy: nan\n",
      "[Epoch   186] - training loss: nan, accuracy: nan\n",
      "[Epoch   187] - training loss: nan, accuracy: nan\n",
      "[Epoch   188] - training loss: nan, accuracy: nan\n",
      "[Epoch   189] - training loss: nan, accuracy: nan\n",
      "[Epoch   190] - training loss: nan, accuracy: nan\n",
      "[Epoch   191] - training loss: nan, accuracy: nan\n",
      "[Epoch   192] - training loss: nan, accuracy: nan\n",
      "[Epoch   193] - training loss: nan, accuracy: nan\n",
      "[Epoch   194] - training loss: nan, accuracy: nan\n",
      "[Epoch   195] - training loss: nan, accuracy: nan\n",
      "[Epoch   196] - training loss: nan, accuracy: nan\n",
      "[Epoch   197] - training loss: nan, accuracy: nan\n",
      "[Epoch   198] - training loss: nan, accuracy: nan\n",
      "[Epoch   199] - training loss: nan, accuracy: nan\n",
      "[Epoch   200] - training loss: nan, accuracy: nan\n",
      "[Epoch   201] - training loss: nan, accuracy: nan\n",
      "[Epoch   202] - training loss: nan, accuracy: nan\n",
      "[Epoch   203] - training loss: nan, accuracy: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   204] - training loss: nan, accuracy: nan\n",
      "[Epoch   205] - training loss: nan, accuracy: nan\n",
      "[Epoch   206] - training loss: nan, accuracy: nan\n",
      "[Epoch   207] - training loss: nan, accuracy: nan\n",
      "[Epoch   208] - training loss: nan, accuracy: nan\n",
      "[Epoch   209] - training loss: nan, accuracy: nan\n",
      "[Epoch   210] - training loss: nan, accuracy: nan\n",
      "[Epoch   211] - training loss: nan, accuracy: nan\n",
      "[Epoch   212] - training loss: nan, accuracy: nan\n",
      "[Epoch   213] - training loss: nan, accuracy: nan\n",
      "[Epoch   214] - training loss: nan, accuracy: nan\n",
      "[Epoch   215] - training loss: nan, accuracy: nan\n",
      "[Epoch   216] - training loss: nan, accuracy: nan\n",
      "[Epoch   217] - training loss: nan, accuracy: nan\n",
      "[Epoch   218] - training loss: nan, accuracy: nan\n",
      "[Epoch   219] - training loss: nan, accuracy: nan\n",
      "[Epoch   220] - training loss: nan, accuracy: nan\n",
      "[Epoch   221] - training loss: nan, accuracy: nan\n",
      "[Epoch   222] - training loss: nan, accuracy: nan\n",
      "[Epoch   223] - training loss: nan, accuracy: nan\n",
      "[Epoch   224] - training loss: nan, accuracy: nan\n",
      "[Epoch   225] - training loss: nan, accuracy: nan\n",
      "[Epoch   226] - training loss: nan, accuracy: nan\n",
      "[Epoch   227] - training loss: nan, accuracy: nan\n",
      "[Epoch   228] - training loss: nan, accuracy: nan\n",
      "[Epoch   229] - training loss: nan, accuracy: nan\n",
      "[Epoch   230] - training loss: nan, accuracy: nan\n",
      "[Epoch   231] - training loss: nan, accuracy: nan\n",
      "[Epoch   232] - training loss: nan, accuracy: nan\n",
      "[Epoch   233] - training loss: nan, accuracy: nan\n",
      "[Epoch   234] - training loss: nan, accuracy: nan\n",
      "[Epoch   235] - training loss: nan, accuracy: nan\n",
      "[Epoch   236] - training loss: nan, accuracy: nan\n",
      "[Epoch   237] - training loss: nan, accuracy: nan\n",
      "[Epoch   238] - training loss: nan, accuracy: nan\n",
      "[Epoch   239] - training loss: nan, accuracy: nan\n",
      "[Epoch   240] - training loss: nan, accuracy: nan\n",
      "[Epoch   241] - training loss: nan, accuracy: nan\n",
      "[Epoch   242] - training loss: nan, accuracy: nan\n",
      "[Epoch   243] - training loss: nan, accuracy: nan\n",
      "[Epoch   244] - training loss: nan, accuracy: nan\n",
      "[Epoch   245] - training loss: nan, accuracy: nan\n",
      "[Epoch   246] - training loss: nan, accuracy: nan\n",
      "[Epoch   247] - training loss: nan, accuracy: nan\n",
      "[Epoch   248] - training loss: nan, accuracy: nan\n",
      "[Epoch   249] - training loss: nan, accuracy: nan\n",
      "[Epoch   250] - training loss: nan, accuracy: nan\n",
      "[Epoch   251] - training loss: nan, accuracy: nan\n",
      "[Epoch   252] - training loss: nan, accuracy: nan\n",
      "[Epoch   253] - training loss: nan, accuracy: nan\n",
      "[Epoch   254] - training loss: nan, accuracy: nan\n",
      "[Epoch   255] - training loss: nan, accuracy: nan\n",
      "[Epoch   256] - training loss: nan, accuracy: nan\n",
      "[Epoch   257] - training loss: nan, accuracy: nan\n",
      "[Epoch   258] - training loss: nan, accuracy: nan\n",
      "[Epoch   259] - training loss: nan, accuracy: nan\n",
      "[Epoch   260] - training loss: nan, accuracy: nan\n",
      "[Epoch   261] - training loss: nan, accuracy: nan\n",
      "[Epoch   262] - training loss: nan, accuracy: nan\n",
      "[Epoch   263] - training loss: nan, accuracy: nan\n",
      "[Epoch   264] - training loss: nan, accuracy: nan\n",
      "[Epoch   265] - training loss: nan, accuracy: nan\n",
      "[Epoch   266] - training loss: nan, accuracy: nan\n",
      "[Epoch   267] - training loss: nan, accuracy: nan\n",
      "[Epoch   268] - training loss: nan, accuracy: nan\n",
      "[Epoch   269] - training loss: nan, accuracy: nan\n",
      "[Epoch   270] - training loss: nan, accuracy: nan\n",
      "[Epoch   271] - training loss: nan, accuracy: nan\n",
      "[Epoch   272] - training loss: nan, accuracy: nan\n",
      "[Epoch   273] - training loss: nan, accuracy: nan\n",
      "[Epoch   274] - training loss: nan, accuracy: nan\n",
      "[Epoch   275] - training loss: nan, accuracy: nan\n",
      "[Epoch   276] - training loss: nan, accuracy: nan\n",
      "[Epoch   277] - training loss: nan, accuracy: nan\n",
      "[Epoch   278] - training loss: nan, accuracy: nan\n",
      "[Epoch   279] - training loss: nan, accuracy: nan\n",
      "[Epoch   280] - training loss: nan, accuracy: nan\n",
      "[Epoch   281] - training loss: nan, accuracy: nan\n",
      "[Epoch   282] - training loss: nan, accuracy: nan\n",
      "[Epoch   283] - training loss: nan, accuracy: nan\n",
      "[Epoch   284] - training loss: nan, accuracy: nan\n",
      "[Epoch   285] - training loss: nan, accuracy: nan\n",
      "[Epoch   286] - training loss: nan, accuracy: nan\n",
      "[Epoch   287] - training loss: nan, accuracy: nan\n",
      "[Epoch   288] - training loss: nan, accuracy: nan\n",
      "[Epoch   289] - training loss: nan, accuracy: nan\n",
      "[Epoch   290] - training loss: nan, accuracy: nan\n",
      "[Epoch   291] - training loss: nan, accuracy: nan\n",
      "[Epoch   292] - training loss: nan, accuracy: nan\n",
      "[Epoch   293] - training loss: nan, accuracy: nan\n",
      "[Epoch   294] - training loss: nan, accuracy: nan\n",
      "[Epoch   295] - training loss: nan, accuracy: nan\n",
      "[Epoch   296] - training loss: nan, accuracy: nan\n",
      "[Epoch   297] - training loss: nan, accuracy: nan\n",
      "[Epoch   298] - training loss: nan, accuracy: nan\n",
      "[Epoch   299] - training loss: nan, accuracy: nan\n",
      "[Epoch   300] - training loss: nan, accuracy: nan\n",
      "[Epoch   301] - training loss: nan, accuracy: nan\n",
      "[Epoch   302] - training loss: nan, accuracy: nan\n",
      "[Epoch   303] - training loss: nan, accuracy: nan\n",
      "[Epoch   304] - training loss: nan, accuracy: nan\n",
      "[Epoch   305] - training loss: nan, accuracy: nan\n",
      "[Epoch   306] - training loss: nan, accuracy: nan\n",
      "[Epoch   307] - training loss: nan, accuracy: nan\n",
      "[Epoch   308] - training loss: nan, accuracy: nan\n",
      "[Epoch   309] - training loss: nan, accuracy: nan\n",
      "[Epoch   310] - training loss: nan, accuracy: nan\n",
      "[Epoch   311] - training loss: nan, accuracy: nan\n",
      "[Epoch   312] - training loss: nan, accuracy: nan\n",
      "[Epoch   313] - training loss: nan, accuracy: nan\n",
      "[Epoch   314] - training loss: nan, accuracy: nan\n",
      "[Epoch   315] - training loss: nan, accuracy: nan\n",
      "[Epoch   316] - training loss: nan, accuracy: nan\n",
      "[Epoch   317] - training loss: nan, accuracy: nan\n",
      "[Epoch   318] - training loss: nan, accuracy: nan\n",
      "[Epoch   319] - training loss: nan, accuracy: nan\n",
      "[Epoch   320] - training loss: nan, accuracy: nan\n",
      "[Epoch   321] - training loss: nan, accuracy: nan\n",
      "[Epoch   322] - training loss: nan, accuracy: nan\n",
      "[Epoch   323] - training loss: nan, accuracy: nan\n",
      "[Epoch   324] - training loss: nan, accuracy: nan\n",
      "[Epoch   325] - training loss: nan, accuracy: nan\n",
      "[Epoch   326] - training loss: nan, accuracy: nan\n",
      "[Epoch   327] - training loss: nan, accuracy: nan\n",
      "[Epoch   328] - training loss: nan, accuracy: nan\n",
      "[Epoch   329] - training loss: nan, accuracy: nan\n",
      "[Epoch   330] - training loss: nan, accuracy: nan\n",
      "[Epoch   331] - training loss: nan, accuracy: nan\n",
      "[Epoch   332] - training loss: nan, accuracy: nan\n",
      "[Epoch   333] - training loss: nan, accuracy: nan\n",
      "[Epoch   334] - training loss: nan, accuracy: nan\n",
      "[Epoch   335] - training loss: nan, accuracy: nan\n",
      "[Epoch   336] - training loss: nan, accuracy: nan\n",
      "[Epoch   337] - training loss: nan, accuracy: nan\n",
      "[Epoch   338] - training loss: nan, accuracy: nan\n",
      "[Epoch   339] - training loss: nan, accuracy: nan\n",
      "[Epoch   340] - training loss: nan, accuracy: nan\n",
      "[Epoch   341] - training loss: nan, accuracy: nan\n",
      "[Epoch   342] - training loss: nan, accuracy: nan\n",
      "[Epoch   343] - training loss: nan, accuracy: nan\n",
      "[Epoch   344] - training loss: nan, accuracy: nan\n",
      "[Epoch   345] - training loss: nan, accuracy: nan\n",
      "[Epoch   346] - training loss: nan, accuracy: nan\n",
      "[Epoch   347] - training loss: nan, accuracy: nan\n",
      "[Epoch   348] - training loss: nan, accuracy: nan\n",
      "[Epoch   349] - training loss: nan, accuracy: nan\n",
      "[Epoch   350] - training loss: nan, accuracy: nan\n",
      "[Epoch   351] - training loss: nan, accuracy: nan\n",
      "[Epoch   352] - training loss: nan, accuracy: nan\n",
      "[Epoch   353] - training loss: nan, accuracy: nan\n",
      "[Epoch   354] - training loss: nan, accuracy: nan\n",
      "[Epoch   355] - training loss: nan, accuracy: nan\n",
      "[Epoch   356] - training loss: nan, accuracy: nan\n",
      "[Epoch   357] - training loss: nan, accuracy: nan\n",
      "[Epoch   358] - training loss: nan, accuracy: nan\n",
      "[Epoch   359] - training loss: nan, accuracy: nan\n",
      "[Epoch   360] - training loss: nan, accuracy: nan\n",
      "[Epoch   361] - training loss: nan, accuracy: nan\n",
      "[Epoch   362] - training loss: nan, accuracy: nan\n",
      "[Epoch   363] - training loss: nan, accuracy: nan\n",
      "[Epoch   364] - training loss: nan, accuracy: nan\n",
      "[Epoch   365] - training loss: nan, accuracy: nan\n",
      "[Epoch   366] - training loss: nan, accuracy: nan\n",
      "[Epoch   367] - training loss: nan, accuracy: nan\n",
      "[Epoch   368] - training loss: nan, accuracy: nan\n",
      "[Epoch   369] - training loss: nan, accuracy: nan\n",
      "[Epoch   370] - training loss: nan, accuracy: nan\n",
      "[Epoch   371] - training loss: nan, accuracy: nan\n",
      "[Epoch   372] - training loss: nan, accuracy: nan\n",
      "[Epoch   373] - training loss: nan, accuracy: nan\n",
      "[Epoch   374] - training loss: nan, accuracy: nan\n",
      "[Epoch   375] - training loss: nan, accuracy: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   376] - training loss: nan, accuracy: nan\n",
      "[Epoch   377] - training loss: nan, accuracy: nan\n",
      "[Epoch   378] - training loss: nan, accuracy: nan\n",
      "[Epoch   379] - training loss: nan, accuracy: nan\n",
      "[Epoch   380] - training loss: nan, accuracy: nan\n",
      "[Epoch   381] - training loss: nan, accuracy: nan\n",
      "[Epoch   382] - training loss: nan, accuracy: nan\n",
      "[Epoch   383] - training loss: nan, accuracy: nan\n",
      "[Epoch   384] - training loss: nan, accuracy: nan\n",
      "[Epoch   385] - training loss: nan, accuracy: nan\n",
      "[Epoch   386] - training loss: nan, accuracy: nan\n",
      "[Epoch   387] - training loss: nan, accuracy: nan\n",
      "[Epoch   388] - training loss: nan, accuracy: nan\n",
      "[Epoch   389] - training loss: nan, accuracy: nan\n",
      "[Epoch   390] - training loss: nan, accuracy: nan\n",
      "[Epoch   391] - training loss: nan, accuracy: nan\n",
      "[Epoch   392] - training loss: nan, accuracy: nan\n",
      "[Epoch   393] - training loss: nan, accuracy: nan\n",
      "[Epoch   394] - training loss: nan, accuracy: nan\n",
      "[Epoch   395] - training loss: nan, accuracy: nan\n",
      "[Epoch   396] - training loss: nan, accuracy: nan\n",
      "[Epoch   397] - training loss: nan, accuracy: nan\n",
      "[Epoch   398] - training loss: nan, accuracy: nan\n",
      "[Epoch   399] - training loss: nan, accuracy: nan\n",
      "[Epoch   400] - training loss: nan, accuracy: nan\n",
      "[Epoch   401] - training loss: nan, accuracy: nan\n",
      "[Epoch   402] - training loss: nan, accuracy: nan\n",
      "[Epoch   403] - training loss: nan, accuracy: nan\n",
      "[Epoch   404] - training loss: nan, accuracy: nan\n",
      "[Epoch   405] - training loss: nan, accuracy: nan\n",
      "[Epoch   406] - training loss: nan, accuracy: nan\n",
      "[Epoch   407] - training loss: nan, accuracy: nan\n",
      "[Epoch   408] - training loss: nan, accuracy: nan\n",
      "[Epoch   409] - training loss: nan, accuracy: nan\n",
      "[Epoch   410] - training loss: nan, accuracy: nan\n",
      "[Epoch   411] - training loss: nan, accuracy: nan\n",
      "[Epoch   412] - training loss: nan, accuracy: nan\n",
      "[Epoch   413] - training loss: nan, accuracy: nan\n",
      "[Epoch   414] - training loss: nan, accuracy: nan\n",
      "[Epoch   415] - training loss: nan, accuracy: nan\n",
      "[Epoch   416] - training loss: nan, accuracy: nan\n",
      "[Epoch   417] - training loss: nan, accuracy: nan\n",
      "[Epoch   418] - training loss: nan, accuracy: nan\n",
      "[Epoch   419] - training loss: nan, accuracy: nan\n",
      "[Epoch   420] - training loss: nan, accuracy: nan\n",
      "[Epoch   421] - training loss: nan, accuracy: nan\n",
      "[Epoch   422] - training loss: nan, accuracy: nan\n",
      "[Epoch   423] - training loss: nan, accuracy: nan\n",
      "[Epoch   424] - training loss: nan, accuracy: nan\n",
      "[Epoch   425] - training loss: nan, accuracy: nan\n",
      "[Epoch   426] - training loss: nan, accuracy: nan\n",
      "[Epoch   427] - training loss: nan, accuracy: nan\n",
      "[Epoch   428] - training loss: nan, accuracy: nan\n",
      "[Epoch   429] - training loss: nan, accuracy: nan\n",
      "[Epoch   430] - training loss: nan, accuracy: nan\n",
      "[Epoch   431] - training loss: nan, accuracy: nan\n",
      "[Epoch   432] - training loss: nan, accuracy: nan\n",
      "[Epoch   433] - training loss: nan, accuracy: nan\n",
      "[Epoch   434] - training loss: nan, accuracy: nan\n",
      "[Epoch   435] - training loss: nan, accuracy: nan\n",
      "[Epoch   436] - training loss: nan, accuracy: nan\n",
      "[Epoch   437] - training loss: nan, accuracy: nan\n",
      "[Epoch   438] - training loss: nan, accuracy: nan\n",
      "[Epoch   439] - training loss: nan, accuracy: nan\n",
      "[Epoch   440] - training loss: nan, accuracy: nan\n",
      "[Epoch   441] - training loss: nan, accuracy: nan\n",
      "[Epoch   442] - training loss: nan, accuracy: nan\n",
      "[Epoch   443] - training loss: nan, accuracy: nan\n",
      "[Epoch   444] - training loss: nan, accuracy: nan\n",
      "[Epoch   445] - training loss: nan, accuracy: nan\n",
      "[Epoch   446] - training loss: nan, accuracy: nan\n",
      "[Epoch   447] - training loss: nan, accuracy: nan\n",
      "[Epoch   448] - training loss: nan, accuracy: nan\n",
      "[Epoch   449] - training loss: nan, accuracy: nan\n",
      "[Epoch   450] - training loss: nan, accuracy: nan\n",
      "[Epoch   451] - training loss: nan, accuracy: nan\n",
      "[Epoch   452] - training loss: nan, accuracy: nan\n",
      "[Epoch   453] - training loss: nan, accuracy: nan\n",
      "[Epoch   454] - training loss: nan, accuracy: nan\n",
      "[Epoch   455] - training loss: nan, accuracy: nan\n",
      "[Epoch   456] - training loss: nan, accuracy: nan\n",
      "[Epoch   457] - training loss: nan, accuracy: nan\n",
      "[Epoch   458] - training loss: nan, accuracy: nan\n",
      "[Epoch   459] - training loss: nan, accuracy: nan\n",
      "[Epoch   460] - training loss: nan, accuracy: nan\n",
      "[Epoch   461] - training loss: nan, accuracy: nan\n",
      "[Epoch   462] - training loss: nan, accuracy: nan\n",
      "[Epoch   463] - training loss: nan, accuracy: nan\n",
      "[Epoch   464] - training loss: nan, accuracy: nan\n",
      "[Epoch   465] - training loss: nan, accuracy: nan\n",
      "[Epoch   466] - training loss: nan, accuracy: nan\n",
      "[Epoch   467] - training loss: nan, accuracy: nan\n",
      "[Epoch   468] - training loss: nan, accuracy: nan\n",
      "[Epoch   469] - training loss: nan, accuracy: nan\n",
      "[Epoch   470] - training loss: nan, accuracy: nan\n",
      "[Epoch   471] - training loss: nan, accuracy: nan\n",
      "[Epoch   472] - training loss: nan, accuracy: nan\n",
      "[Epoch   473] - training loss: nan, accuracy: nan\n",
      "[Epoch   474] - training loss: nan, accuracy: nan\n",
      "[Epoch   475] - training loss: nan, accuracy: nan\n",
      "[Epoch   476] - training loss: nan, accuracy: nan\n",
      "[Epoch   477] - training loss: nan, accuracy: nan\n",
      "[Epoch   478] - training loss: nan, accuracy: nan\n",
      "[Epoch   479] - training loss: nan, accuracy: nan\n",
      "[Epoch   480] - training loss: nan, accuracy: nan\n",
      "[Epoch   481] - training loss: nan, accuracy: nan\n",
      "[Epoch   482] - training loss: nan, accuracy: nan\n",
      "[Epoch   483] - training loss: nan, accuracy: nan\n",
      "[Epoch   484] - training loss: nan, accuracy: nan\n",
      "[Epoch   485] - training loss: nan, accuracy: nan\n",
      "[Epoch   486] - training loss: nan, accuracy: nan\n",
      "[Epoch   487] - training loss: nan, accuracy: nan\n",
      "[Epoch   488] - training loss: nan, accuracy: nan\n",
      "[Epoch   489] - training loss: nan, accuracy: nan\n",
      "[Epoch   490] - training loss: nan, accuracy: nan\n",
      "[Epoch   491] - training loss: nan, accuracy: nan\n",
      "[Epoch   492] - training loss: nan, accuracy: nan\n",
      "[Epoch   493] - training loss: nan, accuracy: nan\n",
      "[Epoch   494] - training loss: nan, accuracy: nan\n",
      "[Epoch   495] - training loss: nan, accuracy: nan\n",
      "[Epoch   496] - training loss: nan, accuracy: nan\n",
      "[Epoch   497] - training loss: nan, accuracy: nan\n",
      "[Epoch   498] - training loss: nan, accuracy: nan\n",
      "[Epoch   499] - training loss: nan, accuracy: nan\n",
      "[Epoch   500] - training loss: nan, accuracy: nan\n",
      "[Epoch   501] - training loss: nan, accuracy: nan\n",
      "[Epoch   502] - training loss: nan, accuracy: nan\n",
      "[Epoch   503] - training loss: nan, accuracy: nan\n",
      "[Epoch   504] - training loss: nan, accuracy: nan\n",
      "[Epoch   505] - training loss: nan, accuracy: nan\n",
      "[Epoch   506] - training loss: nan, accuracy: nan\n",
      "[Epoch   507] - training loss: nan, accuracy: nan\n",
      "[Epoch   508] - training loss: nan, accuracy: nan\n",
      "[Epoch   509] - training loss: nan, accuracy: nan\n",
      "[Epoch   510] - training loss: nan, accuracy: nan\n",
      "[Epoch   511] - training loss: nan, accuracy: nan\n",
      "[Epoch   512] - training loss: nan, accuracy: nan\n",
      "[Epoch   513] - training loss: nan, accuracy: nan\n",
      "[Epoch   514] - training loss: nan, accuracy: nan\n",
      "[Epoch   515] - training loss: nan, accuracy: nan\n",
      "[Epoch   516] - training loss: nan, accuracy: nan\n",
      "[Epoch   517] - training loss: nan, accuracy: nan\n",
      "[Epoch   518] - training loss: nan, accuracy: nan\n",
      "[Epoch   519] - training loss: nan, accuracy: nan\n",
      "[Epoch   520] - training loss: nan, accuracy: nan\n",
      "[Epoch   521] - training loss: nan, accuracy: nan\n",
      "[Epoch   522] - training loss: nan, accuracy: nan\n",
      "[Epoch   523] - training loss: nan, accuracy: nan\n",
      "[Epoch   524] - training loss: nan, accuracy: nan\n",
      "[Epoch   525] - training loss: nan, accuracy: nan\n",
      "[Epoch   526] - training loss: nan, accuracy: nan\n",
      "[Epoch   527] - training loss: nan, accuracy: nan\n",
      "[Epoch   528] - training loss: nan, accuracy: nan\n",
      "[Epoch   529] - training loss: nan, accuracy: nan\n",
      "[Epoch   530] - training loss: nan, accuracy: nan\n",
      "[Epoch   531] - training loss: nan, accuracy: nan\n",
      "[Epoch   532] - training loss: nan, accuracy: nan\n",
      "[Epoch   533] - training loss: nan, accuracy: nan\n",
      "[Epoch   534] - training loss: nan, accuracy: nan\n",
      "[Epoch   535] - training loss: nan, accuracy: nan\n",
      "[Epoch   536] - training loss: nan, accuracy: nan\n",
      "[Epoch   537] - training loss: nan, accuracy: nan\n",
      "[Epoch   538] - training loss: nan, accuracy: nan\n",
      "[Epoch   539] - training loss: nan, accuracy: nan\n",
      "[Epoch   540] - training loss: nan, accuracy: nan\n",
      "[Epoch   541] - training loss: nan, accuracy: nan\n",
      "[Epoch   542] - training loss: nan, accuracy: nan\n",
      "[Epoch   543] - training loss: nan, accuracy: nan\n",
      "[Epoch   544] - training loss: nan, accuracy: nan\n",
      "[Epoch   545] - training loss: nan, accuracy: nan\n",
      "[Epoch   546] - training loss: nan, accuracy: nan\n",
      "[Epoch   547] - training loss: nan, accuracy: nan\n",
      "[Epoch   548] - training loss: nan, accuracy: nan\n",
      "[Epoch   549] - training loss: nan, accuracy: nan\n",
      "[Epoch   550] - training loss: nan, accuracy: nan\n",
      "[Epoch   551] - training loss: nan, accuracy: nan\n",
      "[Epoch   552] - training loss: nan, accuracy: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   553] - training loss: nan, accuracy: nan\n",
      "[Epoch   554] - training loss: nan, accuracy: nan\n",
      "[Epoch   555] - training loss: nan, accuracy: nan\n",
      "[Epoch   556] - training loss: nan, accuracy: nan\n",
      "[Epoch   557] - training loss: nan, accuracy: nan\n",
      "[Epoch   558] - training loss: nan, accuracy: nan\n",
      "[Epoch   559] - training loss: nan, accuracy: nan\n",
      "[Epoch   560] - training loss: nan, accuracy: nan\n",
      "[Epoch   561] - training loss: nan, accuracy: nan\n",
      "[Epoch   562] - training loss: nan, accuracy: nan\n",
      "[Epoch   563] - training loss: nan, accuracy: nan\n",
      "[Epoch   564] - training loss: nan, accuracy: nan\n",
      "[Epoch   565] - training loss: nan, accuracy: nan\n",
      "[Epoch   566] - training loss: nan, accuracy: nan\n",
      "[Epoch   567] - training loss: nan, accuracy: nan\n",
      "[Epoch   568] - training loss: nan, accuracy: nan\n",
      "[Epoch   569] - training loss: nan, accuracy: nan\n",
      "[Epoch   570] - training loss: nan, accuracy: nan\n",
      "[Epoch   571] - training loss: nan, accuracy: nan\n",
      "[Epoch   572] - training loss: nan, accuracy: nan\n",
      "[Epoch   573] - training loss: nan, accuracy: nan\n",
      "[Epoch   574] - training loss: nan, accuracy: nan\n",
      "[Epoch   575] - training loss: nan, accuracy: nan\n",
      "[Epoch   576] - training loss: nan, accuracy: nan\n",
      "[Epoch   577] - training loss: nan, accuracy: nan\n",
      "[Epoch   578] - training loss: nan, accuracy: nan\n",
      "[Epoch   579] - training loss: nan, accuracy: nan\n",
      "[Epoch   580] - training loss: nan, accuracy: nan\n",
      "[Epoch   581] - training loss: nan, accuracy: nan\n",
      "[Epoch   582] - training loss: nan, accuracy: nan\n",
      "[Epoch   583] - training loss: nan, accuracy: nan\n",
      "[Epoch   584] - training loss: nan, accuracy: nan\n",
      "[Epoch   585] - training loss: nan, accuracy: nan\n",
      "[Epoch   586] - training loss: nan, accuracy: nan\n",
      "[Epoch   587] - training loss: nan, accuracy: nan\n",
      "[Epoch   588] - training loss: nan, accuracy: nan\n",
      "[Epoch   589] - training loss: nan, accuracy: nan\n",
      "[Epoch   590] - training loss: nan, accuracy: nan\n",
      "[Epoch   591] - training loss: nan, accuracy: nan\n",
      "[Epoch   592] - training loss: nan, accuracy: nan\n",
      "[Epoch   593] - training loss: nan, accuracy: nan\n",
      "[Epoch   594] - training loss: nan, accuracy: nan\n",
      "[Epoch   595] - training loss: nan, accuracy: nan\n",
      "[Epoch   596] - training loss: nan, accuracy: nan\n",
      "[Epoch   597] - training loss: nan, accuracy: nan\n",
      "[Epoch   598] - training loss: nan, accuracy: nan\n",
      "[Epoch   599] - training loss: nan, accuracy: nan\n",
      "[Epoch   600] - training loss: nan, accuracy: nan\n",
      "[Epoch   601] - training loss: nan, accuracy: nan\n",
      "[Epoch   602] - training loss: nan, accuracy: nan\n",
      "[Epoch   603] - training loss: nan, accuracy: nan\n",
      "[Epoch   604] - training loss: nan, accuracy: nan\n",
      "[Epoch   605] - training loss: nan, accuracy: nan\n",
      "[Epoch   606] - training loss: nan, accuracy: nan\n",
      "[Epoch   607] - training loss: nan, accuracy: nan\n",
      "[Epoch   608] - training loss: nan, accuracy: nan\n",
      "[Epoch   609] - training loss: nan, accuracy: nan\n",
      "[Epoch   610] - training loss: nan, accuracy: nan\n",
      "[Epoch   611] - training loss: nan, accuracy: nan\n",
      "[Epoch   612] - training loss: nan, accuracy: nan\n",
      "[Epoch   613] - training loss: nan, accuracy: nan\n",
      "[Epoch   614] - training loss: nan, accuracy: nan\n",
      "[Epoch   615] - training loss: nan, accuracy: nan\n",
      "[Epoch   616] - training loss: nan, accuracy: nan\n",
      "[Epoch   617] - training loss: nan, accuracy: nan\n",
      "[Epoch   618] - training loss: nan, accuracy: nan\n",
      "[Epoch   619] - training loss: nan, accuracy: nan\n",
      "[Epoch   620] - training loss: nan, accuracy: nan\n",
      "[Epoch   621] - training loss: nan, accuracy: nan\n",
      "[Epoch   622] - training loss: nan, accuracy: nan\n",
      "[Epoch   623] - training loss: nan, accuracy: nan\n",
      "[Epoch   624] - training loss: nan, accuracy: nan\n",
      "[Epoch   625] - training loss: nan, accuracy: nan\n",
      "[Epoch   626] - training loss: nan, accuracy: nan\n",
      "[Epoch   627] - training loss: nan, accuracy: nan\n",
      "[Epoch   628] - training loss: nan, accuracy: nan\n",
      "[Epoch   629] - training loss: nan, accuracy: nan\n",
      "[Epoch   630] - training loss: nan, accuracy: nan\n",
      "[Epoch   631] - training loss: nan, accuracy: nan\n",
      "[Epoch   632] - training loss: nan, accuracy: nan\n",
      "[Epoch   633] - training loss: nan, accuracy: nan\n",
      "[Epoch   634] - training loss: nan, accuracy: nan\n",
      "[Epoch   635] - training loss: nan, accuracy: nan\n",
      "[Epoch   636] - training loss: nan, accuracy: nan\n",
      "[Epoch   637] - training loss: nan, accuracy: nan\n",
      "[Epoch   638] - training loss: nan, accuracy: nan\n",
      "[Epoch   639] - training loss: nan, accuracy: nan\n",
      "[Epoch   640] - training loss: nan, accuracy: nan\n",
      "[Epoch   641] - training loss: nan, accuracy: nan\n",
      "[Epoch   642] - training loss: nan, accuracy: nan\n",
      "[Epoch   643] - training loss: nan, accuracy: nan\n",
      "[Epoch   644] - training loss: nan, accuracy: nan\n",
      "[Epoch   645] - training loss: nan, accuracy: nan\n",
      "[Epoch   646] - training loss: nan, accuracy: nan\n",
      "[Epoch   647] - training loss: nan, accuracy: nan\n",
      "[Epoch   648] - training loss: nan, accuracy: nan\n",
      "[Epoch   649] - training loss: nan, accuracy: nan\n",
      "[Epoch   650] - training loss: nan, accuracy: nan\n",
      "[Epoch   651] - training loss: nan, accuracy: nan\n",
      "[Epoch   652] - training loss: nan, accuracy: nan\n",
      "[Epoch   653] - training loss: nan, accuracy: nan\n",
      "[Epoch   654] - training loss: nan, accuracy: nan\n",
      "[Epoch   655] - training loss: nan, accuracy: nan\n",
      "[Epoch   656] - training loss: nan, accuracy: nan\n",
      "[Epoch   657] - training loss: nan, accuracy: nan\n",
      "[Epoch   658] - training loss: nan, accuracy: nan\n",
      "[Epoch   659] - training loss: nan, accuracy: nan\n",
      "[Epoch   660] - training loss: nan, accuracy: nan\n",
      "[Epoch   661] - training loss: nan, accuracy: nan\n",
      "[Epoch   662] - training loss: nan, accuracy: nan\n",
      "[Epoch   663] - training loss: nan, accuracy: nan\n",
      "[Epoch   664] - training loss: nan, accuracy: nan\n",
      "[Epoch   665] - training loss: nan, accuracy: nan\n",
      "[Epoch   666] - training loss: nan, accuracy: nan\n",
      "[Epoch   667] - training loss: nan, accuracy: nan\n",
      "[Epoch   668] - training loss: nan, accuracy: nan\n",
      "[Epoch   669] - training loss: nan, accuracy: nan\n",
      "[Epoch   670] - training loss: nan, accuracy: nan\n",
      "[Epoch   671] - training loss: nan, accuracy: nan\n",
      "[Epoch   672] - training loss: nan, accuracy: nan\n",
      "[Epoch   673] - training loss: nan, accuracy: nan\n",
      "[Epoch   674] - training loss: nan, accuracy: nan\n",
      "[Epoch   675] - training loss: nan, accuracy: nan\n",
      "[Epoch   676] - training loss: nan, accuracy: nan\n",
      "[Epoch   677] - training loss: nan, accuracy: nan\n",
      "[Epoch   678] - training loss: nan, accuracy: nan\n",
      "[Epoch   679] - training loss: nan, accuracy: nan\n",
      "[Epoch   680] - training loss: nan, accuracy: nan\n",
      "[Epoch   681] - training loss: nan, accuracy: nan\n",
      "[Epoch   682] - training loss: nan, accuracy: nan\n",
      "[Epoch   683] - training loss: nan, accuracy: nan\n",
      "[Epoch   684] - training loss: nan, accuracy: nan\n",
      "[Epoch   685] - training loss: nan, accuracy: nan\n",
      "[Epoch   686] - training loss: nan, accuracy: nan\n",
      "[Epoch   687] - training loss: nan, accuracy: nan\n",
      "[Epoch   688] - training loss: nan, accuracy: nan\n",
      "[Epoch   689] - training loss: nan, accuracy: nan\n",
      "[Epoch   690] - training loss: nan, accuracy: nan\n",
      "[Epoch   691] - training loss: nan, accuracy: nan\n",
      "[Epoch   692] - training loss: nan, accuracy: nan\n",
      "[Epoch   693] - training loss: nan, accuracy: nan\n",
      "[Epoch   694] - training loss: nan, accuracy: nan\n",
      "[Epoch   695] - training loss: nan, accuracy: nan\n",
      "[Epoch   696] - training loss: nan, accuracy: nan\n",
      "[Epoch   697] - training loss: nan, accuracy: nan\n",
      "[Epoch   698] - training loss: nan, accuracy: nan\n",
      "[Epoch   699] - training loss: nan, accuracy: nan\n",
      "[Epoch   700] - training loss: nan, accuracy: nan\n",
      "[Epoch   701] - training loss: nan, accuracy: nan\n",
      "[Epoch   702] - training loss: nan, accuracy: nan\n",
      "[Epoch   703] - training loss: nan, accuracy: nan\n",
      "[Epoch   704] - training loss: nan, accuracy: nan\n",
      "[Epoch   705] - training loss: nan, accuracy: nan\n",
      "[Epoch   706] - training loss: nan, accuracy: nan\n",
      "[Epoch   707] - training loss: nan, accuracy: nan\n",
      "[Epoch   708] - training loss: nan, accuracy: nan\n",
      "[Epoch   709] - training loss: nan, accuracy: nan\n",
      "[Epoch   710] - training loss: nan, accuracy: nan\n",
      "[Epoch   711] - training loss: nan, accuracy: nan\n",
      "[Epoch   712] - training loss: nan, accuracy: nan\n",
      "[Epoch   713] - training loss: nan, accuracy: nan\n",
      "[Epoch   714] - training loss: nan, accuracy: nan\n",
      "[Epoch   715] - training loss: nan, accuracy: nan\n",
      "[Epoch   716] - training loss: nan, accuracy: nan\n",
      "[Epoch   717] - training loss: nan, accuracy: nan\n",
      "[Epoch   718] - training loss: nan, accuracy: nan\n",
      "[Epoch   719] - training loss: nan, accuracy: nan\n",
      "[Epoch   720] - training loss: nan, accuracy: nan\n",
      "[Epoch   721] - training loss: nan, accuracy: nan\n",
      "[Epoch   722] - training loss: nan, accuracy: nan\n",
      "[Epoch   723] - training loss: nan, accuracy: nan\n",
      "[Epoch   724] - training loss: nan, accuracy: nan\n",
      "[Epoch   725] - training loss: nan, accuracy: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   726] - training loss: nan, accuracy: nan\n",
      "[Epoch   727] - training loss: nan, accuracy: nan\n",
      "[Epoch   728] - training loss: nan, accuracy: nan\n",
      "[Epoch   729] - training loss: nan, accuracy: nan\n",
      "[Epoch   730] - training loss: nan, accuracy: nan\n",
      "[Epoch   731] - training loss: nan, accuracy: nan\n",
      "[Epoch   732] - training loss: nan, accuracy: nan\n",
      "[Epoch   733] - training loss: nan, accuracy: nan\n",
      "[Epoch   734] - training loss: nan, accuracy: nan\n",
      "[Epoch   735] - training loss: nan, accuracy: nan\n",
      "[Epoch   736] - training loss: nan, accuracy: nan\n",
      "[Epoch   737] - training loss: nan, accuracy: nan\n",
      "[Epoch   738] - training loss: nan, accuracy: nan\n",
      "[Epoch   739] - training loss: nan, accuracy: nan\n",
      "[Epoch   740] - training loss: nan, accuracy: nan\n",
      "[Epoch   741] - training loss: nan, accuracy: nan\n",
      "[Epoch   742] - training loss: nan, accuracy: nan\n",
      "[Epoch   743] - training loss: nan, accuracy: nan\n",
      "[Epoch   744] - training loss: nan, accuracy: nan\n",
      "[Epoch   745] - training loss: nan, accuracy: nan\n",
      "[Epoch   746] - training loss: nan, accuracy: nan\n",
      "[Epoch   747] - training loss: nan, accuracy: nan\n",
      "[Epoch   748] - training loss: nan, accuracy: nan\n",
      "[Epoch   749] - training loss: nan, accuracy: nan\n",
      "[Epoch   750] - training loss: nan, accuracy: nan\n",
      "[Epoch   751] - training loss: nan, accuracy: nan\n",
      "[Epoch   752] - training loss: nan, accuracy: nan\n",
      "[Epoch   753] - training loss: nan, accuracy: nan\n",
      "[Epoch   754] - training loss: nan, accuracy: nan\n",
      "[Epoch   755] - training loss: nan, accuracy: nan\n",
      "[Epoch   756] - training loss: nan, accuracy: nan\n",
      "[Epoch   757] - training loss: nan, accuracy: nan\n",
      "[Epoch   758] - training loss: nan, accuracy: nan\n",
      "[Epoch   759] - training loss: nan, accuracy: nan\n",
      "[Epoch   760] - training loss: nan, accuracy: nan\n",
      "[Epoch   761] - training loss: nan, accuracy: nan\n",
      "[Epoch   762] - training loss: nan, accuracy: nan\n",
      "[Epoch   763] - training loss: nan, accuracy: nan\n",
      "[Epoch   764] - training loss: nan, accuracy: nan\n",
      "[Epoch   765] - training loss: nan, accuracy: nan\n",
      "[Epoch   766] - training loss: nan, accuracy: nan\n",
      "[Epoch   767] - training loss: nan, accuracy: nan\n",
      "[Epoch   768] - training loss: nan, accuracy: nan\n",
      "[Epoch   769] - training loss: nan, accuracy: nan\n",
      "[Epoch   770] - training loss: nan, accuracy: nan\n",
      "[Epoch   771] - training loss: nan, accuracy: nan\n",
      "[Epoch   772] - training loss: nan, accuracy: nan\n",
      "[Epoch   773] - training loss: nan, accuracy: nan\n",
      "[Epoch   774] - training loss: nan, accuracy: nan\n",
      "[Epoch   775] - training loss: nan, accuracy: nan\n",
      "[Epoch   776] - training loss: nan, accuracy: nan\n",
      "[Epoch   777] - training loss: nan, accuracy: nan\n",
      "[Epoch   778] - training loss: nan, accuracy: nan\n",
      "[Epoch   779] - training loss: nan, accuracy: nan\n",
      "[Epoch   780] - training loss: nan, accuracy: nan\n",
      "[Epoch   781] - training loss: nan, accuracy: nan\n",
      "[Epoch   782] - training loss: nan, accuracy: nan\n",
      "[Epoch   783] - training loss: nan, accuracy: nan\n",
      "[Epoch   784] - training loss: nan, accuracy: nan\n",
      "[Epoch   785] - training loss: nan, accuracy: nan\n",
      "[Epoch   786] - training loss: nan, accuracy: nan\n",
      "[Epoch   787] - training loss: nan, accuracy: nan\n",
      "[Epoch   788] - training loss: nan, accuracy: nan\n",
      "[Epoch   789] - training loss: nan, accuracy: nan\n",
      "[Epoch   790] - training loss: nan, accuracy: nan\n",
      "[Epoch   791] - training loss: nan, accuracy: nan\n",
      "[Epoch   792] - training loss: nan, accuracy: nan\n",
      "[Epoch   793] - training loss: nan, accuracy: nan\n",
      "[Epoch   794] - training loss: nan, accuracy: nan\n",
      "[Epoch   795] - training loss: nan, accuracy: nan\n",
      "[Epoch   796] - training loss: nan, accuracy: nan\n",
      "[Epoch   797] - training loss: nan, accuracy: nan\n",
      "[Epoch   798] - training loss: nan, accuracy: nan\n",
      "[Epoch   799] - training loss: nan, accuracy: nan\n",
      "[Epoch   800] - training loss: nan, accuracy: nan\n",
      "[Epoch   801] - training loss: nan, accuracy: nan\n",
      "[Epoch   802] - training loss: nan, accuracy: nan\n",
      "[Epoch   803] - training loss: nan, accuracy: nan\n",
      "[Epoch   804] - training loss: nan, accuracy: nan\n",
      "[Epoch   805] - training loss: nan, accuracy: nan\n",
      "[Epoch   806] - training loss: nan, accuracy: nan\n",
      "[Epoch   807] - training loss: nan, accuracy: nan\n",
      "[Epoch   808] - training loss: nan, accuracy: nan\n",
      "[Epoch   809] - training loss: nan, accuracy: nan\n",
      "[Epoch   810] - training loss: nan, accuracy: nan\n",
      "[Epoch   811] - training loss: nan, accuracy: nan\n",
      "[Epoch   812] - training loss: nan, accuracy: nan\n",
      "[Epoch   813] - training loss: nan, accuracy: nan\n",
      "[Epoch   814] - training loss: nan, accuracy: nan\n",
      "[Epoch   815] - training loss: nan, accuracy: nan\n",
      "[Epoch   816] - training loss: nan, accuracy: nan\n",
      "[Epoch   817] - training loss: nan, accuracy: nan\n",
      "[Epoch   818] - training loss: nan, accuracy: nan\n",
      "[Epoch   819] - training loss: nan, accuracy: nan\n",
      "[Epoch   820] - training loss: nan, accuracy: nan\n",
      "[Epoch   821] - training loss: nan, accuracy: nan\n",
      "[Epoch   822] - training loss: nan, accuracy: nan\n",
      "[Epoch   823] - training loss: nan, accuracy: nan\n",
      "[Epoch   824] - training loss: nan, accuracy: nan\n",
      "[Epoch   825] - training loss: nan, accuracy: nan\n",
      "[Epoch   826] - training loss: nan, accuracy: nan\n",
      "[Epoch   827] - training loss: nan, accuracy: nan\n",
      "[Epoch   828] - training loss: nan, accuracy: nan\n",
      "[Epoch   829] - training loss: nan, accuracy: nan\n",
      "[Epoch   830] - training loss: nan, accuracy: nan\n",
      "[Epoch   831] - training loss: nan, accuracy: nan\n",
      "[Epoch   832] - training loss: nan, accuracy: nan\n",
      "[Epoch   833] - training loss: nan, accuracy: nan\n",
      "[Epoch   834] - training loss: nan, accuracy: nan\n",
      "[Epoch   835] - training loss: nan, accuracy: nan\n",
      "[Epoch   836] - training loss: nan, accuracy: nan\n",
      "[Epoch   837] - training loss: nan, accuracy: nan\n",
      "[Epoch   838] - training loss: nan, accuracy: nan\n",
      "[Epoch   839] - training loss: nan, accuracy: nan\n",
      "[Epoch   840] - training loss: nan, accuracy: nan\n",
      "[Epoch   841] - training loss: nan, accuracy: nan\n",
      "[Epoch   842] - training loss: nan, accuracy: nan\n",
      "[Epoch   843] - training loss: nan, accuracy: nan\n",
      "[Epoch   844] - training loss: nan, accuracy: nan\n",
      "[Epoch   845] - training loss: nan, accuracy: nan\n",
      "[Epoch   846] - training loss: nan, accuracy: nan\n",
      "[Epoch   847] - training loss: nan, accuracy: nan\n",
      "[Epoch   848] - training loss: nan, accuracy: nan\n",
      "[Epoch   849] - training loss: nan, accuracy: nan\n",
      "[Epoch   850] - training loss: nan, accuracy: nan\n",
      "[Epoch   851] - training loss: nan, accuracy: nan\n",
      "[Epoch   852] - training loss: nan, accuracy: nan\n",
      "[Epoch   853] - training loss: nan, accuracy: nan\n",
      "[Epoch   854] - training loss: nan, accuracy: nan\n",
      "[Epoch   855] - training loss: nan, accuracy: nan\n",
      "[Epoch   856] - training loss: nan, accuracy: nan\n",
      "[Epoch   857] - training loss: nan, accuracy: nan\n",
      "[Epoch   858] - training loss: nan, accuracy: nan\n",
      "[Epoch   859] - training loss: nan, accuracy: nan\n",
      "[Epoch   860] - training loss: nan, accuracy: nan\n",
      "[Epoch   861] - training loss: nan, accuracy: nan\n",
      "[Epoch   862] - training loss: nan, accuracy: nan\n",
      "[Epoch   863] - training loss: nan, accuracy: nan\n",
      "[Epoch   864] - training loss: nan, accuracy: nan\n",
      "[Epoch   865] - training loss: nan, accuracy: nan\n",
      "[Epoch   866] - training loss: nan, accuracy: nan\n",
      "[Epoch   867] - training loss: nan, accuracy: nan\n",
      "[Epoch   868] - training loss: nan, accuracy: nan\n",
      "[Epoch   869] - training loss: nan, accuracy: nan\n",
      "[Epoch   870] - training loss: nan, accuracy: nan\n",
      "[Epoch   871] - training loss: nan, accuracy: nan\n",
      "[Epoch   872] - training loss: nan, accuracy: nan\n",
      "[Epoch   873] - training loss: nan, accuracy: nan\n",
      "[Epoch   874] - training loss: nan, accuracy: nan\n",
      "[Epoch   875] - training loss: nan, accuracy: nan\n",
      "[Epoch   876] - training loss: nan, accuracy: nan\n",
      "[Epoch   877] - training loss: nan, accuracy: nan\n",
      "[Epoch   878] - training loss: nan, accuracy: nan\n",
      "[Epoch   879] - training loss: nan, accuracy: nan\n",
      "[Epoch   880] - training loss: nan, accuracy: nan\n",
      "[Epoch   881] - training loss: nan, accuracy: nan\n",
      "[Epoch   882] - training loss: nan, accuracy: nan\n",
      "[Epoch   883] - training loss: nan, accuracy: nan\n",
      "[Epoch   884] - training loss: nan, accuracy: nan\n",
      "[Epoch   885] - training loss: nan, accuracy: nan\n",
      "[Epoch   886] - training loss: nan, accuracy: nan\n",
      "[Epoch   887] - training loss: nan, accuracy: nan\n",
      "[Epoch   888] - training loss: nan, accuracy: nan\n",
      "[Epoch   889] - training loss: nan, accuracy: nan\n",
      "[Epoch   890] - training loss: nan, accuracy: nan\n",
      "[Epoch   891] - training loss: nan, accuracy: nan\n",
      "[Epoch   892] - training loss: nan, accuracy: nan\n",
      "[Epoch   893] - training loss: nan, accuracy: nan\n",
      "[Epoch   894] - training loss: nan, accuracy: nan\n",
      "[Epoch   895] - training loss: nan, accuracy: nan\n",
      "[Epoch   896] - training loss: nan, accuracy: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   897] - training loss: nan, accuracy: nan\n",
      "[Epoch   898] - training loss: nan, accuracy: nan\n",
      "[Epoch   899] - training loss: nan, accuracy: nan\n",
      "[Epoch   900] - training loss: nan, accuracy: nan\n",
      "[Epoch   901] - training loss: nan, accuracy: nan\n",
      "[Epoch   902] - training loss: nan, accuracy: nan\n",
      "[Epoch   903] - training loss: nan, accuracy: nan\n",
      "[Epoch   904] - training loss: nan, accuracy: nan\n",
      "[Epoch   905] - training loss: nan, accuracy: nan\n",
      "[Epoch   906] - training loss: nan, accuracy: nan\n",
      "[Epoch   907] - training loss: nan, accuracy: nan\n",
      "[Epoch   908] - training loss: nan, accuracy: nan\n",
      "[Epoch   909] - training loss: nan, accuracy: nan\n",
      "[Epoch   910] - training loss: nan, accuracy: nan\n",
      "[Epoch   911] - training loss: nan, accuracy: nan\n",
      "[Epoch   912] - training loss: nan, accuracy: nan\n",
      "[Epoch   913] - training loss: nan, accuracy: nan\n",
      "[Epoch   914] - training loss: nan, accuracy: nan\n",
      "[Epoch   915] - training loss: nan, accuracy: nan\n",
      "[Epoch   916] - training loss: nan, accuracy: nan\n",
      "[Epoch   917] - training loss: nan, accuracy: nan\n",
      "[Epoch   918] - training loss: nan, accuracy: nan\n",
      "[Epoch   919] - training loss: nan, accuracy: nan\n",
      "[Epoch   920] - training loss: nan, accuracy: nan\n",
      "[Epoch   921] - training loss: nan, accuracy: nan\n",
      "[Epoch   922] - training loss: nan, accuracy: nan\n",
      "[Epoch   923] - training loss: nan, accuracy: nan\n",
      "[Epoch   924] - training loss: nan, accuracy: nan\n",
      "[Epoch   925] - training loss: nan, accuracy: nan\n",
      "[Epoch   926] - training loss: nan, accuracy: nan\n",
      "[Epoch   927] - training loss: nan, accuracy: nan\n",
      "[Epoch   928] - training loss: nan, accuracy: nan\n",
      "[Epoch   929] - training loss: nan, accuracy: nan\n",
      "[Epoch   930] - training loss: nan, accuracy: nan\n",
      "[Epoch   931] - training loss: nan, accuracy: nan\n",
      "[Epoch   932] - training loss: nan, accuracy: nan\n",
      "[Epoch   933] - training loss: nan, accuracy: nan\n",
      "[Epoch   934] - training loss: nan, accuracy: nan\n",
      "[Epoch   935] - training loss: nan, accuracy: nan\n",
      "[Epoch   936] - training loss: nan, accuracy: nan\n",
      "[Epoch   937] - training loss: nan, accuracy: nan\n",
      "[Epoch   938] - training loss: nan, accuracy: nan\n",
      "[Epoch   939] - training loss: nan, accuracy: nan\n",
      "[Epoch   940] - training loss: nan, accuracy: nan\n",
      "[Epoch   941] - training loss: nan, accuracy: nan\n",
      "[Epoch   942] - training loss: nan, accuracy: nan\n",
      "[Epoch   943] - training loss: nan, accuracy: nan\n",
      "[Epoch   944] - training loss: nan, accuracy: nan\n",
      "[Epoch   945] - training loss: nan, accuracy: nan\n",
      "[Epoch   946] - training loss: nan, accuracy: nan\n",
      "[Epoch   947] - training loss: nan, accuracy: nan\n",
      "[Epoch   948] - training loss: nan, accuracy: nan\n",
      "[Epoch   949] - training loss: nan, accuracy: nan\n",
      "[Epoch   950] - training loss: nan, accuracy: nan\n",
      "[Epoch   951] - training loss: nan, accuracy: nan\n",
      "[Epoch   952] - training loss: nan, accuracy: nan\n",
      "[Epoch   953] - training loss: nan, accuracy: nan\n",
      "[Epoch   954] - training loss: nan, accuracy: nan\n",
      "[Epoch   955] - training loss: nan, accuracy: nan\n",
      "[Epoch   956] - training loss: nan, accuracy: nan\n",
      "[Epoch   957] - training loss: nan, accuracy: nan\n",
      "[Epoch   958] - training loss: nan, accuracy: nan\n",
      "[Epoch   959] - training loss: nan, accuracy: nan\n",
      "[Epoch   960] - training loss: nan, accuracy: nan\n",
      "[Epoch   961] - training loss: nan, accuracy: nan\n",
      "[Epoch   962] - training loss: nan, accuracy: nan\n",
      "[Epoch   963] - training loss: nan, accuracy: nan\n",
      "[Epoch   964] - training loss: nan, accuracy: nan\n",
      "[Epoch   965] - training loss: nan, accuracy: nan\n",
      "[Epoch   966] - training loss: nan, accuracy: nan\n",
      "[Epoch   967] - training loss: nan, accuracy: nan\n",
      "[Epoch   968] - training loss: nan, accuracy: nan\n",
      "[Epoch   969] - training loss: nan, accuracy: nan\n",
      "[Epoch   970] - training loss: nan, accuracy: nan\n",
      "[Epoch   971] - training loss: nan, accuracy: nan\n",
      "[Epoch   972] - training loss: nan, accuracy: nan\n",
      "[Epoch   973] - training loss: nan, accuracy: nan\n",
      "[Epoch   974] - training loss: nan, accuracy: nan\n",
      "[Epoch   975] - training loss: nan, accuracy: nan\n",
      "[Epoch   976] - training loss: nan, accuracy: nan\n",
      "[Epoch   977] - training loss: nan, accuracy: nan\n",
      "[Epoch   978] - training loss: nan, accuracy: nan\n",
      "[Epoch   979] - training loss: nan, accuracy: nan\n",
      "[Epoch   980] - training loss: nan, accuracy: nan\n",
      "[Epoch   981] - training loss: nan, accuracy: nan\n",
      "[Epoch   982] - training loss: nan, accuracy: nan\n",
      "[Epoch   983] - training loss: nan, accuracy: nan\n",
      "[Epoch   984] - training loss: nan, accuracy: nan\n",
      "[Epoch   985] - training loss: nan, accuracy: nan\n",
      "[Epoch   986] - training loss: nan, accuracy: nan\n",
      "[Epoch   987] - training loss: nan, accuracy: nan\n",
      "[Epoch   988] - training loss: nan, accuracy: nan\n",
      "[Epoch   989] - training loss: nan, accuracy: nan\n",
      "[Epoch   990] - training loss: nan, accuracy: nan\n",
      "[Epoch   991] - training loss: nan, accuracy: nan\n",
      "[Epoch   992] - training loss: nan, accuracy: nan\n",
      "[Epoch   993] - training loss: nan, accuracy: nan\n",
      "[Epoch   994] - training loss: nan, accuracy: nan\n",
      "[Epoch   995] - training loss: nan, accuracy: nan\n",
      "[Epoch   996] - training loss: nan, accuracy: nan\n",
      "[Epoch   997] - training loss: nan, accuracy: nan\n",
      "[Epoch   998] - training loss: nan, accuracy: nan\n",
      "[Epoch   999] - training loss: nan, accuracy: nan\n",
      "[Epoch  1000] - training loss: nan, accuracy: nan\n",
      "[Epoch  1001] - training loss: nan, accuracy: nan\n",
      "[Epoch  1002] - training loss: nan, accuracy: nan\n",
      "[Epoch  1003] - training loss: nan, accuracy: nan\n",
      "[Epoch  1004] - training loss: nan, accuracy: nan\n",
      "[Epoch  1005] - training loss: nan, accuracy: nan\n",
      "[Epoch  1006] - training loss: nan, accuracy: nan\n",
      "[Epoch  1007] - training loss: nan, accuracy: nan\n",
      "[Epoch  1008] - training loss: nan, accuracy: nan\n",
      "[Epoch  1009] - training loss: nan, accuracy: nan\n",
      "[Epoch  1010] - training loss: nan, accuracy: nan\n",
      "[Epoch  1011] - training loss: nan, accuracy: nan\n",
      "[Epoch  1012] - training loss: nan, accuracy: nan\n",
      "[Epoch  1013] - training loss: nan, accuracy: nan\n",
      "[Epoch  1014] - training loss: nan, accuracy: nan\n",
      "[Epoch  1015] - training loss: nan, accuracy: nan\n",
      "[Epoch  1016] - training loss: nan, accuracy: nan\n",
      "[Epoch  1017] - training loss: nan, accuracy: nan\n",
      "[Epoch  1018] - training loss: nan, accuracy: nan\n",
      "[Epoch  1019] - training loss: nan, accuracy: nan\n",
      "[Epoch  1020] - training loss: nan, accuracy: nan\n",
      "[Epoch  1021] - training loss: nan, accuracy: nan\n",
      "[Epoch  1022] - training loss: nan, accuracy: nan\n",
      "[Epoch  1023] - training loss: nan, accuracy: nan\n",
      "[Epoch  1024] - training loss: nan, accuracy: nan\n",
      "[Epoch  1025] - training loss: nan, accuracy: nan\n",
      "[Epoch  1026] - training loss: nan, accuracy: nan\n",
      "[Epoch  1027] - training loss: nan, accuracy: nan\n",
      "[Epoch  1028] - training loss: nan, accuracy: nan\n",
      "[Epoch  1029] - training loss: nan, accuracy: nan\n",
      "[Epoch  1030] - training loss: nan, accuracy: nan\n",
      "[Epoch  1031] - training loss: nan, accuracy: nan\n",
      "[Epoch  1032] - training loss: nan, accuracy: nan\n",
      "[Epoch  1033] - training loss: nan, accuracy: nan\n",
      "[Epoch  1034] - training loss: nan, accuracy: nan\n",
      "[Epoch  1035] - training loss: nan, accuracy: nan\n",
      "[Epoch  1036] - training loss: nan, accuracy: nan\n",
      "[Epoch  1037] - training loss: nan, accuracy: nan\n",
      "[Epoch  1038] - training loss: nan, accuracy: nan\n",
      "[Epoch  1039] - training loss: nan, accuracy: nan\n",
      "[Epoch  1040] - training loss: nan, accuracy: nan\n",
      "[Epoch  1041] - training loss: nan, accuracy: nan\n",
      "[Epoch  1042] - training loss: nan, accuracy: nan\n",
      "[Epoch  1043] - training loss: nan, accuracy: nan\n",
      "[Epoch  1044] - training loss: nan, accuracy: nan\n",
      "[Epoch  1045] - training loss: nan, accuracy: nan\n",
      "[Epoch  1046] - training loss: nan, accuracy: nan\n",
      "[Epoch  1047] - training loss: nan, accuracy: nan\n",
      "[Epoch  1048] - training loss: nan, accuracy: nan\n",
      "[Epoch  1049] - training loss: nan, accuracy: nan\n",
      "[Epoch  1050] - training loss: nan, accuracy: nan\n",
      "[Epoch  1051] - training loss: nan, accuracy: nan\n",
      "[Epoch  1052] - training loss: nan, accuracy: nan\n",
      "[Epoch  1053] - training loss: nan, accuracy: nan\n",
      "[Epoch  1054] - training loss: nan, accuracy: nan\n",
      "[Epoch  1055] - training loss: nan, accuracy: nan\n",
      "[Epoch  1056] - training loss: nan, accuracy: nan\n",
      "[Epoch  1057] - training loss: nan, accuracy: nan\n",
      "[Epoch  1058] - training loss: nan, accuracy: nan\n",
      "[Epoch  1059] - training loss: nan, accuracy: nan\n",
      "[Epoch  1060] - training loss: nan, accuracy: nan\n",
      "[Epoch  1061] - training loss: nan, accuracy: nan\n",
      "[Epoch  1062] - training loss: nan, accuracy: nan\n",
      "[Epoch  1063] - training loss: nan, accuracy: nan\n",
      "[Epoch  1064] - training loss: nan, accuracy: nan\n",
      "[Epoch  1065] - training loss: nan, accuracy: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  1066] - training loss: nan, accuracy: nan\n",
      "[Epoch  1067] - training loss: nan, accuracy: nan\n",
      "[Epoch  1068] - training loss: nan, accuracy: nan\n",
      "[Epoch  1069] - training loss: nan, accuracy: nan\n",
      "[Epoch  1070] - training loss: nan, accuracy: nan\n",
      "[Epoch  1071] - training loss: nan, accuracy: nan\n",
      "[Epoch  1072] - training loss: nan, accuracy: nan\n",
      "[Epoch  1073] - training loss: nan, accuracy: nan\n",
      "[Epoch  1074] - training loss: nan, accuracy: nan\n",
      "[Epoch  1075] - training loss: nan, accuracy: nan\n",
      "[Epoch  1076] - training loss: nan, accuracy: nan\n",
      "[Epoch  1077] - training loss: nan, accuracy: nan\n",
      "[Epoch  1078] - training loss: nan, accuracy: nan\n",
      "[Epoch  1079] - training loss: nan, accuracy: nan\n",
      "[Epoch  1080] - training loss: nan, accuracy: nan\n",
      "[Epoch  1081] - training loss: nan, accuracy: nan\n",
      "[Epoch  1082] - training loss: nan, accuracy: nan\n",
      "[Epoch  1083] - training loss: nan, accuracy: nan\n",
      "[Epoch  1084] - training loss: nan, accuracy: nan\n",
      "[Epoch  1085] - training loss: nan, accuracy: nan\n",
      "[Epoch  1086] - training loss: nan, accuracy: nan\n",
      "[Epoch  1087] - training loss: nan, accuracy: nan\n",
      "[Epoch  1088] - training loss: nan, accuracy: nan\n",
      "[Epoch  1089] - training loss: nan, accuracy: nan\n",
      "[Epoch  1090] - training loss: nan, accuracy: nan\n",
      "[Epoch  1091] - training loss: nan, accuracy: nan\n",
      "[Epoch  1092] - training loss: nan, accuracy: nan\n",
      "[Epoch  1093] - training loss: nan, accuracy: nan\n",
      "[Epoch  1094] - training loss: nan, accuracy: nan\n",
      "[Epoch  1095] - training loss: nan, accuracy: nan\n",
      "[Epoch  1096] - training loss: nan, accuracy: nan\n",
      "[Epoch  1097] - training loss: nan, accuracy: nan\n",
      "[Epoch  1098] - training loss: nan, accuracy: nan\n",
      "[Epoch  1099] - training loss: nan, accuracy: nan\n",
      "[Epoch  1100] - training loss: nan, accuracy: nan\n",
      "[Epoch  1101] - training loss: nan, accuracy: nan\n",
      "[Epoch  1102] - training loss: nan, accuracy: nan\n",
      "[Epoch  1103] - training loss: nan, accuracy: nan\n",
      "[Epoch  1104] - training loss: nan, accuracy: nan\n",
      "[Epoch  1105] - training loss: nan, accuracy: nan\n",
      "[Epoch  1106] - training loss: nan, accuracy: nan\n",
      "[Epoch  1107] - training loss: nan, accuracy: nan\n",
      "[Epoch  1108] - training loss: nan, accuracy: nan\n",
      "[Epoch  1109] - training loss: nan, accuracy: nan\n",
      "[Epoch  1110] - training loss: nan, accuracy: nan\n",
      "[Epoch  1111] - training loss: nan, accuracy: nan\n",
      "[Epoch  1112] - training loss: nan, accuracy: nan\n",
      "[Epoch  1113] - training loss: nan, accuracy: nan\n",
      "[Epoch  1114] - training loss: nan, accuracy: nan\n",
      "[Epoch  1115] - training loss: nan, accuracy: nan\n",
      "[Epoch  1116] - training loss: nan, accuracy: nan\n",
      "[Epoch  1117] - training loss: nan, accuracy: nan\n",
      "[Epoch  1118] - training loss: nan, accuracy: nan\n",
      "[Epoch  1119] - training loss: nan, accuracy: nan\n",
      "[Epoch  1120] - training loss: nan, accuracy: nan\n",
      "[Epoch  1121] - training loss: nan, accuracy: nan\n",
      "[Epoch  1122] - training loss: nan, accuracy: nan\n",
      "[Epoch  1123] - training loss: nan, accuracy: nan\n",
      "[Epoch  1124] - training loss: nan, accuracy: nan\n",
      "[Epoch  1125] - training loss: nan, accuracy: nan\n",
      "[Epoch  1126] - training loss: nan, accuracy: nan\n",
      "[Epoch  1127] - training loss: nan, accuracy: nan\n",
      "[Epoch  1128] - training loss: nan, accuracy: nan\n",
      "[Epoch  1129] - training loss: nan, accuracy: nan\n",
      "[Epoch  1130] - training loss: nan, accuracy: nan\n",
      "[Epoch  1131] - training loss: nan, accuracy: nan\n",
      "[Epoch  1132] - training loss: nan, accuracy: nan\n",
      "[Epoch  1133] - training loss: nan, accuracy: nan\n",
      "[Epoch  1134] - training loss: nan, accuracy: nan\n",
      "[Epoch  1135] - training loss: nan, accuracy: nan\n",
      "[Epoch  1136] - training loss: nan, accuracy: nan\n",
      "[Epoch  1137] - training loss: nan, accuracy: nan\n",
      "[Epoch  1138] - training loss: nan, accuracy: nan\n",
      "[Epoch  1139] - training loss: nan, accuracy: nan\n",
      "[Epoch  1140] - training loss: nan, accuracy: nan\n",
      "[Epoch  1141] - training loss: nan, accuracy: nan\n",
      "[Epoch  1142] - training loss: nan, accuracy: nan\n",
      "[Epoch  1143] - training loss: nan, accuracy: nan\n",
      "[Epoch  1144] - training loss: nan, accuracy: nan\n",
      "[Epoch  1145] - training loss: nan, accuracy: nan\n",
      "[Epoch  1146] - training loss: nan, accuracy: nan\n",
      "[Epoch  1147] - training loss: nan, accuracy: nan\n",
      "[Epoch  1148] - training loss: nan, accuracy: nan\n",
      "[Epoch  1149] - training loss: nan, accuracy: nan\n",
      "[Epoch  1150] - training loss: nan, accuracy: nan\n",
      "[Epoch  1151] - training loss: nan, accuracy: nan\n",
      "[Epoch  1152] - training loss: nan, accuracy: nan\n",
      "[Epoch  1153] - training loss: nan, accuracy: nan\n",
      "[Epoch  1154] - training loss: nan, accuracy: nan\n",
      "[Epoch  1155] - training loss: nan, accuracy: nan\n",
      "[Epoch  1156] - training loss: nan, accuracy: nan\n",
      "[Epoch  1157] - training loss: nan, accuracy: nan\n",
      "[Epoch  1158] - training loss: nan, accuracy: nan\n",
      "[Epoch  1159] - training loss: nan, accuracy: nan\n",
      "[Epoch  1160] - training loss: nan, accuracy: nan\n",
      "[Epoch  1161] - training loss: nan, accuracy: nan\n",
      "[Epoch  1162] - training loss: nan, accuracy: nan\n",
      "[Epoch  1163] - training loss: nan, accuracy: nan\n",
      "[Epoch  1164] - training loss: nan, accuracy: nan\n",
      "[Epoch  1165] - training loss: nan, accuracy: nan\n",
      "[Epoch  1166] - training loss: nan, accuracy: nan\n",
      "[Epoch  1167] - training loss: nan, accuracy: nan\n",
      "[Epoch  1168] - training loss: nan, accuracy: nan\n",
      "[Epoch  1169] - training loss: nan, accuracy: nan\n",
      "[Epoch  1170] - training loss: nan, accuracy: nan\n",
      "[Epoch  1171] - training loss: nan, accuracy: nan\n",
      "[Epoch  1172] - training loss: nan, accuracy: nan\n",
      "[Epoch  1173] - training loss: nan, accuracy: nan\n",
      "[Epoch  1174] - training loss: nan, accuracy: nan\n",
      "[Epoch  1175] - training loss: nan, accuracy: nan\n",
      "[Epoch  1176] - training loss: nan, accuracy: nan\n",
      "[Epoch  1177] - training loss: nan, accuracy: nan\n",
      "[Epoch  1178] - training loss: nan, accuracy: nan\n",
      "[Epoch  1179] - training loss: nan, accuracy: nan\n",
      "[Epoch  1180] - training loss: nan, accuracy: nan\n",
      "[Epoch  1181] - training loss: nan, accuracy: nan\n",
      "[Epoch  1182] - training loss: nan, accuracy: nan\n",
      "[Epoch  1183] - training loss: nan, accuracy: nan\n",
      "[Epoch  1184] - training loss: nan, accuracy: nan\n",
      "[Epoch  1185] - training loss: nan, accuracy: nan\n",
      "[Epoch  1186] - training loss: nan, accuracy: nan\n",
      "[Epoch  1187] - training loss: nan, accuracy: nan\n",
      "[Epoch  1188] - training loss: nan, accuracy: nan\n",
      "[Epoch  1189] - training loss: nan, accuracy: nan\n",
      "[Epoch  1190] - training loss: nan, accuracy: nan\n",
      "[Epoch  1191] - training loss: nan, accuracy: nan\n",
      "[Epoch  1192] - training loss: nan, accuracy: nan\n",
      "[Epoch  1193] - training loss: nan, accuracy: nan\n",
      "[Epoch  1194] - training loss: nan, accuracy: nan\n",
      "[Epoch  1195] - training loss: nan, accuracy: nan\n",
      "[Epoch  1196] - training loss: nan, accuracy: nan\n",
      "[Epoch  1197] - training loss: nan, accuracy: nan\n",
      "[Epoch  1198] - training loss: nan, accuracy: nan\n",
      "[Epoch  1199] - training loss: nan, accuracy: nan\n",
      "[Epoch  1200] - training loss: nan, accuracy: nan\n",
      "[Epoch  1201] - training loss: nan, accuracy: nan\n",
      "[Epoch  1202] - training loss: nan, accuracy: nan\n",
      "[Epoch  1203] - training loss: nan, accuracy: nan\n",
      "[Epoch  1204] - training loss: nan, accuracy: nan\n",
      "[Epoch  1205] - training loss: nan, accuracy: nan\n",
      "[Epoch  1206] - training loss: nan, accuracy: nan\n",
      "[Epoch  1207] - training loss: nan, accuracy: nan\n",
      "[Epoch  1208] - training loss: nan, accuracy: nan\n",
      "[Epoch  1209] - training loss: nan, accuracy: nan\n",
      "[Epoch  1210] - training loss: nan, accuracy: nan\n",
      "[Epoch  1211] - training loss: nan, accuracy: nan\n",
      "[Epoch  1212] - training loss: nan, accuracy: nan\n",
      "[Epoch  1213] - training loss: nan, accuracy: nan\n",
      "[Epoch  1214] - training loss: nan, accuracy: nan\n",
      "[Epoch  1215] - training loss: nan, accuracy: nan\n",
      "[Epoch  1216] - training loss: nan, accuracy: nan\n",
      "[Epoch  1217] - training loss: nan, accuracy: nan\n",
      "[Epoch  1218] - training loss: nan, accuracy: nan\n",
      "[Epoch  1219] - training loss: nan, accuracy: nan\n",
      "[Epoch  1220] - training loss: nan, accuracy: nan\n",
      "[Epoch  1221] - training loss: nan, accuracy: nan\n",
      "[Epoch  1222] - training loss: nan, accuracy: nan\n",
      "[Epoch  1223] - training loss: nan, accuracy: nan\n",
      "[Epoch  1224] - training loss: nan, accuracy: nan\n",
      "[Epoch  1225] - training loss: nan, accuracy: nan\n",
      "[Epoch  1226] - training loss: nan, accuracy: nan\n",
      "[Epoch  1227] - training loss: nan, accuracy: nan\n",
      "[Epoch  1228] - training loss: nan, accuracy: nan\n",
      "[Epoch  1229] - training loss: nan, accuracy: nan\n",
      "[Epoch  1230] - training loss: nan, accuracy: nan\n",
      "[Epoch  1231] - training loss: nan, accuracy: nan\n",
      "[Epoch  1232] - training loss: nan, accuracy: nan\n",
      "[Epoch  1233] - training loss: nan, accuracy: nan\n",
      "[Epoch  1234] - training loss: nan, accuracy: nan\n",
      "[Epoch  1235] - training loss: nan, accuracy: nan\n",
      "[Epoch  1236] - training loss: nan, accuracy: nan\n",
      "[Epoch  1237] - training loss: nan, accuracy: nan\n",
      "[Epoch  1238] - training loss: nan, accuracy: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  1239] - training loss: nan, accuracy: nan\n",
      "[Epoch  1240] - training loss: nan, accuracy: nan\n",
      "[Epoch  1241] - training loss: nan, accuracy: nan\n",
      "[Epoch  1242] - training loss: nan, accuracy: nan\n",
      "[Epoch  1243] - training loss: nan, accuracy: nan\n",
      "[Epoch  1244] - training loss: nan, accuracy: nan\n",
      "[Epoch  1245] - training loss: nan, accuracy: nan\n",
      "[Epoch  1246] - training loss: nan, accuracy: nan\n",
      "[Epoch  1247] - training loss: nan, accuracy: nan\n",
      "[Epoch  1248] - training loss: nan, accuracy: nan\n",
      "[Epoch  1249] - training loss: nan, accuracy: nan\n",
      "[Epoch  1250] - training loss: nan, accuracy: nan\n",
      "[Epoch  1251] - training loss: nan, accuracy: nan\n",
      "[Epoch  1252] - training loss: nan, accuracy: nan\n",
      "[Epoch  1253] - training loss: nan, accuracy: nan\n",
      "[Epoch  1254] - training loss: nan, accuracy: nan\n",
      "[Epoch  1255] - training loss: nan, accuracy: nan\n",
      "[Epoch  1256] - training loss: nan, accuracy: nan\n",
      "[Epoch  1257] - training loss: nan, accuracy: nan\n",
      "[Epoch  1258] - training loss: nan, accuracy: nan\n",
      "[Epoch  1259] - training loss: nan, accuracy: nan\n",
      "[Epoch  1260] - training loss: nan, accuracy: nan\n",
      "[Epoch  1261] - training loss: nan, accuracy: nan\n",
      "[Epoch  1262] - training loss: nan, accuracy: nan\n",
      "[Epoch  1263] - training loss: nan, accuracy: nan\n",
      "[Epoch  1264] - training loss: nan, accuracy: nan\n",
      "[Epoch  1265] - training loss: nan, accuracy: nan\n",
      "[Epoch  1266] - training loss: nan, accuracy: nan\n",
      "[Epoch  1267] - training loss: nan, accuracy: nan\n",
      "[Epoch  1268] - training loss: nan, accuracy: nan\n",
      "[Epoch  1269] - training loss: nan, accuracy: nan\n",
      "[Epoch  1270] - training loss: nan, accuracy: nan\n",
      "[Epoch  1271] - training loss: nan, accuracy: nan\n",
      "[Epoch  1272] - training loss: nan, accuracy: nan\n",
      "[Epoch  1273] - training loss: nan, accuracy: nan\n",
      "[Epoch  1274] - training loss: nan, accuracy: nan\n",
      "[Epoch  1275] - training loss: nan, accuracy: nan\n",
      "[Epoch  1276] - training loss: nan, accuracy: nan\n",
      "[Epoch  1277] - training loss: nan, accuracy: nan\n",
      "[Epoch  1278] - training loss: nan, accuracy: nan\n",
      "[Epoch  1279] - training loss: nan, accuracy: nan\n",
      "[Epoch  1280] - training loss: nan, accuracy: nan\n",
      "[Epoch  1281] - training loss: nan, accuracy: nan\n",
      "[Epoch  1282] - training loss: nan, accuracy: nan\n",
      "[Epoch  1283] - training loss: nan, accuracy: nan\n",
      "[Epoch  1284] - training loss: nan, accuracy: nan\n",
      "[Epoch  1285] - training loss: nan, accuracy: nan\n",
      "[Epoch  1286] - training loss: nan, accuracy: nan\n",
      "[Epoch  1287] - training loss: nan, accuracy: nan\n",
      "[Epoch  1288] - training loss: nan, accuracy: nan\n",
      "[Epoch  1289] - training loss: nan, accuracy: nan\n",
      "[Epoch  1290] - training loss: nan, accuracy: nan\n",
      "[Epoch  1291] - training loss: nan, accuracy: nan\n",
      "[Epoch  1292] - training loss: nan, accuracy: nan\n",
      "[Epoch  1293] - training loss: nan, accuracy: nan\n",
      "[Epoch  1294] - training loss: nan, accuracy: nan\n",
      "[Epoch  1295] - training loss: nan, accuracy: nan\n",
      "[Epoch  1296] - training loss: nan, accuracy: nan\n",
      "[Epoch  1297] - training loss: nan, accuracy: nan\n",
      "[Epoch  1298] - training loss: nan, accuracy: nan\n",
      "[Epoch  1299] - training loss: nan, accuracy: nan\n",
      "[Epoch  1300] - training loss: nan, accuracy: nan\n",
      "[Epoch  1301] - training loss: nan, accuracy: nan\n",
      "[Epoch  1302] - training loss: nan, accuracy: nan\n",
      "[Epoch  1303] - training loss: nan, accuracy: nan\n",
      "[Epoch  1304] - training loss: nan, accuracy: nan\n",
      "[Epoch  1305] - training loss: nan, accuracy: nan\n",
      "[Epoch  1306] - training loss: nan, accuracy: nan\n",
      "[Epoch  1307] - training loss: nan, accuracy: nan\n",
      "[Epoch  1308] - training loss: nan, accuracy: nan\n",
      "[Epoch  1309] - training loss: nan, accuracy: nan\n",
      "[Epoch  1310] - training loss: nan, accuracy: nan\n",
      "[Epoch  1311] - training loss: nan, accuracy: nan\n",
      "[Epoch  1312] - training loss: nan, accuracy: nan\n",
      "[Epoch  1313] - training loss: nan, accuracy: nan\n",
      "[Epoch  1314] - training loss: nan, accuracy: nan\n",
      "[Epoch  1315] - training loss: nan, accuracy: nan\n",
      "[Epoch  1316] - training loss: nan, accuracy: nan\n",
      "[Epoch  1317] - training loss: nan, accuracy: nan\n",
      "[Epoch  1318] - training loss: nan, accuracy: nan\n",
      "[Epoch  1319] - training loss: nan, accuracy: nan\n",
      "[Epoch  1320] - training loss: nan, accuracy: nan\n",
      "[Epoch  1321] - training loss: nan, accuracy: nan\n",
      "[Epoch  1322] - training loss: nan, accuracy: nan\n",
      "[Epoch  1323] - training loss: nan, accuracy: nan\n",
      "[Epoch  1324] - training loss: nan, accuracy: nan\n",
      "[Epoch  1325] - training loss: nan, accuracy: nan\n",
      "[Epoch  1326] - training loss: nan, accuracy: nan\n",
      "[Epoch  1327] - training loss: nan, accuracy: nan\n",
      "[Epoch  1328] - training loss: nan, accuracy: nan\n",
      "[Epoch  1329] - training loss: nan, accuracy: nan\n",
      "[Epoch  1330] - training loss: nan, accuracy: nan\n",
      "[Epoch  1331] - training loss: nan, accuracy: nan\n",
      "[Epoch  1332] - training loss: nan, accuracy: nan\n",
      "[Epoch  1333] - training loss: nan, accuracy: nan\n",
      "[Epoch  1334] - training loss: nan, accuracy: nan\n",
      "[Epoch  1335] - training loss: nan, accuracy: nan\n",
      "[Epoch  1336] - training loss: nan, accuracy: nan\n",
      "[Epoch  1337] - training loss: nan, accuracy: nan\n",
      "[Epoch  1338] - training loss: nan, accuracy: nan\n",
      "[Epoch  1339] - training loss: nan, accuracy: nan\n",
      "[Epoch  1340] - training loss: nan, accuracy: nan\n",
      "[Epoch  1341] - training loss: nan, accuracy: nan\n",
      "[Epoch  1342] - training loss: nan, accuracy: nan\n",
      "[Epoch  1343] - training loss: nan, accuracy: nan\n",
      "[Epoch  1344] - training loss: nan, accuracy: nan\n",
      "[Epoch  1345] - training loss: nan, accuracy: nan\n",
      "[Epoch  1346] - training loss: nan, accuracy: nan\n",
      "[Epoch  1347] - training loss: nan, accuracy: nan\n",
      "[Epoch  1348] - training loss: nan, accuracy: nan\n",
      "[Epoch  1349] - training loss: nan, accuracy: nan\n",
      "[Epoch  1350] - training loss: nan, accuracy: nan\n",
      "[Epoch  1351] - training loss: nan, accuracy: nan\n",
      "[Epoch  1352] - training loss: nan, accuracy: nan\n",
      "[Epoch  1353] - training loss: nan, accuracy: nan\n",
      "[Epoch  1354] - training loss: nan, accuracy: nan\n",
      "[Epoch  1355] - training loss: nan, accuracy: nan\n",
      "[Epoch  1356] - training loss: nan, accuracy: nan\n",
      "[Epoch  1357] - training loss: nan, accuracy: nan\n",
      "[Epoch  1358] - training loss: nan, accuracy: nan\n",
      "[Epoch  1359] - training loss: nan, accuracy: nan\n",
      "[Epoch  1360] - training loss: nan, accuracy: nan\n",
      "[Epoch  1361] - training loss: nan, accuracy: nan\n",
      "[Epoch  1362] - training loss: nan, accuracy: nan\n",
      "[Epoch  1363] - training loss: nan, accuracy: nan\n",
      "[Epoch  1364] - training loss: nan, accuracy: nan\n",
      "[Epoch  1365] - training loss: nan, accuracy: nan\n",
      "[Epoch  1366] - training loss: nan, accuracy: nan\n",
      "[Epoch  1367] - training loss: nan, accuracy: nan\n",
      "[Epoch  1368] - training loss: nan, accuracy: nan\n",
      "[Epoch  1369] - training loss: nan, accuracy: nan\n",
      "[Epoch  1370] - training loss: nan, accuracy: nan\n",
      "[Epoch  1371] - training loss: nan, accuracy: nan\n",
      "[Epoch  1372] - training loss: nan, accuracy: nan\n",
      "[Epoch  1373] - training loss: nan, accuracy: nan\n",
      "[Epoch  1374] - training loss: nan, accuracy: nan\n",
      "[Epoch  1375] - training loss: nan, accuracy: nan\n",
      "[Epoch  1376] - training loss: nan, accuracy: nan\n",
      "[Epoch  1377] - training loss: nan, accuracy: nan\n",
      "[Epoch  1378] - training loss: nan, accuracy: nan\n",
      "[Epoch  1379] - training loss: nan, accuracy: nan\n",
      "[Epoch  1380] - training loss: nan, accuracy: nan\n",
      "[Epoch  1381] - training loss: nan, accuracy: nan\n",
      "[Epoch  1382] - training loss: nan, accuracy: nan\n",
      "[Epoch  1383] - training loss: nan, accuracy: nan\n",
      "[Epoch  1384] - training loss: nan, accuracy: nan\n",
      "[Epoch  1385] - training loss: nan, accuracy: nan\n",
      "[Epoch  1386] - training loss: nan, accuracy: nan\n",
      "[Epoch  1387] - training loss: nan, accuracy: nan\n",
      "[Epoch  1388] - training loss: nan, accuracy: nan\n",
      "[Epoch  1389] - training loss: nan, accuracy: nan\n",
      "[Epoch  1390] - training loss: nan, accuracy: nan\n",
      "[Epoch  1391] - training loss: nan, accuracy: nan\n",
      "[Epoch  1392] - training loss: nan, accuracy: nan\n",
      "[Epoch  1393] - training loss: nan, accuracy: nan\n",
      "[Epoch  1394] - training loss: nan, accuracy: nan\n",
      "[Epoch  1395] - training loss: nan, accuracy: nan\n",
      "[Epoch  1396] - training loss: nan, accuracy: nan\n",
      "[Epoch  1397] - training loss: nan, accuracy: nan\n",
      "[Epoch  1398] - training loss: nan, accuracy: nan\n",
      "[Epoch  1399] - training loss: nan, accuracy: nan\n",
      "[Epoch  1400] - training loss: nan, accuracy: nan\n",
      "[Epoch  1401] - training loss: nan, accuracy: nan\n",
      "[Epoch  1402] - training loss: nan, accuracy: nan\n",
      "[Epoch  1403] - training loss: nan, accuracy: nan\n",
      "[Epoch  1404] - training loss: nan, accuracy: nan\n",
      "[Epoch  1405] - training loss: nan, accuracy: nan\n",
      "[Epoch  1406] - training loss: nan, accuracy: nan\n",
      "[Epoch  1407] - training loss: nan, accuracy: nan\n",
      "[Epoch  1408] - training loss: nan, accuracy: nan\n",
      "[Epoch  1409] - training loss: nan, accuracy: nan\n",
      "[Epoch  1410] - training loss: nan, accuracy: nan\n",
      "[Epoch  1411] - training loss: nan, accuracy: nan\n",
      "[Epoch  1412] - training loss: nan, accuracy: nan\n",
      "[Epoch  1413] - training loss: nan, accuracy: nan\n",
      "[Epoch  1414] - training loss: nan, accuracy: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  1415] - training loss: nan, accuracy: nan\n",
      "[Epoch  1416] - training loss: nan, accuracy: nan\n",
      "[Epoch  1417] - training loss: nan, accuracy: nan\n",
      "[Epoch  1418] - training loss: nan, accuracy: nan\n",
      "[Epoch  1419] - training loss: nan, accuracy: nan\n",
      "[Epoch  1420] - training loss: nan, accuracy: nan\n",
      "[Epoch  1421] - training loss: nan, accuracy: nan\n",
      "[Epoch  1422] - training loss: nan, accuracy: nan\n",
      "[Epoch  1423] - training loss: nan, accuracy: nan\n",
      "[Epoch  1424] - training loss: nan, accuracy: nan\n",
      "[Epoch  1425] - training loss: nan, accuracy: nan\n",
      "[Epoch  1426] - training loss: nan, accuracy: nan\n",
      "[Epoch  1427] - training loss: nan, accuracy: nan\n",
      "[Epoch  1428] - training loss: nan, accuracy: nan\n",
      "[Epoch  1429] - training loss: nan, accuracy: nan\n",
      "[Epoch  1430] - training loss: nan, accuracy: nan\n",
      "[Epoch  1431] - training loss: nan, accuracy: nan\n",
      "[Epoch  1432] - training loss: nan, accuracy: nan\n",
      "[Epoch  1433] - training loss: nan, accuracy: nan\n",
      "[Epoch  1434] - training loss: nan, accuracy: nan\n",
      "[Epoch  1435] - training loss: nan, accuracy: nan\n",
      "[Epoch  1436] - training loss: nan, accuracy: nan\n",
      "[Epoch  1437] - training loss: nan, accuracy: nan\n",
      "[Epoch  1438] - training loss: nan, accuracy: nan\n",
      "[Epoch  1439] - training loss: nan, accuracy: nan\n",
      "[Epoch  1440] - training loss: nan, accuracy: nan\n",
      "[Epoch  1441] - training loss: nan, accuracy: nan\n",
      "[Epoch  1442] - training loss: nan, accuracy: nan\n",
      "[Epoch  1443] - training loss: nan, accuracy: nan\n",
      "[Epoch  1444] - training loss: nan, accuracy: nan\n",
      "[Epoch  1445] - training loss: nan, accuracy: nan\n",
      "[Epoch  1446] - training loss: nan, accuracy: nan\n",
      "[Epoch  1447] - training loss: nan, accuracy: nan\n",
      "[Epoch  1448] - training loss: nan, accuracy: nan\n",
      "[Epoch  1449] - training loss: nan, accuracy: nan\n",
      "[Epoch  1450] - training loss: nan, accuracy: nan\n",
      "[Epoch  1451] - training loss: nan, accuracy: nan\n",
      "[Epoch  1452] - training loss: nan, accuracy: nan\n",
      "[Epoch  1453] - training loss: nan, accuracy: nan\n",
      "[Epoch  1454] - training loss: nan, accuracy: nan\n",
      "[Epoch  1455] - training loss: nan, accuracy: nan\n",
      "[Epoch  1456] - training loss: nan, accuracy: nan\n",
      "[Epoch  1457] - training loss: nan, accuracy: nan\n",
      "[Epoch  1458] - training loss: nan, accuracy: nan\n",
      "[Epoch  1459] - training loss: nan, accuracy: nan\n",
      "[Epoch  1460] - training loss: nan, accuracy: nan\n",
      "[Epoch  1461] - training loss: nan, accuracy: nan\n",
      "[Epoch  1462] - training loss: nan, accuracy: nan\n",
      "[Epoch  1463] - training loss: nan, accuracy: nan\n",
      "[Epoch  1464] - training loss: nan, accuracy: nan\n",
      "[Epoch  1465] - training loss: nan, accuracy: nan\n",
      "[Epoch  1466] - training loss: nan, accuracy: nan\n",
      "[Epoch  1467] - training loss: nan, accuracy: nan\n",
      "[Epoch  1468] - training loss: nan, accuracy: nan\n",
      "[Epoch  1469] - training loss: nan, accuracy: nan\n",
      "[Epoch  1470] - training loss: nan, accuracy: nan\n",
      "[Epoch  1471] - training loss: nan, accuracy: nan\n",
      "[Epoch  1472] - training loss: nan, accuracy: nan\n",
      "[Epoch  1473] - training loss: nan, accuracy: nan\n",
      "[Epoch  1474] - training loss: nan, accuracy: nan\n",
      "[Epoch  1475] - training loss: nan, accuracy: nan\n",
      "[Epoch  1476] - training loss: nan, accuracy: nan\n",
      "[Epoch  1477] - training loss: nan, accuracy: nan\n",
      "[Epoch  1478] - training loss: nan, accuracy: nan\n",
      "[Epoch  1479] - training loss: nan, accuracy: nan\n",
      "[Epoch  1480] - training loss: nan, accuracy: nan\n",
      "[Epoch  1481] - training loss: nan, accuracy: nan\n",
      "[Epoch  1482] - training loss: nan, accuracy: nan\n",
      "[Epoch  1483] - training loss: nan, accuracy: nan\n",
      "[Epoch  1484] - training loss: nan, accuracy: nan\n",
      "[Epoch  1485] - training loss: nan, accuracy: nan\n",
      "[Epoch  1486] - training loss: nan, accuracy: nan\n",
      "[Epoch  1487] - training loss: nan, accuracy: nan\n",
      "[Epoch  1488] - training loss: nan, accuracy: nan\n",
      "[Epoch  1489] - training loss: nan, accuracy: nan\n",
      "[Epoch  1490] - training loss: nan, accuracy: nan\n",
      "[Epoch  1491] - training loss: nan, accuracy: nan\n",
      "[Epoch  1492] - training loss: nan, accuracy: nan\n",
      "[Epoch  1493] - training loss: nan, accuracy: nan\n",
      "[Epoch  1494] - training loss: nan, accuracy: nan\n",
      "[Epoch  1495] - training loss: nan, accuracy: nan\n",
      "[Epoch  1496] - training loss: nan, accuracy: nan\n",
      "[Epoch  1497] - training loss: nan, accuracy: nan\n",
      "[Epoch  1498] - training loss: nan, accuracy: nan\n",
      "[Epoch  1499] - training loss: nan, accuracy: nan\n",
      "[Epoch  1500] - training loss: nan, accuracy: nan\n",
      "[Epoch  1501] - training loss: nan, accuracy: nan\n",
      "[Epoch  1502] - training loss: nan, accuracy: nan\n",
      "[Epoch  1503] - training loss: nan, accuracy: nan\n",
      "[Epoch  1504] - training loss: nan, accuracy: nan\n",
      "[Epoch  1505] - training loss: nan, accuracy: nan\n",
      "[Epoch  1506] - training loss: nan, accuracy: nan\n",
      "[Epoch  1507] - training loss: nan, accuracy: nan\n",
      "[Epoch  1508] - training loss: nan, accuracy: nan\n",
      "[Epoch  1509] - training loss: nan, accuracy: nan\n",
      "[Epoch  1510] - training loss: nan, accuracy: nan\n",
      "[Epoch  1511] - training loss: nan, accuracy: nan\n",
      "[Epoch  1512] - training loss: nan, accuracy: nan\n",
      "[Epoch  1513] - training loss: nan, accuracy: nan\n",
      "[Epoch  1514] - training loss: nan, accuracy: nan\n",
      "[Epoch  1515] - training loss: nan, accuracy: nan\n",
      "[Epoch  1516] - training loss: nan, accuracy: nan\n",
      "[Epoch  1517] - training loss: nan, accuracy: nan\n",
      "[Epoch  1518] - training loss: nan, accuracy: nan\n",
      "[Epoch  1519] - training loss: nan, accuracy: nan\n",
      "[Epoch  1520] - training loss: nan, accuracy: nan\n",
      "[Epoch  1521] - training loss: nan, accuracy: nan\n",
      "[Epoch  1522] - training loss: nan, accuracy: nan\n",
      "[Epoch  1523] - training loss: nan, accuracy: nan\n",
      "[Epoch  1524] - training loss: nan, accuracy: nan\n",
      "[Epoch  1525] - training loss: nan, accuracy: nan\n",
      "[Epoch  1526] - training loss: nan, accuracy: nan\n",
      "[Epoch  1527] - training loss: nan, accuracy: nan\n",
      "[Epoch  1528] - training loss: nan, accuracy: nan\n",
      "[Epoch  1529] - training loss: nan, accuracy: nan\n",
      "[Epoch  1530] - training loss: nan, accuracy: nan\n",
      "[Epoch  1531] - training loss: nan, accuracy: nan\n",
      "[Epoch  1532] - training loss: nan, accuracy: nan\n",
      "[Epoch  1533] - training loss: nan, accuracy: nan\n",
      "[Epoch  1534] - training loss: nan, accuracy: nan\n",
      "[Epoch  1535] - training loss: nan, accuracy: nan\n",
      "[Epoch  1536] - training loss: nan, accuracy: nan\n",
      "[Epoch  1537] - training loss: nan, accuracy: nan\n",
      "[Epoch  1538] - training loss: nan, accuracy: nan\n",
      "[Epoch  1539] - training loss: nan, accuracy: nan\n",
      "[Epoch  1540] - training loss: nan, accuracy: nan\n",
      "[Epoch  1541] - training loss: nan, accuracy: nan\n",
      "[Epoch  1542] - training loss: nan, accuracy: nan\n",
      "[Epoch  1543] - training loss: nan, accuracy: nan\n",
      "[Epoch  1544] - training loss: nan, accuracy: nan\n",
      "[Epoch  1545] - training loss: nan, accuracy: nan\n",
      "[Epoch  1546] - training loss: nan, accuracy: nan\n",
      "[Epoch  1547] - training loss: nan, accuracy: nan\n",
      "[Epoch  1548] - training loss: nan, accuracy: nan\n",
      "[Epoch  1549] - training loss: nan, accuracy: nan\n",
      "[Epoch  1550] - training loss: nan, accuracy: nan\n",
      "[Epoch  1551] - training loss: nan, accuracy: nan\n",
      "[Epoch  1552] - training loss: nan, accuracy: nan\n",
      "[Epoch  1553] - training loss: nan, accuracy: nan\n",
      "[Epoch  1554] - training loss: nan, accuracy: nan\n",
      "[Epoch  1555] - training loss: nan, accuracy: nan\n",
      "[Epoch  1556] - training loss: nan, accuracy: nan\n",
      "[Epoch  1557] - training loss: nan, accuracy: nan\n",
      "[Epoch  1558] - training loss: nan, accuracy: nan\n",
      "[Epoch  1559] - training loss: nan, accuracy: nan\n",
      "[Epoch  1560] - training loss: nan, accuracy: nan\n",
      "[Epoch  1561] - training loss: nan, accuracy: nan\n",
      "[Epoch  1562] - training loss: nan, accuracy: nan\n",
      "[Epoch  1563] - training loss: nan, accuracy: nan\n",
      "[Epoch  1564] - training loss: nan, accuracy: nan\n",
      "[Epoch  1565] - training loss: nan, accuracy: nan\n",
      "[Epoch  1566] - training loss: nan, accuracy: nan\n",
      "[Epoch  1567] - training loss: nan, accuracy: nan\n",
      "[Epoch  1568] - training loss: nan, accuracy: nan\n",
      "[Epoch  1569] - training loss: nan, accuracy: nan\n",
      "[Epoch  1570] - training loss: nan, accuracy: nan\n",
      "[Epoch  1571] - training loss: nan, accuracy: nan\n",
      "[Epoch  1572] - training loss: nan, accuracy: nan\n",
      "[Epoch  1573] - training loss: nan, accuracy: nan\n",
      "[Epoch  1574] - training loss: nan, accuracy: nan\n",
      "[Epoch  1575] - training loss: nan, accuracy: nan\n",
      "[Epoch  1576] - training loss: nan, accuracy: nan\n",
      "[Epoch  1577] - training loss: nan, accuracy: nan\n",
      "[Epoch  1578] - training loss: nan, accuracy: nan\n",
      "[Epoch  1579] - training loss: nan, accuracy: nan\n",
      "[Epoch  1580] - training loss: nan, accuracy: nan\n",
      "[Epoch  1581] - training loss: nan, accuracy: nan\n",
      "[Epoch  1582] - training loss: nan, accuracy: nan\n",
      "[Epoch  1583] - training loss: nan, accuracy: nan\n",
      "[Epoch  1584] - training loss: nan, accuracy: nan\n",
      "[Epoch  1585] - training loss: nan, accuracy: nan\n",
      "[Epoch  1586] - training loss: nan, accuracy: nan\n",
      "[Epoch  1587] - training loss: nan, accuracy: nan\n",
      "[Epoch  1588] - training loss: nan, accuracy: nan\n",
      "[Epoch  1589] - training loss: nan, accuracy: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  1590] - training loss: nan, accuracy: nan\n",
      "[Epoch  1591] - training loss: nan, accuracy: nan\n",
      "[Epoch  1592] - training loss: nan, accuracy: nan\n",
      "[Epoch  1593] - training loss: nan, accuracy: nan\n",
      "[Epoch  1594] - training loss: nan, accuracy: nan\n",
      "[Epoch  1595] - training loss: nan, accuracy: nan\n",
      "[Epoch  1596] - training loss: nan, accuracy: nan\n",
      "[Epoch  1597] - training loss: nan, accuracy: nan\n",
      "[Epoch  1598] - training loss: nan, accuracy: nan\n",
      "[Epoch  1599] - training loss: nan, accuracy: nan\n",
      "[Epoch  1600] - training loss: nan, accuracy: nan\n",
      "[Epoch  1601] - training loss: nan, accuracy: nan\n",
      "[Epoch  1602] - training loss: nan, accuracy: nan\n",
      "[Epoch  1603] - training loss: nan, accuracy: nan\n",
      "[Epoch  1604] - training loss: nan, accuracy: nan\n",
      "[Epoch  1605] - training loss: nan, accuracy: nan\n",
      "[Epoch  1606] - training loss: nan, accuracy: nan\n",
      "[Epoch  1607] - training loss: nan, accuracy: nan\n",
      "[Epoch  1608] - training loss: nan, accuracy: nan\n",
      "[Epoch  1609] - training loss: nan, accuracy: nan\n",
      "[Epoch  1610] - training loss: nan, accuracy: nan\n",
      "[Epoch  1611] - training loss: nan, accuracy: nan\n",
      "[Epoch  1612] - training loss: nan, accuracy: nan\n",
      "[Epoch  1613] - training loss: nan, accuracy: nan\n",
      "[Epoch  1614] - training loss: nan, accuracy: nan\n",
      "[Epoch  1615] - training loss: nan, accuracy: nan\n",
      "[Epoch  1616] - training loss: nan, accuracy: nan\n",
      "[Epoch  1617] - training loss: nan, accuracy: nan\n",
      "[Epoch  1618] - training loss: nan, accuracy: nan\n",
      "[Epoch  1619] - training loss: nan, accuracy: nan\n",
      "[Epoch  1620] - training loss: nan, accuracy: nan\n",
      "[Epoch  1621] - training loss: nan, accuracy: nan\n",
      "[Epoch  1622] - training loss: nan, accuracy: nan\n",
      "[Epoch  1623] - training loss: nan, accuracy: nan\n",
      "[Epoch  1624] - training loss: nan, accuracy: nan\n",
      "[Epoch  1625] - training loss: nan, accuracy: nan\n",
      "[Epoch  1626] - training loss: nan, accuracy: nan\n",
      "[Epoch  1627] - training loss: nan, accuracy: nan\n",
      "[Epoch  1628] - training loss: nan, accuracy: nan\n",
      "[Epoch  1629] - training loss: nan, accuracy: nan\n",
      "[Epoch  1630] - training loss: nan, accuracy: nan\n",
      "[Epoch  1631] - training loss: nan, accuracy: nan\n",
      "[Epoch  1632] - training loss: nan, accuracy: nan\n",
      "[Epoch  1633] - training loss: nan, accuracy: nan\n",
      "[Epoch  1634] - training loss: nan, accuracy: nan\n",
      "[Epoch  1635] - training loss: nan, accuracy: nan\n",
      "[Epoch  1636] - training loss: nan, accuracy: nan\n",
      "[Epoch  1637] - training loss: nan, accuracy: nan\n",
      "[Epoch  1638] - training loss: nan, accuracy: nan\n",
      "[Epoch  1639] - training loss: nan, accuracy: nan\n",
      "[Epoch  1640] - training loss: nan, accuracy: nan\n",
      "[Epoch  1641] - training loss: nan, accuracy: nan\n",
      "[Epoch  1642] - training loss: nan, accuracy: nan\n",
      "[Epoch  1643] - training loss: nan, accuracy: nan\n",
      "[Epoch  1644] - training loss: nan, accuracy: nan\n",
      "[Epoch  1645] - training loss: nan, accuracy: nan\n",
      "[Epoch  1646] - training loss: nan, accuracy: nan\n",
      "[Epoch  1647] - training loss: nan, accuracy: nan\n",
      "[Epoch  1648] - training loss: nan, accuracy: nan\n",
      "[Epoch  1649] - training loss: nan, accuracy: nan\n",
      "[Epoch  1650] - training loss: nan, accuracy: nan\n",
      "[Epoch  1651] - training loss: nan, accuracy: nan\n",
      "[Epoch  1652] - training loss: nan, accuracy: nan\n",
      "[Epoch  1653] - training loss: nan, accuracy: nan\n",
      "[Epoch  1654] - training loss: nan, accuracy: nan\n",
      "[Epoch  1655] - training loss: nan, accuracy: nan\n",
      "[Epoch  1656] - training loss: nan, accuracy: nan\n",
      "[Epoch  1657] - training loss: nan, accuracy: nan\n",
      "[Epoch  1658] - training loss: nan, accuracy: nan\n",
      "[Epoch  1659] - training loss: nan, accuracy: nan\n",
      "[Epoch  1660] - training loss: nan, accuracy: nan\n",
      "[Epoch  1661] - training loss: nan, accuracy: nan\n",
      "[Epoch  1662] - training loss: nan, accuracy: nan\n",
      "[Epoch  1663] - training loss: nan, accuracy: nan\n",
      "[Epoch  1664] - training loss: nan, accuracy: nan\n",
      "[Epoch  1665] - training loss: nan, accuracy: nan\n",
      "[Epoch  1666] - training loss: nan, accuracy: nan\n",
      "[Epoch  1667] - training loss: nan, accuracy: nan\n",
      "[Epoch  1668] - training loss: nan, accuracy: nan\n",
      "[Epoch  1669] - training loss: nan, accuracy: nan\n",
      "[Epoch  1670] - training loss: nan, accuracy: nan\n",
      "[Epoch  1671] - training loss: nan, accuracy: nan\n",
      "[Epoch  1672] - training loss: nan, accuracy: nan\n",
      "[Epoch  1673] - training loss: nan, accuracy: nan\n",
      "[Epoch  1674] - training loss: nan, accuracy: nan\n",
      "[Epoch  1675] - training loss: nan, accuracy: nan\n",
      "[Epoch  1676] - training loss: nan, accuracy: nan\n",
      "[Epoch  1677] - training loss: nan, accuracy: nan\n",
      "[Epoch  1678] - training loss: nan, accuracy: nan\n",
      "[Epoch  1679] - training loss: nan, accuracy: nan\n",
      "[Epoch  1680] - training loss: nan, accuracy: nan\n",
      "[Epoch  1681] - training loss: nan, accuracy: nan\n",
      "[Epoch  1682] - training loss: nan, accuracy: nan\n",
      "[Epoch  1683] - training loss: nan, accuracy: nan\n",
      "[Epoch  1684] - training loss: nan, accuracy: nan\n",
      "[Epoch  1685] - training loss: nan, accuracy: nan\n",
      "[Epoch  1686] - training loss: nan, accuracy: nan\n",
      "[Epoch  1687] - training loss: nan, accuracy: nan\n",
      "[Epoch  1688] - training loss: nan, accuracy: nan\n",
      "[Epoch  1689] - training loss: nan, accuracy: nan\n",
      "[Epoch  1690] - training loss: nan, accuracy: nan\n",
      "[Epoch  1691] - training loss: nan, accuracy: nan\n",
      "[Epoch  1692] - training loss: nan, accuracy: nan\n",
      "[Epoch  1693] - training loss: nan, accuracy: nan\n",
      "[Epoch  1694] - training loss: nan, accuracy: nan\n",
      "[Epoch  1695] - training loss: nan, accuracy: nan\n",
      "[Epoch  1696] - training loss: nan, accuracy: nan\n",
      "[Epoch  1697] - training loss: nan, accuracy: nan\n",
      "[Epoch  1698] - training loss: nan, accuracy: nan\n",
      "[Epoch  1699] - training loss: nan, accuracy: nan\n",
      "[Epoch  1700] - training loss: nan, accuracy: nan\n",
      "[Epoch  1701] - training loss: nan, accuracy: nan\n",
      "[Epoch  1702] - training loss: nan, accuracy: nan\n",
      "[Epoch  1703] - training loss: nan, accuracy: nan\n",
      "[Epoch  1704] - training loss: nan, accuracy: nan\n",
      "[Epoch  1705] - training loss: nan, accuracy: nan\n",
      "[Epoch  1706] - training loss: nan, accuracy: nan\n",
      "[Epoch  1707] - training loss: nan, accuracy: nan\n",
      "[Epoch  1708] - training loss: nan, accuracy: nan\n",
      "[Epoch  1709] - training loss: nan, accuracy: nan\n",
      "[Epoch  1710] - training loss: nan, accuracy: nan\n",
      "[Epoch  1711] - training loss: nan, accuracy: nan\n",
      "[Epoch  1712] - training loss: nan, accuracy: nan\n",
      "[Epoch  1713] - training loss: nan, accuracy: nan\n",
      "[Epoch  1714] - training loss: nan, accuracy: nan\n",
      "[Epoch  1715] - training loss: nan, accuracy: nan\n",
      "[Epoch  1716] - training loss: nan, accuracy: nan\n",
      "[Epoch  1717] - training loss: nan, accuracy: nan\n",
      "[Epoch  1718] - training loss: nan, accuracy: nan\n",
      "[Epoch  1719] - training loss: nan, accuracy: nan\n",
      "[Epoch  1720] - training loss: nan, accuracy: nan\n",
      "[Epoch  1721] - training loss: nan, accuracy: nan\n",
      "[Epoch  1722] - training loss: nan, accuracy: nan\n",
      "[Epoch  1723] - training loss: nan, accuracy: nan\n",
      "[Epoch  1724] - training loss: nan, accuracy: nan\n",
      "[Epoch  1725] - training loss: nan, accuracy: nan\n",
      "[Epoch  1726] - training loss: nan, accuracy: nan\n",
      "[Epoch  1727] - training loss: nan, accuracy: nan\n",
      "[Epoch  1728] - training loss: nan, accuracy: nan\n",
      "[Epoch  1729] - training loss: nan, accuracy: nan\n",
      "[Epoch  1730] - training loss: nan, accuracy: nan\n",
      "[Epoch  1731] - training loss: nan, accuracy: nan\n",
      "[Epoch  1732] - training loss: nan, accuracy: nan\n",
      "[Epoch  1733] - training loss: nan, accuracy: nan\n",
      "[Epoch  1734] - training loss: nan, accuracy: nan\n",
      "[Epoch  1735] - training loss: nan, accuracy: nan\n",
      "[Epoch  1736] - training loss: nan, accuracy: nan\n",
      "[Epoch  1737] - training loss: nan, accuracy: nan\n",
      "[Epoch  1738] - training loss: nan, accuracy: nan\n",
      "[Epoch  1739] - training loss: nan, accuracy: nan\n",
      "[Epoch  1740] - training loss: nan, accuracy: nan\n",
      "[Epoch  1741] - training loss: nan, accuracy: nan\n",
      "[Epoch  1742] - training loss: nan, accuracy: nan\n",
      "[Epoch  1743] - training loss: nan, accuracy: nan\n",
      "[Epoch  1744] - training loss: nan, accuracy: nan\n",
      "[Epoch  1745] - training loss: nan, accuracy: nan\n",
      "[Epoch  1746] - training loss: nan, accuracy: nan\n",
      "[Epoch  1747] - training loss: nan, accuracy: nan\n",
      "[Epoch  1748] - training loss: nan, accuracy: nan\n",
      "[Epoch  1749] - training loss: nan, accuracy: nan\n",
      "[Epoch  1750] - training loss: nan, accuracy: nan\n",
      "[Epoch  1751] - training loss: nan, accuracy: nan\n",
      "[Epoch  1752] - training loss: nan, accuracy: nan\n",
      "[Epoch  1753] - training loss: nan, accuracy: nan\n",
      "[Epoch  1754] - training loss: nan, accuracy: nan\n",
      "[Epoch  1755] - training loss: nan, accuracy: nan\n",
      "[Epoch  1756] - training loss: nan, accuracy: nan\n",
      "[Epoch  1757] - training loss: nan, accuracy: nan\n",
      "[Epoch  1758] - training loss: nan, accuracy: nan\n",
      "[Epoch  1759] - training loss: nan, accuracy: nan\n",
      "[Epoch  1760] - training loss: nan, accuracy: nan\n",
      "[Epoch  1761] - training loss: nan, accuracy: nan\n",
      "[Epoch  1762] - training loss: nan, accuracy: nan\n",
      "[Epoch  1763] - training loss: nan, accuracy: nan\n",
      "[Epoch  1764] - training loss: nan, accuracy: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  1765] - training loss: nan, accuracy: nan\n",
      "[Epoch  1766] - training loss: nan, accuracy: nan\n",
      "[Epoch  1767] - training loss: nan, accuracy: nan\n",
      "[Epoch  1768] - training loss: nan, accuracy: nan\n",
      "[Epoch  1769] - training loss: nan, accuracy: nan\n",
      "[Epoch  1770] - training loss: nan, accuracy: nan\n",
      "[Epoch  1771] - training loss: nan, accuracy: nan\n",
      "[Epoch  1772] - training loss: nan, accuracy: nan\n",
      "[Epoch  1773] - training loss: nan, accuracy: nan\n",
      "[Epoch  1774] - training loss: nan, accuracy: nan\n",
      "[Epoch  1775] - training loss: nan, accuracy: nan\n",
      "[Epoch  1776] - training loss: nan, accuracy: nan\n",
      "[Epoch  1777] - training loss: nan, accuracy: nan\n",
      "[Epoch  1778] - training loss: nan, accuracy: nan\n",
      "[Epoch  1779] - training loss: nan, accuracy: nan\n",
      "[Epoch  1780] - training loss: nan, accuracy: nan\n",
      "[Epoch  1781] - training loss: nan, accuracy: nan\n",
      "[Epoch  1782] - training loss: nan, accuracy: nan\n",
      "[Epoch  1783] - training loss: nan, accuracy: nan\n",
      "[Epoch  1784] - training loss: nan, accuracy: nan\n",
      "[Epoch  1785] - training loss: nan, accuracy: nan\n",
      "[Epoch  1786] - training loss: nan, accuracy: nan\n",
      "[Epoch  1787] - training loss: nan, accuracy: nan\n",
      "[Epoch  1788] - training loss: nan, accuracy: nan\n",
      "[Epoch  1789] - training loss: nan, accuracy: nan\n",
      "[Epoch  1790] - training loss: nan, accuracy: nan\n",
      "[Epoch  1791] - training loss: nan, accuracy: nan\n",
      "[Epoch  1792] - training loss: nan, accuracy: nan\n",
      "[Epoch  1793] - training loss: nan, accuracy: nan\n",
      "[Epoch  1794] - training loss: nan, accuracy: nan\n",
      "[Epoch  1795] - training loss: nan, accuracy: nan\n",
      "[Epoch  1796] - training loss: nan, accuracy: nan\n",
      "[Epoch  1797] - training loss: nan, accuracy: nan\n",
      "[Epoch  1798] - training loss: nan, accuracy: nan\n",
      "[Epoch  1799] - training loss: nan, accuracy: nan\n",
      "[Epoch  1800] - training loss: nan, accuracy: nan\n",
      "[Epoch  1801] - training loss: nan, accuracy: nan\n",
      "[Epoch  1802] - training loss: nan, accuracy: nan\n",
      "[Epoch  1803] - training loss: nan, accuracy: nan\n",
      "[Epoch  1804] - training loss: nan, accuracy: nan\n",
      "[Epoch  1805] - training loss: nan, accuracy: nan\n",
      "[Epoch  1806] - training loss: nan, accuracy: nan\n",
      "[Epoch  1807] - training loss: nan, accuracy: nan\n",
      "[Epoch  1808] - training loss: nan, accuracy: nan\n",
      "[Epoch  1809] - training loss: nan, accuracy: nan\n",
      "[Epoch  1810] - training loss: nan, accuracy: nan\n",
      "[Epoch  1811] - training loss: nan, accuracy: nan\n",
      "[Epoch  1812] - training loss: nan, accuracy: nan\n",
      "[Epoch  1813] - training loss: nan, accuracy: nan\n",
      "[Epoch  1814] - training loss: nan, accuracy: nan\n",
      "[Epoch  1815] - training loss: nan, accuracy: nan\n",
      "[Epoch  1816] - training loss: nan, accuracy: nan\n",
      "[Epoch  1817] - training loss: nan, accuracy: nan\n",
      "[Epoch  1818] - training loss: nan, accuracy: nan\n",
      "[Epoch  1819] - training loss: nan, accuracy: nan\n",
      "[Epoch  1820] - training loss: nan, accuracy: nan\n",
      "[Epoch  1821] - training loss: nan, accuracy: nan\n",
      "[Epoch  1822] - training loss: nan, accuracy: nan\n",
      "[Epoch  1823] - training loss: nan, accuracy: nan\n",
      "[Epoch  1824] - training loss: nan, accuracy: nan\n",
      "[Epoch  1825] - training loss: nan, accuracy: nan\n",
      "[Epoch  1826] - training loss: nan, accuracy: nan\n",
      "[Epoch  1827] - training loss: nan, accuracy: nan\n",
      "[Epoch  1828] - training loss: nan, accuracy: nan\n",
      "[Epoch  1829] - training loss: nan, accuracy: nan\n",
      "[Epoch  1830] - training loss: nan, accuracy: nan\n",
      "[Epoch  1831] - training loss: nan, accuracy: nan\n",
      "[Epoch  1832] - training loss: nan, accuracy: nan\n",
      "[Epoch  1833] - training loss: nan, accuracy: nan\n",
      "[Epoch  1834] - training loss: nan, accuracy: nan\n",
      "[Epoch  1835] - training loss: nan, accuracy: nan\n",
      "[Epoch  1836] - training loss: nan, accuracy: nan\n",
      "[Epoch  1837] - training loss: nan, accuracy: nan\n",
      "[Epoch  1838] - training loss: nan, accuracy: nan\n",
      "[Epoch  1839] - training loss: nan, accuracy: nan\n",
      "[Epoch  1840] - training loss: nan, accuracy: nan\n",
      "[Epoch  1841] - training loss: nan, accuracy: nan\n",
      "[Epoch  1842] - training loss: nan, accuracy: nan\n",
      "[Epoch  1843] - training loss: nan, accuracy: nan\n",
      "[Epoch  1844] - training loss: nan, accuracy: nan\n",
      "[Epoch  1845] - training loss: nan, accuracy: nan\n",
      "[Epoch  1846] - training loss: nan, accuracy: nan\n",
      "[Epoch  1847] - training loss: nan, accuracy: nan\n",
      "[Epoch  1848] - training loss: nan, accuracy: nan\n",
      "[Epoch  1849] - training loss: nan, accuracy: nan\n",
      "[Epoch  1850] - training loss: nan, accuracy: nan\n",
      "[Epoch  1851] - training loss: nan, accuracy: nan\n",
      "[Epoch  1852] - training loss: nan, accuracy: nan\n",
      "[Epoch  1853] - training loss: nan, accuracy: nan\n",
      "[Epoch  1854] - training loss: nan, accuracy: nan\n",
      "[Epoch  1855] - training loss: nan, accuracy: nan\n",
      "[Epoch  1856] - training loss: nan, accuracy: nan\n",
      "[Epoch  1857] - training loss: nan, accuracy: nan\n",
      "[Epoch  1858] - training loss: nan, accuracy: nan\n",
      "[Epoch  1859] - training loss: nan, accuracy: nan\n",
      "[Epoch  1860] - training loss: nan, accuracy: nan\n",
      "[Epoch  1861] - training loss: nan, accuracy: nan\n",
      "[Epoch  1862] - training loss: nan, accuracy: nan\n",
      "[Epoch  1863] - training loss: nan, accuracy: nan\n",
      "[Epoch  1864] - training loss: nan, accuracy: nan\n",
      "[Epoch  1865] - training loss: nan, accuracy: nan\n",
      "[Epoch  1866] - training loss: nan, accuracy: nan\n",
      "[Epoch  1867] - training loss: nan, accuracy: nan\n",
      "[Epoch  1868] - training loss: nan, accuracy: nan\n",
      "[Epoch  1869] - training loss: nan, accuracy: nan\n",
      "[Epoch  1870] - training loss: nan, accuracy: nan\n",
      "[Epoch  1871] - training loss: nan, accuracy: nan\n",
      "[Epoch  1872] - training loss: nan, accuracy: nan\n",
      "[Epoch  1873] - training loss: nan, accuracy: nan\n",
      "[Epoch  1874] - training loss: nan, accuracy: nan\n",
      "[Epoch  1875] - training loss: nan, accuracy: nan\n",
      "[Epoch  1876] - training loss: nan, accuracy: nan\n",
      "[Epoch  1877] - training loss: nan, accuracy: nan\n",
      "[Epoch  1878] - training loss: nan, accuracy: nan\n",
      "[Epoch  1879] - training loss: nan, accuracy: nan\n",
      "[Epoch  1880] - training loss: nan, accuracy: nan\n",
      "[Epoch  1881] - training loss: nan, accuracy: nan\n",
      "[Epoch  1882] - training loss: nan, accuracy: nan\n",
      "[Epoch  1883] - training loss: nan, accuracy: nan\n",
      "[Epoch  1884] - training loss: nan, accuracy: nan\n",
      "[Epoch  1885] - training loss: nan, accuracy: nan\n",
      "[Epoch  1886] - training loss: nan, accuracy: nan\n",
      "[Epoch  1887] - training loss: nan, accuracy: nan\n",
      "[Epoch  1888] - training loss: nan, accuracy: nan\n",
      "[Epoch  1889] - training loss: nan, accuracy: nan\n",
      "[Epoch  1890] - training loss: nan, accuracy: nan\n",
      "[Epoch  1891] - training loss: nan, accuracy: nan\n",
      "[Epoch  1892] - training loss: nan, accuracy: nan\n",
      "[Epoch  1893] - training loss: nan, accuracy: nan\n",
      "[Epoch  1894] - training loss: nan, accuracy: nan\n",
      "[Epoch  1895] - training loss: nan, accuracy: nan\n",
      "[Epoch  1896] - training loss: nan, accuracy: nan\n",
      "[Epoch  1897] - training loss: nan, accuracy: nan\n",
      "[Epoch  1898] - training loss: nan, accuracy: nan\n",
      "[Epoch  1899] - training loss: nan, accuracy: nan\n",
      "[Epoch  1900] - training loss: nan, accuracy: nan\n",
      "[Epoch  1901] - training loss: nan, accuracy: nan\n",
      "[Epoch  1902] - training loss: nan, accuracy: nan\n",
      "[Epoch  1903] - training loss: nan, accuracy: nan\n",
      "[Epoch  1904] - training loss: nan, accuracy: nan\n",
      "[Epoch  1905] - training loss: nan, accuracy: nan\n",
      "[Epoch  1906] - training loss: nan, accuracy: nan\n",
      "[Epoch  1907] - training loss: nan, accuracy: nan\n",
      "[Epoch  1908] - training loss: nan, accuracy: nan\n",
      "[Epoch  1909] - training loss: nan, accuracy: nan\n",
      "[Epoch  1910] - training loss: nan, accuracy: nan\n",
      "[Epoch  1911] - training loss: nan, accuracy: nan\n",
      "[Epoch  1912] - training loss: nan, accuracy: nan\n",
      "[Epoch  1913] - training loss: nan, accuracy: nan\n",
      "[Epoch  1914] - training loss: nan, accuracy: nan\n",
      "[Epoch  1915] - training loss: nan, accuracy: nan\n",
      "[Epoch  1916] - training loss: nan, accuracy: nan\n",
      "[Epoch  1917] - training loss: nan, accuracy: nan\n",
      "[Epoch  1918] - training loss: nan, accuracy: nan\n",
      "[Epoch  1919] - training loss: nan, accuracy: nan\n",
      "[Epoch  1920] - training loss: nan, accuracy: nan\n",
      "[Epoch  1921] - training loss: nan, accuracy: nan\n",
      "[Epoch  1922] - training loss: nan, accuracy: nan\n",
      "[Epoch  1923] - training loss: nan, accuracy: nan\n",
      "[Epoch  1924] - training loss: nan, accuracy: nan\n",
      "[Epoch  1925] - training loss: nan, accuracy: nan\n",
      "[Epoch  1926] - training loss: nan, accuracy: nan\n",
      "[Epoch  1927] - training loss: nan, accuracy: nan\n",
      "[Epoch  1928] - training loss: nan, accuracy: nan\n",
      "[Epoch  1929] - training loss: nan, accuracy: nan\n",
      "[Epoch  1930] - training loss: nan, accuracy: nan\n",
      "[Epoch  1931] - training loss: nan, accuracy: nan\n",
      "[Epoch  1932] - training loss: nan, accuracy: nan\n",
      "[Epoch  1933] - training loss: nan, accuracy: nan\n",
      "[Epoch  1934] - training loss: nan, accuracy: nan\n",
      "[Epoch  1935] - training loss: nan, accuracy: nan\n",
      "[Epoch  1936] - training loss: nan, accuracy: nan\n",
      "[Epoch  1937] - training loss: nan, accuracy: nan\n",
      "[Epoch  1938] - training loss: nan, accuracy: nan\n",
      "[Epoch  1939] - training loss: nan, accuracy: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  1940] - training loss: nan, accuracy: nan\n",
      "[Epoch  1941] - training loss: nan, accuracy: nan\n",
      "[Epoch  1942] - training loss: nan, accuracy: nan\n",
      "[Epoch  1943] - training loss: nan, accuracy: nan\n",
      "[Epoch  1944] - training loss: nan, accuracy: nan\n",
      "[Epoch  1945] - training loss: nan, accuracy: nan\n",
      "[Epoch  1946] - training loss: nan, accuracy: nan\n",
      "[Epoch  1947] - training loss: nan, accuracy: nan\n",
      "[Epoch  1948] - training loss: nan, accuracy: nan\n",
      "[Epoch  1949] - training loss: nan, accuracy: nan\n",
      "[Epoch  1950] - training loss: nan, accuracy: nan\n",
      "[Epoch  1951] - training loss: nan, accuracy: nan\n",
      "[Epoch  1952] - training loss: nan, accuracy: nan\n",
      "[Epoch  1953] - training loss: nan, accuracy: nan\n",
      "[Epoch  1954] - training loss: nan, accuracy: nan\n",
      "[Epoch  1955] - training loss: nan, accuracy: nan\n",
      "[Epoch  1956] - training loss: nan, accuracy: nan\n",
      "[Epoch  1957] - training loss: nan, accuracy: nan\n",
      "[Epoch  1958] - training loss: nan, accuracy: nan\n",
      "[Epoch  1959] - training loss: nan, accuracy: nan\n",
      "[Epoch  1960] - training loss: nan, accuracy: nan\n",
      "[Epoch  1961] - training loss: nan, accuracy: nan\n",
      "[Epoch  1962] - training loss: nan, accuracy: nan\n",
      "[Epoch  1963] - training loss: nan, accuracy: nan\n",
      "[Epoch  1964] - training loss: nan, accuracy: nan\n",
      "[Epoch  1965] - training loss: nan, accuracy: nan\n",
      "[Epoch  1966] - training loss: nan, accuracy: nan\n",
      "[Epoch  1967] - training loss: nan, accuracy: nan\n",
      "[Epoch  1968] - training loss: nan, accuracy: nan\n",
      "[Epoch  1969] - training loss: nan, accuracy: nan\n",
      "[Epoch  1970] - training loss: nan, accuracy: nan\n",
      "[Epoch  1971] - training loss: nan, accuracy: nan\n",
      "[Epoch  1972] - training loss: nan, accuracy: nan\n",
      "[Epoch  1973] - training loss: nan, accuracy: nan\n",
      "[Epoch  1974] - training loss: nan, accuracy: nan\n",
      "[Epoch  1975] - training loss: nan, accuracy: nan\n",
      "[Epoch  1976] - training loss: nan, accuracy: nan\n",
      "[Epoch  1977] - training loss: nan, accuracy: nan\n",
      "[Epoch  1978] - training loss: nan, accuracy: nan\n",
      "[Epoch  1979] - training loss: nan, accuracy: nan\n",
      "[Epoch  1980] - training loss: nan, accuracy: nan\n",
      "[Epoch  1981] - training loss: nan, accuracy: nan\n",
      "[Epoch  1982] - training loss: nan, accuracy: nan\n",
      "[Epoch  1983] - training loss: nan, accuracy: nan\n",
      "[Epoch  1984] - training loss: nan, accuracy: nan\n",
      "[Epoch  1985] - training loss: nan, accuracy: nan\n",
      "[Epoch  1986] - training loss: nan, accuracy: nan\n",
      "[Epoch  1987] - training loss: nan, accuracy: nan\n",
      "[Epoch  1988] - training loss: nan, accuracy: nan\n",
      "[Epoch  1989] - training loss: nan, accuracy: nan\n",
      "[Epoch  1990] - training loss: nan, accuracy: nan\n",
      "[Epoch  1991] - training loss: nan, accuracy: nan\n",
      "[Epoch  1992] - training loss: nan, accuracy: nan\n",
      "[Epoch  1993] - training loss: nan, accuracy: nan\n",
      "[Epoch  1994] - training loss: nan, accuracy: nan\n",
      "[Epoch  1995] - training loss: nan, accuracy: nan\n",
      "[Epoch  1996] - training loss: nan, accuracy: nan\n",
      "[Epoch  1997] - training loss: nan, accuracy: nan\n",
      "[Epoch  1998] - training loss: nan, accuracy: nan\n",
      "[Epoch  1999] - training loss: nan, accuracy: nan\n",
      "[Epoch  2000] - training loss: nan, accuracy: nan\n"
     ]
    }
   ],
   "source": [
    "model = Logistic_Regression()\n",
    "model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
