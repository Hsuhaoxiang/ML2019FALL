{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'X_train' does not exist: b'X_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-879cb4e5099a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_test\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'X_train' does not exist: b'X_train'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "X = pd.read_csv(\"X_train\",low_memory=False)\n",
    "\n",
    "X_test = pd.read_csv(\"X_test\",low_memory=False)\n",
    "X=np.array(X,dtype = float)\n",
    "X_test = np.array(X_test,dtype = float)\n",
    "\n",
    "\n",
    "\n",
    "X_mean = np.mean(X,axis =0,keepdims = True)\n",
    "X_std = np.std(X,axis = 0,keepdims = True)\n",
    "\n",
    "X = (X-X_mean)/X_std\n",
    "X_test = (X_test-X_mean)/X_std\n",
    "\n",
    "Y = pd.read_csv(\"Y_train\",low_memory=False)\n",
    "Y = np.array(Y,dtype = float)\n",
    "bias = np.ones((32561,1))\n",
    "biastest = np.ones((16281,1))\n",
    "X = np.concatenate((X,bias),axis = 1)\n",
    "X_test = np.concatenate((X_test,biastest),axis = 1)\n",
    "print(\"X_shape:\",X.shape,\"\\nY_shape:\",Y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_regression():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def _init_para(self):\n",
    "        self.W =np.ones((107,1))\n",
    "        \n",
    "    def fit(self, X, Y, valid=None, max_epoch=2000, lr=0.000001):\n",
    "        assert X.shape[0] == Y.shape[0]\n",
    "        self._init_para()\n",
    "\n",
    "        for epoch in range(1, max_epoch+1):\n",
    "            \n",
    "            W_grad = -np.dot(X.T,(Y-self.predict(X)))\n",
    "            #print(W_grad.shape)\n",
    "            self.W = self.W -(lr*W_grad)\n",
    "            #print(self.W)\n",
    "\n",
    "            if epoch%100==0:\n",
    "                training_loss = self.loss(X,Y)\n",
    "                #accuracy = self.evaluate(X,Y)\n",
    "                print('[Epoch%5d] - training loss: %5f'%(epoch, training_loss))\n",
    "            \n",
    "    def sigmod(self,z):#   sigmod(z) = 1/(1+e^-z)\n",
    "        return 1/(1+np.exp(-z+0.00000000001))\n",
    "    \n",
    "    def predict(self, X, test=False):\n",
    "        return self.sigmod(np.dot(X,self.W))\n",
    "\n",
    "    def loss(self, X, Y, pred=None):\n",
    "        predict_value = self.predict(X)\n",
    "        return -np.sum(Y*np.log(predict_value+0.00000000001)+(1-Y)*(np.log(1-predict_value+0.00000000001)))\n",
    "\n",
    "\n",
    "    def evaluate(self, X, Y):\n",
    "        pred=self.predict(X)\n",
    "        for i in range(len(pred)):\n",
    "            if pred[i]>=0.5:\n",
    "                pred[i] = 1\n",
    "            else:\n",
    "                pred[i] =0\n",
    "            return np.mean(1-np.abs(pred-Y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  100] - training loss: 49461.490985\n",
      "[Epoch  200] - training loss: 34861.873531\n",
      "[Epoch  300] - training loss: 26246.406711\n",
      "[Epoch  400] - training loss: 21087.937325\n",
      "[Epoch  500] - training loss: 18098.638756\n",
      "[Epoch  600] - training loss: 16220.007544\n",
      "[Epoch  700] - training loss: 14912.858727\n",
      "[Epoch  800] - training loss: 13944.096320\n",
      "[Epoch  900] - training loss: 13174.891010\n",
      "[Epoch 1000] - training loss: 12560.356696\n",
      "[Epoch 1100] - training loss: 12080.282724\n",
      "[Epoch 1200] - training loss: 11695.043819\n",
      "[Epoch 1300] - training loss: 11387.599953\n",
      "[Epoch 1400] - training loss: 11150.349846\n",
      "[Epoch 1500] - training loss: 10960.058786\n",
      "[Epoch 1600] - training loss: 10803.977335\n",
      "[Epoch 1700] - training loss: 10677.832307\n",
      "[Epoch 1800] - training loss: 10576.973986\n",
      "[Epoch 1900] - training loss: 10502.608172\n",
      "[Epoch 2000] - training loss: 10461.658463\n",
      "[Epoch 2100] - training loss: 10440.505876\n",
      "[Epoch 2200] - training loss: 10426.717341\n",
      "[Epoch 2300] - training loss: 10416.048237\n",
      "[Epoch 2400] - training loss: 10407.107045\n",
      "[Epoch 2500] - training loss: 10399.348731\n",
      "[Epoch 2600] - training loss: 10392.508536\n",
      "[Epoch 2700] - training loss: 10386.429704\n",
      "[Epoch 2800] - training loss: 10381.004294\n",
      "[Epoch 2900] - training loss: 10376.149960\n",
      "[Epoch 3000] - training loss: 10371.799596\n",
      "[Epoch 3100] - training loss: 10367.896174\n",
      "[Epoch 3200] - training loss: 10364.389942\n",
      "[Epoch 3300] - training loss: 10361.236807\n",
      "[Epoch 3400] - training loss: 10358.397354\n",
      "[Epoch 3500] - training loss: 10355.836219\n",
      "[Epoch 3600] - training loss: 10353.521658\n",
      "[Epoch 3700] - training loss: 10351.425234\n",
      "[Epoch 3800] - training loss: 10349.521553\n",
      "[Epoch 3900] - training loss: 10347.788020\n",
      "[Epoch 4000] - training loss: 10346.204620\n",
      "[Epoch 4100] - training loss: 10344.753671\n",
      "[Epoch 4200] - training loss: 10343.418891\n",
      "[Epoch 4300] - training loss: 10342.168027\n",
      "[Epoch 4400] - training loss: 10340.610810\n",
      "[Epoch 4500] - training loss: 10337.264980\n",
      "[Epoch 4600] - training loss: 10333.089057\n",
      "[Epoch 4700] - training loss: 10328.914781\n",
      "[Epoch 4800] - training loss: 10324.795224\n",
      "[Epoch 4900] - training loss: 10320.726972\n",
      "[Epoch 5000] - training loss: 10316.707907\n",
      "[Epoch 5100] - training loss: 10312.805792\n",
      "[Epoch 5200] - training loss: 10309.865414\n",
      "[Epoch 5300] - training loss: 10308.580950\n",
      "[Epoch 5400] - training loss: 10307.798439\n",
      "[Epoch 5500] - training loss: 10307.141709\n",
      "[Epoch 5600] - training loss: 10306.542235\n",
      "[Epoch 5700] - training loss: 10305.980398\n",
      "[Epoch 5800] - training loss: 10305.447981\n",
      "[Epoch 5900] - training loss: 10304.940506\n",
      "[Epoch 6000] - training loss: 10304.455053\n",
      "[Epoch 6100] - training loss: 10303.989485\n",
      "[Epoch 6200] - training loss: 10303.542116\n",
      "[Epoch 6300] - training loss: 10303.111552\n",
      "[Epoch 6400] - training loss: 10302.696604\n",
      "[Epoch 6500] - training loss: 10302.296235\n",
      "[Epoch 6600] - training loss: 10301.909529\n",
      "[Epoch 6700] - training loss: 10301.535670\n",
      "[Epoch 6800] - training loss: 10301.173919\n",
      "[Epoch 6900] - training loss: 10300.823609\n",
      "[Epoch 7000] - training loss: 10300.484131\n",
      "[Epoch 7100] - training loss: 10300.154927\n",
      "[Epoch 7200] - training loss: 10299.835485\n",
      "[Epoch 7300] - training loss: 10299.525333\n",
      "[Epoch 7400] - training loss: 10299.224034\n",
      "[Epoch 7500] - training loss: 10298.931181\n",
      "[Epoch 7600] - training loss: 10298.646398\n",
      "[Epoch 7700] - training loss: 10298.369334\n",
      "[Epoch 7800] - training loss: 10298.099661\n",
      "[Epoch 7900] - training loss: 10297.837070\n",
      "[Epoch 8000] - training loss: 10297.581276\n",
      "[Epoch 8100] - training loss: 10297.332006\n",
      "[Epoch 8200] - training loss: 10297.089008\n",
      "[Epoch 8300] - training loss: 10296.852041\n",
      "[Epoch 8400] - training loss: 10296.620881\n",
      "[Epoch 8500] - training loss: 10296.395313\n",
      "[Epoch 8600] - training loss: 10296.175137\n",
      "[Epoch 8700] - training loss: 10295.960162\n",
      "[Epoch 8800] - training loss: 10295.750206\n",
      "[Epoch 8900] - training loss: 10295.545098\n",
      "[Epoch 9000] - training loss: 10295.344676\n",
      "[Epoch 9100] - training loss: 10295.148784\n",
      "[Epoch 9200] - training loss: 10294.957275\n",
      "[Epoch 9300] - training loss: 10294.770009\n",
      "[Epoch 9400] - training loss: 10294.586852\n",
      "[Epoch 9500] - training loss: 10294.407676\n",
      "[Epoch 9600] - training loss: 10294.232359\n",
      "[Epoch 9700] - training loss: 10294.060784\n",
      "[Epoch 9800] - training loss: 10293.892840\n",
      "[Epoch 9900] - training loss: 10293.728421\n",
      "[Epoch10000] - training loss: 10293.567423\n"
     ]
    }
   ],
   "source": [
    "model = logistic_regression()\n",
    "model.fit(X,Y,max_epoch = 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16281, 1)\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(predict.shape)\n",
    "for i in range(len(predict)):\n",
    "    if predict[i]<0.5:\n",
    "        predict[i] = 0\n",
    "    else:\n",
    "        predict[i] = 1\n",
    "predict =np.array(predict,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " with open('logistic_regression.csv', 'w') as f:\n",
    "        print('id,label', file=f)\n",
    "        for (i, p) in enumerate(predict) :\n",
    "            print('{},{}'.format(i+1, p[0]), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
