{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_path, label_path):\n",
    "    train_image = sorted(glob.glob(os.path.join(img_path, '*.jpg')))\n",
    "    train_label = pd.read_csv(label_path)\n",
    "    train_label = train_label.iloc[:,1].values.tolist()\n",
    "    \n",
    "    train_data = list(zip(train_image, train_label))\n",
    "    random.shuffle(train_data)\n",
    "    \n",
    "    train_set = train_data[:20000]\n",
    "    valid_set = train_data[20000:]\n",
    "    \n",
    "    return train_set, valid_set\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hw3_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data, transform):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.data[idx][0])\n",
    "        img = self.transform(img)\n",
    "        label = self.data[idx][1]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, padding=2),\n",
    "            nn.LeakyReLU(negative_slope=0.05),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2),     \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.05),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2),            \n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3,padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.05),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3,padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.05),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(3*3*128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 7)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #image size (48,48)\n",
    "        x = self.conv1(x) #(24,24)\n",
    "        x = self.conv2(x) #(12,12)\n",
    "        x = self.conv3(x) #(6,6)\n",
    "        x = self.conv4(x) #(3,3)\n",
    "        x = x.view(-1, 3*3*128)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model\n",
      "Epoch: 1, train Loss: 0.6642, train Acc: 0.8063\n",
      "Epoch: 1, valid Loss: 0.6971, valid Acc: 0.7879\n",
      "Epoch: 2, train Loss: 0.3471, train Acc: 0.8912\n",
      "Epoch: 2, valid Loss: 0.6882, valid Acc: 0.7965\n",
      "Epoch: 3, train Loss: 0.1779, train Acc: 0.9477\n",
      "Epoch: 3, valid Loss: 0.7841, valid Acc: 0.7872\n",
      "model saved to model_3.pth\n",
      "Epoch: 4, train Loss: 0.1011, train Acc: 0.9730\n",
      "Epoch: 4, valid Loss: 0.9268, valid Acc: 0.7586\n",
      "model saved to model_4.pth\n",
      "Epoch: 5, train Loss: 0.1029, train Acc: 0.9695\n",
      "Epoch: 5, valid Loss: 1.1556, valid Acc: 0.7230\n",
      "model saved to model_5.pth\n",
      "Epoch: 6, train Loss: 0.1406, train Acc: 0.9533\n",
      "Epoch: 6, valid Loss: 1.0881, valid Acc: 0.7305\n",
      "model saved to model_6.pth\n",
      "Epoch: 7, train Loss: 0.1417, train Acc: 0.9523\n",
      "Epoch: 7, valid Loss: 1.1121, valid Acc: 0.7305\n",
      "model saved to model_7.pth\n",
      "Epoch: 8, train Loss: 0.1052, train Acc: 0.9662\n",
      "Epoch: 8, valid Loss: 1.4067, valid Acc: 0.6786\n",
      "model saved to model_8.pth\n",
      "Epoch: 9, train Loss: 0.0653, train Acc: 0.9811\n",
      "Epoch: 9, valid Loss: 1.2023, valid Acc: 0.7302\n",
      "model saved to model_9.pth\n",
      "Epoch: 10, train Loss: 0.0429, train Acc: 0.9875\n",
      "Epoch: 10, valid Loss: 1.1732, valid Acc: 0.7379\n",
      "model saved to model_10.pth\n",
      "Epoch: 11, train Loss: 0.0315, train Acc: 0.9909\n",
      "Epoch: 11, valid Loss: 1.3096, valid Acc: 0.7229\n",
      "model saved to model_11.pth\n",
      "Epoch: 12, train Loss: 0.0570, train Acc: 0.9821\n",
      "Epoch: 12, valid Loss: 1.3816, valid Acc: 0.6989\n",
      "model saved to model_12.pth\n",
      "Epoch: 13, train Loss: 0.0705, train Acc: 0.9767\n",
      "Epoch: 13, valid Loss: 1.4403, valid Acc: 0.6951\n",
      "model saved to model_13.pth\n",
      "Epoch: 14, train Loss: 0.0990, train Acc: 0.9664\n",
      "Epoch: 14, valid Loss: 1.5816, valid Acc: 0.6666\n",
      "model saved to model_14.pth\n",
      "Epoch: 15, train Loss: 0.1670, train Acc: 0.9424\n",
      "Epoch: 15, valid Loss: 1.4014, valid Acc: 0.6919\n",
      "model saved to model_15.pth\n",
      "Epoch: 16, train Loss: 0.0646, train Acc: 0.9789\n",
      "Epoch: 16, valid Loss: 1.4092, valid Acc: 0.7013\n",
      "model saved to model_16.pth\n",
      "Epoch: 17, train Loss: 0.0297, train Acc: 0.9919\n",
      "Epoch: 17, valid Loss: 1.4101, valid Acc: 0.7055\n",
      "model saved to model_17.pth\n",
      "Epoch: 18, train Loss: 0.0163, train Acc: 0.9965\n",
      "Epoch: 18, valid Loss: 1.3827, valid Acc: 0.7098\n",
      "model saved to model_18.pth\n",
      "Epoch: 19, train Loss: 0.0093, train Acc: 0.9979\n",
      "Epoch: 19, valid Loss: 1.3709, valid Acc: 0.7167\n",
      "model saved to model_19.pth\n",
      "Epoch: 20, train Loss: 0.0226, train Acc: 0.9927\n",
      "Epoch: 20, valid Loss: 1.5109, valid Acc: 0.6973\n",
      "model saved to model_20.pth\n",
      "Epoch: 21, train Loss: 0.0360, train Acc: 0.9889\n",
      "Epoch: 21, valid Loss: 1.5380, valid Acc: 0.6969\n",
      "model saved to model_21.pth\n",
      "Epoch: 22, train Loss: 0.0371, train Acc: 0.9888\n",
      "Epoch: 22, valid Loss: 1.7736, valid Acc: 0.6694\n",
      "model saved to model_22.pth\n",
      "Epoch: 23, train Loss: 0.0931, train Acc: 0.9690\n",
      "Epoch: 23, valid Loss: 1.7336, valid Acc: 0.6543\n",
      "model saved to model_23.pth\n",
      "Epoch: 24, train Loss: 0.0850, train Acc: 0.9703\n",
      "Epoch: 24, valid Loss: 1.6989, valid Acc: 0.6650\n",
      "model saved to model_24.pth\n",
      "Epoch: 25, train Loss: 0.0899, train Acc: 0.9694\n",
      "Epoch: 25, valid Loss: 1.9484, valid Acc: 0.6254\n",
      "model saved to model_25.pth\n",
      "Epoch: 26, train Loss: 0.0962, train Acc: 0.9665\n",
      "Epoch: 26, valid Loss: 1.7600, valid Acc: 0.6595\n",
      "model saved to model_26.pth\n",
      "Epoch: 27, train Loss: 0.0524, train Acc: 0.9821\n",
      "Epoch: 27, valid Loss: 1.6446, valid Acc: 0.6785\n",
      "model saved to model_27.pth\n",
      "Epoch: 28, train Loss: 0.0252, train Acc: 0.9929\n",
      "Epoch: 28, valid Loss: 1.5901, valid Acc: 0.6879\n",
      "model saved to model_28.pth\n",
      "Epoch: 29, train Loss: 0.0146, train Acc: 0.9966\n",
      "Epoch: 29, valid Loss: 1.6517, valid Acc: 0.6890\n",
      "model saved to model_29.pth\n",
      "Epoch: 30, train Loss: 0.0106, train Acc: 0.9973\n",
      "Epoch: 30, valid Loss: 1.6178, valid Acc: 0.6913\n",
      "model saved to model_30.pth\n",
      "Epoch: 31, train Loss: 0.0094, train Acc: 0.9975\n",
      "Epoch: 31, valid Loss: 1.6110, valid Acc: 0.6912\n",
      "model saved to model_31.pth\n",
      "Epoch: 32, train Loss: 0.0081, train Acc: 0.9978\n",
      "Epoch: 32, valid Loss: 1.6328, valid Acc: 0.6913\n",
      "model saved to model_32.pth\n",
      "Epoch: 33, train Loss: 0.0062, train Acc: 0.9980\n",
      "Epoch: 33, valid Loss: 1.6309, valid Acc: 0.6947\n",
      "model saved to model_33.pth\n",
      "Epoch: 34, train Loss: 0.0074, train Acc: 0.9977\n",
      "Epoch: 34, valid Loss: 1.6308, valid Acc: 0.6967\n",
      "model saved to model_34.pth\n",
      "Epoch: 35, train Loss: 0.0063, train Acc: 0.9980\n",
      "Epoch: 35, valid Loss: 1.6738, valid Acc: 0.6964\n",
      "model saved to model_35.pth\n",
      "Epoch: 36, train Loss: 0.0060, train Acc: 0.9977\n",
      "Epoch: 36, valid Loss: 1.7131, valid Acc: 0.6864\n",
      "model saved to model_36.pth\n",
      "Epoch: 37, train Loss: 0.0063, train Acc: 0.9978\n",
      "Epoch: 37, valid Loss: 1.6539, valid Acc: 0.6952\n",
      "model saved to model_37.pth\n",
      "Epoch: 38, train Loss: 0.0054, train Acc: 0.9981\n",
      "Epoch: 38, valid Loss: 1.7376, valid Acc: 0.6827\n",
      "model saved to model_38.pth\n",
      "Epoch: 39, train Loss: 0.0069, train Acc: 0.9977\n",
      "Epoch: 39, valid Loss: 1.7015, valid Acc: 0.6882\n",
      "model saved to model_39.pth\n",
      "Epoch: 40, train Loss: 0.0076, train Acc: 0.9978\n",
      "Epoch: 40, valid Loss: 1.7103, valid Acc: 0.6918\n",
      "model saved to model_40.pth\n",
      "Epoch: 41, train Loss: 0.0073, train Acc: 0.9980\n",
      "Epoch: 41, valid Loss: 1.9145, valid Acc: 0.6671\n",
      "model saved to model_41.pth\n",
      "Epoch: 42, train Loss: 0.0688, train Acc: 0.9781\n",
      "Epoch: 42, valid Loss: 2.6124, valid Acc: 0.5545\n",
      "model saved to model_42.pth\n",
      "Epoch: 43, train Loss: 0.4506, train Acc: 0.8505\n",
      "Epoch: 43, valid Loss: 1.5241, valid Acc: 0.6351\n",
      "Epoch: 44, train Loss: 0.0878, train Acc: 0.9727\n",
      "Epoch: 44, valid Loss: 1.5669, valid Acc: 0.6433\n",
      "model saved to model_44.pth\n",
      "Epoch: 45, train Loss: 0.0223, train Acc: 0.9949\n",
      "Epoch: 45, valid Loss: 1.5399, valid Acc: 0.6573\n",
      "model saved to model_45.pth\n",
      "Epoch: 46, train Loss: 0.0115, train Acc: 0.9971\n",
      "Epoch: 46, valid Loss: 1.5627, valid Acc: 0.6637\n",
      "model saved to model_46.pth\n",
      "Epoch: 47, train Loss: 0.0125, train Acc: 0.9970\n",
      "Epoch: 47, valid Loss: 1.6408, valid Acc: 0.6626\n",
      "model saved to model_47.pth\n",
      "Epoch: 48, train Loss: 0.0087, train Acc: 0.9979\n",
      "Epoch: 48, valid Loss: 1.6458, valid Acc: 0.6615\n",
      "model saved to model_48.pth\n",
      "Epoch: 49, train Loss: 0.0068, train Acc: 0.9981\n",
      "Epoch: 49, valid Loss: 1.6548, valid Acc: 0.6628\n",
      "model saved to model_49.pth\n",
      "Epoch: 50, train Loss: 0.0060, train Acc: 0.9980\n",
      "Epoch: 50, valid Loss: 1.7021, valid Acc: 0.6614\n",
      "model saved to model_50.pth\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "\n",
    "    train_set, valid_set = load_data('./train_img', 'train.csv')\n",
    "\n",
    "    #transform to tensor, data augmentation\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "    #transforms.RandomAffine(15, translate=(0.1,0.1), scale=(0.9,1.1), shear=10, fillcolor=0),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize([mean], [std], inplace=False)\n",
    "    ])\n",
    "    \n",
    "    train_dataset = hw3_dataset(train_set,transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "    valid_dataset = hw3_dataset(valid_set,transform)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=False)\n",
    "    \"\"\"\n",
    "    model = Net()\n",
    "    if use_gpu:\n",
    "        model.cuda()\n",
    "    \"\"\"\n",
    "    model =Net()\n",
    "    model.load_state_dict(torch.load('model_10.pth'))\n",
    "    print(\"load model\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    num_epoch = 50\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        train_acc = []\n",
    "        for idx, (img, label) in enumerate(train_loader):\n",
    "            if use_gpu:\n",
    "                img = img.cuda()\n",
    "                label = label.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(img)\n",
    "            loss = loss_fn(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predict = torch.max(output, 1)[1]\n",
    "            acc = np.mean((label == predict).cpu().numpy())\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss.item())\n",
    "        print(\"Epoch: {}, train Loss: {:.4f}, train Acc: {:.4f}\".format(epoch + 1, np.mean(train_loss), np.mean(train_acc)))\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_loss = []\n",
    "            valid_acc = []\n",
    "            for idx, (img, label) in enumerate(valid_loader):\n",
    "                if use_gpu:\n",
    "                    img = img.cuda()\n",
    "                    label = label.cuda()\n",
    "                output = model(img)\n",
    "                loss = loss_fn(output, label)\n",
    "                predict = torch.max(output, 1)[1]\n",
    "                acc = np.mean((label == predict).cpu().numpy())\n",
    "                valid_loss.append(loss.item())\n",
    "                valid_acc.append(acc)\n",
    "            print(\"Epoch: {}, valid Loss: {:.4f}, valid Acc: {:.4f}\".format(epoch + 1, np.mean(valid_loss), np.mean(valid_acc)))\n",
    "        \n",
    "        if np.mean(train_acc) > 0.9:\n",
    "            checkpoint_path = './ta_model/model_{}.pth'.format(epoch+1) \n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print('model saved to %s' % checkpoint_path)\n",
    "    \n",
    "\n",
    "    #finish test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    #......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
