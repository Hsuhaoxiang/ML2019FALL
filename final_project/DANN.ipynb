{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import optim\n",
    "import cv2\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "#from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Function\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import PIL.Image\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from torchvision.models.resnet import ResNet, BasicBlock\n",
    "import inspect\n",
    "#from tqdm.autonotebook import tqdm\n",
    "#from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNModel(\n",
      "  (feature): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace)\n",
      "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (21): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (23): ReLU(inplace)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (30): ReLU(inplace)\n",
      "    (31): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (32): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (33): ReLU(inplace)\n",
      "    (34): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (35): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  )\n",
      "  (class_classifier): Sequential(\n",
      "    (c_fc1): Linear(in_features=25088, out_features=100, bias=True)\n",
      "    (c_bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (c_relu1): ReLU(inplace)\n",
      "    (c_drop1): Dropout2d(p=0.5)\n",
      "    (c_fc2): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (c_bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (c_relu2): ReLU(inplace)\n",
      "    (c_fc3): Linear(in_features=100, out_features=10, bias=True)\n",
      "    (c_softmax): LogSoftmax()\n",
      "  )\n",
      "  (domain_classifier): Sequential(\n",
      "    (d_fc1): Linear(in_features=25088, out_features=100, bias=True)\n",
      "    (d_bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (d_relu1): ReLU(inplace)\n",
      "    (d_fc2): Linear(in_features=100, out_features=2, bias=True)\n",
      "    (d_softmax): LogSoftmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "original_model = torchvision.models.vgg13_bn(pretrained = True)\n",
    "\n",
    "from torch.autograd import Function\n",
    "\n",
    "\n",
    "class ReverseLayerF(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "\n",
    "        return output, None\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "            *list(original_model.features.children()),\n",
    "            original_model.avgpool\n",
    "        )\n",
    "\n",
    "        self.class_classifier = nn.Sequential()\n",
    "        self.class_classifier.add_module('c_fc1', nn.Linear(25088, 100))\n",
    "        self.class_classifier.add_module('c_bn1', nn.BatchNorm1d(100))\n",
    "        self.class_classifier.add_module('c_relu1', nn.ReLU(True))\n",
    "        self.class_classifier.add_module('c_drop1', nn.Dropout2d())\n",
    "        self.class_classifier.add_module('c_fc2', nn.Linear(100, 100))\n",
    "        self.class_classifier.add_module('c_bn2', nn.BatchNorm1d(100))\n",
    "        self.class_classifier.add_module('c_relu2', nn.ReLU(True))\n",
    "        self.class_classifier.add_module('c_fc3', nn.Linear(100, 10))\n",
    "        self.class_classifier.add_module('c_softmax', nn.LogSoftmax(dim=1))\n",
    "\n",
    "        self.domain_classifier = nn.Sequential()\n",
    "        self.domain_classifier.add_module('d_fc1', nn.Linear(25088, 100))\n",
    "        self.domain_classifier.add_module('d_bn1', nn.BatchNorm1d(100))\n",
    "        self.domain_classifier.add_module('d_relu1', nn.ReLU(True))\n",
    "        self.domain_classifier.add_module('d_fc2', nn.Linear(100, 2))\n",
    "        self.domain_classifier.add_module('d_softmax', nn.LogSoftmax(dim=1))\n",
    "\n",
    "    def forward(self, input_image, alpha):\n",
    "        input_data = input_image.expand(input_image.data.shape[0], 3, 32, 32)\n",
    "        feature = self.feature(input_data)\n",
    "        feature = feature.view(-1, 25088)\n",
    "        reverse_feature = ReverseLayerF.apply(feature, alpha)\n",
    "        class_output = self.class_classifier(feature)\n",
    "        domain_output = self.domain_classifier(reverse_feature)\n",
    "\n",
    "        return class_output, domain_output\n",
    "\n",
    "test = CNNModel()\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"cuda\")\n",
    "    device =torch.device('cuda:0')\n",
    "else:\n",
    "    print(\"cpu\")\n",
    "    device =torch.device(\"cpu\")\n",
    "    \n",
    "data_transforms =   transforms.Compose([\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                ])\n",
    "    \n",
    "class Image_data(Dataset):\n",
    "    def __init__(self,label,data,data_transforms):\n",
    "        self.data_path = data\n",
    "        self.label_path = label\n",
    "        self.data_transforms = data_transforms\n",
    "    def __getitem__(self,index):\n",
    "\n",
    "        trainX = np.load(self.data_path)\n",
    "        trainY = np.load(self.label_path)\n",
    "        image = PIL.Image.fromarray(np.uint8(trainX[index]))\n",
    "\n",
    "        \n",
    "        #trainX[index] = np.transpose(trainX[index], ( 2, 0, 1))\n",
    "        #trainX = torch.Tensor(trainX)\n",
    "        trainY = torch.Tensor(trainY)\n",
    "        \n",
    "        return data_transforms(image),trainY[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(np.load(self.label_path))\n",
    "\n",
    "train_data = Image_data('./trainY.npy','./trainX.npy',data_transforms)\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "validation_split = .1\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(train_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size,sampler=train_sampler)\n",
    "val_loader = DataLoader(train_data, batch_size=batch_size,sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms =   transforms.Compose([\n",
    "                    transforms.Resize((32, 32)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                ])\n",
    "class Test_data(Dataset):\n",
    "    def __init__(self,data,data_transforms):\n",
    "        self.data_path = data\n",
    "        self.data_transforms = data_transforms\n",
    "    def __getitem__(self,index):\n",
    "\n",
    "        trainX = np.load(self.data_path)\n",
    "        color_img = cv2.cvtColor(trainX[index],cv2.COLOR_GRAY2RGB)\n",
    "        image = PIL.Image.fromarray(np.uint8(color_img))\n",
    "\n",
    "        \n",
    "        return test_transforms(image)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(np.load(self.data_path))\n",
    "\n",
    "\n",
    "test_data = Test_data('testX.npy',test_transforms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientReversalFunction(Function):\n",
    "    \"\"\"\n",
    "    Gradient Reversal Layer from:\n",
    "    Unsupervised Domain Adaptation by Backpropagation (Ganin & Lempitsky, 2015)\n",
    "    Forward pass is the identity function. In the backward pass,\n",
    "    the upstream gradients are multiplied by -lambda (i.e. gradient is reversed)\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, lambda_):\n",
    "        ctx.lambda_ = lambda_\n",
    "        return x.clone()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grads):\n",
    "        lambda_ = ctx.lambda_\n",
    "        lambda_ = grads.new_tensor(lambda_)\n",
    "        dx = -lambda_ * grads\n",
    "        return dx, None\n",
    "\n",
    "\n",
    "class GradientReversal(torch.nn.Module):\n",
    "    def __init__(self, lambda_=1):\n",
    "        super(GradientReversal, self).__init__()\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    def forward(self, x):\n",
    "        return GradientReversalFunction.apply(x, self.lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, [iter: 157 / all 157], err_s_label: 0.201724, err_s_domain: 0.648389, err_t_domain: 0.544706\n",
      "epoch: 1, [iter: 157 / all 157], err_s_label: 0.695885, err_s_domain: 1.185739, err_t_domain: 0.739188\n",
      "epoch: 2, [iter: 157 / all 157], err_s_label: 0.065816, err_s_domain: 0.622307, err_t_domain: 0.684092\n",
      "epoch: 3, [iter: 157 / all 157], err_s_label: 0.833639, err_s_domain: 1.041361, err_t_domain: 0.547164\n",
      "epoch: 4, [iter: 157 / all 157], err_s_label: 1.920633, err_s_domain: 0.903636, err_t_domain: 0.567220\n",
      "epoch: 5, [iter: 157 / all 157], err_s_label: 0.143327, err_s_domain: 1.086723, err_t_domain: 0.429844\n",
      "epoch: 6, [iter: 157 / all 157], err_s_label: 0.176544, err_s_domain: 0.966275, err_t_domain: 0.745064\n",
      "epoch: 7, [iter: 157 / all 157], err_s_label: 0.108838, err_s_domain: 0.714771, err_t_domain: 0.657422\n",
      "epoch: 8, [iter: 157 / all 157], err_s_label: 1.026261, err_s_domain: 0.947371, err_t_domain: 0.628381\n",
      "epoch: 9, [iter: 157 / all 157], err_s_label: 0.498070, err_s_domain: 0.889027, err_t_domain: 0.702132\n",
      "epoch: 10, [iter: 157 / all 157], err_s_label: 0.652283, err_s_domain: 0.829681, err_t_domain: 0.759259\n",
      "epoch: 11, [iter: 157 / all 157], err_s_label: 0.012916, err_s_domain: 0.630366, err_t_domain: 0.717164\n",
      "epoch: 12, [iter: 157 / all 157], err_s_label: 0.031110, err_s_domain: 0.900477, err_t_domain: 0.717604\n",
      "epoch: 13, [iter: 157 / all 157], err_s_label: 0.288597, err_s_domain: 0.715260, err_t_domain: 0.709919\n",
      "epoch: 14, [iter: 157 / all 157], err_s_label: 0.090052, err_s_domain: 0.830553, err_t_domain: 0.650584\n",
      "epoch: 15, [iter: 157 / all 157], err_s_label: 0.003445, err_s_domain: 0.831414, err_t_domain: 0.714010\n",
      "epoch: 16, [iter: 157 / all 157], err_s_label: 0.042643, err_s_domain: 0.838820, err_t_domain: 0.789955\n",
      "epoch: 17, [iter: 157 / all 157], err_s_label: 0.005605, err_s_domain: 0.827903, err_t_domain: 0.703999\n",
      "epoch: 18, [iter: 157 / all 157], err_s_label: 0.050015, err_s_domain: 0.762327, err_t_domain: 0.730303\n",
      "epoch: 19, [iter: 157 / all 157], err_s_label: 0.824433, err_s_domain: 0.729091, err_t_domain: 0.666909\n",
      "epoch: 20, [iter: 157 / all 157], err_s_label: 0.020981, err_s_domain: 0.808863, err_t_domain: 0.701167\n",
      "epoch: 21, [iter: 157 / all 157], err_s_label: 1.058841, err_s_domain: 0.812608, err_t_domain: 0.712954\n",
      "epoch: 22, [iter: 157 / all 157], err_s_label: 1.453424, err_s_domain: 0.935718, err_t_domain: 0.719531\n",
      "epoch: 23, [iter: 157 / all 157], err_s_label: 0.453322, err_s_domain: 0.870812, err_t_domain: 0.712227\n",
      "epoch: 24, [iter: 157 / all 157], err_s_label: 0.010178, err_s_domain: 0.685092, err_t_domain: 0.663349\n",
      "epoch: 25, [iter: 157 / all 157], err_s_label: 0.002502, err_s_domain: 0.654791, err_t_domain: 0.741478\n",
      "epoch: 26, [iter: 157 / all 157], err_s_label: 0.003967, err_s_domain: 0.762905, err_t_domain: 0.717969\n",
      "epoch: 27, [iter: 157 / all 157], err_s_label: 0.361198, err_s_domain: 0.774942, err_t_domain: 0.675633\n",
      "epoch: 28, [iter: 157 / all 157], err_s_label: 0.005005, err_s_domain: 0.757198, err_t_domain: 0.766097\n",
      "epoch: 29, [iter: 157 / all 157], err_s_label: 0.016729, err_s_domain: 0.817620, err_t_domain: 0.699280\n",
      "epoch: 30, [iter: 157 / all 157], err_s_label: 0.022970, err_s_domain: 0.815482, err_t_domain: 0.679716\n",
      "epoch: 31, [iter: 157 / all 157], err_s_label: 0.003208, err_s_domain: 0.787989, err_t_domain: 0.710889\n",
      "epoch: 32, [iter: 157 / all 157], err_s_label: 0.007066, err_s_domain: 0.687912, err_t_domain: 0.667525\n",
      "epoch: 33, [iter: 157 / all 157], err_s_label: 0.078939, err_s_domain: 0.740414, err_t_domain: 0.716212\n",
      "epoch: 34, [iter: 157 / all 157], err_s_label: 0.041092, err_s_domain: 0.707143, err_t_domain: 0.655477\n",
      "epoch: 35, [iter: 157 / all 157], err_s_label: 0.001035, err_s_domain: 0.714179, err_t_domain: 0.724304\n",
      "epoch: 36, [iter: 157 / all 157], err_s_label: 0.228922, err_s_domain: 0.749592, err_t_domain: 0.670011\n",
      "epoch: 37, [iter: 157 / all 157], err_s_label: 0.005069, err_s_domain: 0.701611, err_t_domain: 0.687689\n",
      "epoch: 38, [iter: 157 / all 157], err_s_label: 0.817256, err_s_domain: 0.684298, err_t_domain: 0.689901\n",
      "epoch: 39, [iter: 157 / all 157], err_s_label: 0.011201, err_s_domain: 0.714941, err_t_domain: 0.689270\n",
      "epoch: 40, [iter: 157 / all 157], err_s_label: 0.003096, err_s_domain: 0.684584, err_t_domain: 0.703720\n",
      "epoch: 41, [iter: 157 / all 157], err_s_label: 0.002674, err_s_domain: 0.717167, err_t_domain: 0.695735\n",
      "epoch: 42, [iter: 157 / all 157], err_s_label: 0.473176, err_s_domain: 0.695512, err_t_domain: 0.714817\n",
      "epoch: 43, [iter: 157 / all 157], err_s_label: 0.515638, err_s_domain: 0.741733, err_t_domain: 0.697183\n",
      "epoch: 44, [iter: 157 / all 157], err_s_label: 0.057638, err_s_domain: 0.737831, err_t_domain: 0.692973\n",
      "epoch: 45, [iter: 157 / all 157], err_s_label: 0.042641, err_s_domain: 0.766085, err_t_domain: 0.676162\n",
      "epoch: 46, [iter: 157 / all 157], err_s_label: 0.051271, err_s_domain: 0.714279, err_t_domain: 0.705863\n",
      "epoch: 47, [iter: 157 / all 157], err_s_label: 0.220080, err_s_domain: 0.772236, err_t_domain: 0.688241\n",
      "epoch: 48, [iter: 157 / all 157], err_s_label: 0.060524, err_s_domain: 0.723245, err_t_domain: 0.711543\n",
      "epoch: 49, [iter: 157 / all 157], err_s_label: 0.103017, err_s_domain: 0.704070, err_t_domain: 0.703120\n",
      "epoch: 50, [iter: 157 / all 157], err_s_label: 0.178555, err_s_domain: 0.733988, err_t_domain: 0.687968\n",
      "epoch: 51, [iter: 157 / all 157], err_s_label: 0.868830, err_s_domain: 0.743362, err_t_domain: 0.697649\n",
      "epoch: 52, [iter: 157 / all 157], err_s_label: 0.017874, err_s_domain: 0.715177, err_t_domain: 0.694687\n",
      "epoch: 53, [iter: 157 / all 157], err_s_label: 0.158928, err_s_domain: 0.692254, err_t_domain: 0.687006\n",
      "epoch: 54, [iter: 157 / all 157], err_s_label: 0.675847, err_s_domain: 0.734444, err_t_domain: 0.711690\n",
      "epoch: 55, [iter: 157 / all 157], err_s_label: 0.953380, err_s_domain: 0.721832, err_t_domain: 0.694985\n",
      "epoch: 56, [iter: 157 / all 157], err_s_label: 0.010590, err_s_domain: 0.750256, err_t_domain: 0.699754\n",
      "epoch: 57, [iter: 157 / all 157], err_s_label: 0.046193, err_s_domain: 0.749290, err_t_domain: 0.703563\n",
      "epoch: 58, [iter: 157 / all 157], err_s_label: 0.805282, err_s_domain: 0.724653, err_t_domain: 0.699004\n",
      "epoch: 59, [iter: 157 / all 157], err_s_label: 0.050808, err_s_domain: 0.718302, err_t_domain: 0.690772\n",
      "epoch: 60, [iter: 157 / all 157], err_s_label: 0.002224, err_s_domain: 0.692104, err_t_domain: 0.690829\n",
      "epoch: 61, [iter: 157 / all 157], err_s_label: 0.159116, err_s_domain: 0.762283, err_t_domain: 0.705491\n",
      "epoch: 62, [iter: 157 / all 157], err_s_label: 0.035240, err_s_domain: 0.725035, err_t_domain: 0.684168\n",
      "epoch: 63, [iter: 157 / all 157], err_s_label: 0.007141, err_s_domain: 0.725026, err_t_domain: 0.711918\n",
      "epoch: 64, [iter: 157 / all 157], err_s_label: 0.008961, err_s_domain: 0.733941, err_t_domain: 0.688369\n",
      "epoch: 65, [iter: 157 / all 157], err_s_label: 1.248719, err_s_domain: 0.705255, err_t_domain: 0.696286\n",
      "epoch: 66, [iter: 157 / all 157], err_s_label: 0.003114, err_s_domain: 0.684818, err_t_domain: 0.708161\n",
      "epoch: 67, [iter: 157 / all 157], err_s_label: 0.146863, err_s_domain: 0.723847, err_t_domain: 0.697161\n",
      "epoch: 68, [iter: 157 / all 157], err_s_label: 0.259842, err_s_domain: 0.742806, err_t_domain: 0.692307\n",
      "epoch: 69, [iter: 157 / all 157], err_s_label: 0.039786, err_s_domain: 0.738579, err_t_domain: 0.702205\n",
      "epoch: 70, [iter: 157 / all 157], err_s_label: 0.333628, err_s_domain: 0.727772, err_t_domain: 0.676383\n",
      "epoch: 71, [iter: 157 / all 157], err_s_label: 0.020212, err_s_domain: 0.708356, err_t_domain: 0.688162\n",
      "epoch: 72, [iter: 157 / all 157], err_s_label: 0.048061, err_s_domain: 0.715010, err_t_domain: 0.693329\n",
      "epoch: 73, [iter: 157 / all 157], err_s_label: 1.612252, err_s_domain: 0.717263, err_t_domain: 0.678968\n",
      "epoch: 74, [iter: 157 / all 157], err_s_label: 0.015977, err_s_domain: 0.677177, err_t_domain: 0.714035\n",
      "epoch: 75, [iter: 157 / all 157], err_s_label: 1.364238, err_s_domain: 0.748028, err_t_domain: 0.699758\n",
      "epoch: 76, [iter: 157 / all 157], err_s_label: 0.000624, err_s_domain: 0.700353, err_t_domain: 0.692320\n",
      "epoch: 77, [iter: 157 / all 157], err_s_label: 0.382320, err_s_domain: 0.700035, err_t_domain: 0.692554\n",
      "epoch: 78, [iter: 157 / all 157], err_s_label: 0.031844, err_s_domain: 0.718442, err_t_domain: 0.694529\n",
      "epoch: 79, [iter: 157 / all 157], err_s_label: 0.450211, err_s_domain: 0.695445, err_t_domain: 0.683312\n",
      "epoch: 80, [iter: 157 / all 157], err_s_label: 0.012097, err_s_domain: 0.702349, err_t_domain: 0.709496\n",
      "epoch: 81, [iter: 157 / all 157], err_s_label: 0.000796, err_s_domain: 0.698160, err_t_domain: 0.703331\n",
      "epoch: 82, [iter: 157 / all 157], err_s_label: 0.001058, err_s_domain: 0.705766, err_t_domain: 0.697495\n",
      "epoch: 83, [iter: 157 / all 157], err_s_label: 0.071063, err_s_domain: 0.725282, err_t_domain: 0.699937\n",
      "epoch: 84, [iter: 157 / all 157], err_s_label: 0.009868, err_s_domain: 0.686000, err_t_domain: 0.694134\n",
      "epoch: 85, [iter: 157 / all 157], err_s_label: 0.011088, err_s_domain: 0.694205, err_t_domain: 0.693057\n",
      "epoch: 86, [iter: 157 / all 157], err_s_label: 0.000870, err_s_domain: 0.684843, err_t_domain: 0.704273\n",
      "epoch: 87, [iter: 157 / all 157], err_s_label: 0.003053, err_s_domain: 0.691772, err_t_domain: 0.697741\n",
      "epoch: 88, [iter: 157 / all 157], err_s_label: 0.891607, err_s_domain: 0.713236, err_t_domain: 0.699844\n",
      "epoch: 89, [iter: 157 / all 157], err_s_label: 0.361112, err_s_domain: 0.734009, err_t_domain: 0.692985\n",
      "epoch: 90, [iter: 157 / all 157], err_s_label: 0.003471, err_s_domain: 0.689706, err_t_domain: 0.711287\n",
      "epoch: 91, [iter: 157 / all 157], err_s_label: 0.002507, err_s_domain: 0.696002, err_t_domain: 0.698741\n",
      "epoch: 92, [iter: 157 / all 157], err_s_label: 0.000308, err_s_domain: 0.699294, err_t_domain: 0.703334\n",
      "epoch: 93, [iter: 157 / all 157], err_s_label: 0.003100, err_s_domain: 0.741271, err_t_domain: 0.717089\n",
      "epoch: 94, [iter: 157 / all 157], err_s_label: 0.081580, err_s_domain: 0.706787, err_t_domain: 0.685977\n",
      "epoch: 95, [iter: 157 / all 157], err_s_label: 0.533372, err_s_domain: 0.704010, err_t_domain: 0.688451\n",
      "epoch: 96, [iter: 157 / all 157], err_s_label: 1.691325, err_s_domain: 0.700743, err_t_domain: 0.700204\n",
      "epoch: 97, [iter: 157 / all 157], err_s_label: 0.039125, err_s_domain: 0.723468, err_t_domain: 0.681202\n",
      "epoch: 98, [iter: 157 / all 157], err_s_label: 2.057422, err_s_domain: 0.708051, err_t_domain: 0.702083\n",
      "epoch: 99, [iter: 157 / all 157], err_s_label: 0.002322, err_s_domain: 0.731373, err_t_domain: 0.689202\n",
      "epoch: 100, [iter: 157 / all 157], err_s_label: 0.018835, err_s_domain: 0.722851, err_t_domain: 0.684948\n",
      "epoch: 101, [iter: 157 / all 157], err_s_label: 0.015825, err_s_domain: 0.713994, err_t_domain: 0.685765\n",
      "epoch: 102, [iter: 157 / all 157], err_s_label: 0.184935, err_s_domain: 0.699774, err_t_domain: 0.697924\n",
      "epoch: 103, [iter: 157 / all 157], err_s_label: 0.003859, err_s_domain: 0.726965, err_t_domain: 0.682622\n",
      "epoch: 104, [iter: 157 / all 157], err_s_label: 0.001864, err_s_domain: 0.704061, err_t_domain: 0.700150\n",
      "epoch: 105, [iter: 157 / all 157], err_s_label: 0.009253, err_s_domain: 0.698198, err_t_domain: 0.696655\n",
      "epoch: 106, [iter: 157 / all 157], err_s_label: 0.010675, err_s_domain: 0.695422, err_t_domain: 0.686455\n",
      "epoch: 107, [iter: 157 / all 157], err_s_label: 0.142849, err_s_domain: 0.712890, err_t_domain: 0.688841\n",
      "epoch: 108, [iter: 157 / all 157], err_s_label: 0.006738, err_s_domain: 0.688992, err_t_domain: 0.701536\n",
      "epoch: 109, [iter: 157 / all 157], err_s_label: 0.010459, err_s_domain: 0.711910, err_t_domain: 0.684775\n",
      "epoch: 110, [iter: 157 / all 157], err_s_label: 0.008283, err_s_domain: 0.694128, err_t_domain: 0.696701\n",
      "epoch: 111, [iter: 157 / all 157], err_s_label: 0.089832, err_s_domain: 0.716015, err_t_domain: 0.696584\n",
      "epoch: 112, [iter: 157 / all 157], err_s_label: 0.001519, err_s_domain: 0.733783, err_t_domain: 0.679700\n",
      "epoch: 113, [iter: 157 / all 157], err_s_label: 0.001728, err_s_domain: 0.708415, err_t_domain: 0.703702\n",
      "epoch: 114, [iter: 157 / all 157], err_s_label: 0.000881, err_s_domain: 0.693195, err_t_domain: 0.699032\n",
      "epoch: 115, [iter: 157 / all 157], err_s_label: 0.001934, err_s_domain: 0.692084, err_t_domain: 0.700988\n",
      "epoch: 116, [iter: 157 / all 157], err_s_label: 0.011360, err_s_domain: 0.706750, err_t_domain: 0.690855\n",
      "epoch: 117, [iter: 157 / all 157], err_s_label: 0.675264, err_s_domain: 0.685212, err_t_domain: 0.691811\n",
      "epoch: 118, [iter: 157 / all 157], err_s_label: 0.504332, err_s_domain: 0.708051, err_t_domain: 0.689307\n",
      "epoch: 119, [iter: 157 / all 157], err_s_label: 0.110231, err_s_domain: 0.704422, err_t_domain: 0.706683\n",
      "epoch: 120, [iter: 157 / all 157], err_s_label: 0.010308, err_s_domain: 0.700939, err_t_domain: 0.677800\n",
      "epoch: 121, [iter: 157 / all 157], err_s_label: 0.020768, err_s_domain: 0.725869, err_t_domain: 0.693589\n",
      "epoch: 122, [iter: 157 / all 157], err_s_label: 0.015067, err_s_domain: 0.719184, err_t_domain: 0.687713\n",
      "epoch: 123, [iter: 157 / all 157], err_s_label: 0.003769, err_s_domain: 0.691487, err_t_domain: 0.701950\n",
      "epoch: 124, [iter: 157 / all 157], err_s_label: 0.345308, err_s_domain: 0.727507, err_t_domain: 0.688095\n",
      "epoch: 125, [iter: 157 / all 157], err_s_label: 0.001451, err_s_domain: 0.719876, err_t_domain: 0.686610\n",
      "epoch: 126, [iter: 157 / all 157], err_s_label: 1.364528, err_s_domain: 0.725628, err_t_domain: 0.706185\n",
      "epoch: 127, [iter: 157 / all 157], err_s_label: 0.224384, err_s_domain: 0.718224, err_t_domain: 0.701308\n",
      "epoch: 128, [iter: 157 / all 157], err_s_label: 0.146824, err_s_domain: 0.727600, err_t_domain: 0.683532\n",
      "epoch: 129, [iter: 157 / all 157], err_s_label: 0.002753, err_s_domain: 0.690843, err_t_domain: 0.694618\n",
      "epoch: 130, [iter: 157 / all 157], err_s_label: 0.007000, err_s_domain: 0.708861, err_t_domain: 0.674678\n",
      "epoch: 131, [iter: 45 / all 157], err_s_label: 0.001467, err_s_domain: 0.703059, err_t_domain: 0.687290\r"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "#from test import test\n",
    "\n",
    "\n",
    "cuda = True\n",
    "cudnn.benchmark = True\n",
    "lr = 1e-3\n",
    "batch_size = 32\n",
    "image_size = 32\n",
    "n_epoch = 500\n",
    "\n",
    "manual_seed = random.randint(1, 10000)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "# load data\n",
    "\n",
    "\n",
    "\n",
    "dataset_source = train_data\n",
    "\n",
    "dataloader_source = torch.utils.data.DataLoader(\n",
    "    dataset=dataset_source,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "dataset_target = test_data\n",
    "\n",
    "dataloader_target = torch.utils.data.DataLoader(\n",
    "    dataset=dataset_target,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "# load model\n",
    "#my_net = CNNModel()\n",
    "my_net = torch.load('./dann10.pth')\n",
    "# setup optimizer\n",
    "\n",
    "optimizer = optim.Adam(my_net.parameters(), lr=lr)\n",
    "\n",
    "loss_class = torch.nn.NLLLoss()\n",
    "loss_domain = torch.nn.NLLLoss()\n",
    "\n",
    "if cuda:\n",
    "    my_net = my_net.cuda()\n",
    "    loss_class = loss_class.cuda()\n",
    "    loss_domain = loss_domain.cuda()\n",
    "\n",
    "for p in my_net.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "# training\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "\n",
    "    len_dataloader = min(len(dataloader_source), len(dataloader_target))\n",
    "    data_source_iter = iter(dataloader_source)\n",
    "    data_target_iter = iter(dataloader_target)\n",
    "\n",
    "    i = 0\n",
    "    while i < len_dataloader:\n",
    "        p = float(i + epoch * len_dataloader) / n_epoch / len_dataloader\n",
    "        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "\n",
    "        # training model using source data\n",
    "        data_source = data_source_iter.next()\n",
    "        s_img, s_label = data_source\n",
    "\n",
    "        my_net.zero_grad()\n",
    "        batch_size = len(s_label)\n",
    "\n",
    "        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n",
    "        class_label = torch.LongTensor(batch_size)\n",
    "        domain_label = torch.zeros(batch_size)\n",
    "        domain_label = domain_label.long()\n",
    "\n",
    "        if cuda:\n",
    "            s_img = s_img.cuda()\n",
    "            s_label = s_label.cuda().long()\n",
    "            input_img = input_img.cuda()\n",
    "            class_label = class_label.cuda()\n",
    "            domain_label = domain_label.cuda()\n",
    "\n",
    "        input_img.resize_as_(s_img).copy_(s_img)\n",
    "        class_label.resize_as_(s_label).copy_(s_label)\n",
    "        class_output, domain_output = my_net(input_image=input_img, alpha=alpha)\n",
    "        err_s_label = loss_class(class_output, class_label)\n",
    "        err_s_domain = loss_domain(domain_output, domain_label)\n",
    "\n",
    "        # training model using target data\n",
    "        data_target = data_target_iter.next()\n",
    "        t_img = data_target\n",
    "\n",
    "        batch_size = len(t_img)\n",
    "\n",
    "        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n",
    "        domain_label = torch.ones(batch_size)\n",
    "        domain_label = domain_label.long()\n",
    "\n",
    "        if cuda:\n",
    "            t_img = t_img.cuda()\n",
    "            input_img = input_img.cuda()\n",
    "            domain_label = domain_label.cuda()\n",
    "\n",
    "        input_img.resize_as_(t_img).copy_(t_img)\n",
    "\n",
    "        _, domain_output = my_net(input_image=input_img, alpha=alpha)\n",
    "        err_t_domain = loss_domain(domain_output, domain_label)\n",
    "        err = err_t_domain + err_s_domain + err_s_label\n",
    "        err.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        print ('epoch: %d, [iter: %d / all %d], err_s_label: %f, err_s_domain: %f, err_t_domain: %f' \\\n",
    "              % (epoch, i, len_dataloader, err_s_label.data.cpu().numpy(),\n",
    "                 err_s_domain.data.cpu().numpy(), err_t_domain.data.cpu().item()),end = \"\\r\")\n",
    "        \n",
    "    print ('epoch: %d, [iter: %d / all %d], err_s_label: %f, err_s_domain: %f, err_t_domain: %f' \\\n",
    "              % (epoch, i, len_dataloader, err_s_label.data.cpu().numpy(),\n",
    "                 err_s_domain.data.cpu().numpy(), err_t_domain.data.cpu().item()))\n",
    "\n",
    "    torch.save(my_net, './dann{}.pth'.format(epoch))\n",
    "    #test(source_dataset_name, epoch)\n",
    "    #test(target_dataset_name, epoch)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
